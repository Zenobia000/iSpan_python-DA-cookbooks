{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "NWRMSLE stands for Normalized Weighted Root Mean Squared Logarithmic Error. It's a metric used to evaluate the performance of regression models, particularly when you're dealing with target values that have a wide range and are positive-valued. This metric is often seen in Kaggle competitions or other machine learning tasks where accurate prediction of quantities is important, especially when those quantities can vary by several orders of magnitude.\n",
    "\n",
    "### Understanding NWRMSLE:\n",
    "\n",
    "1. **Root Mean Squared Logarithmic Error (RMSLE)**: \n",
    "   - The RMSLE is a variation of the Root Mean Squared Error (RMSE) and is particularly useful when you want to penalize underestimation more than overestimation.\n",
    "   - It's calculated by taking the natural logarithm (`log(1 + x)`) of the predicted and actual values, computing the squared difference between these log-transformed values, and then taking the square root of the average of these squared differences.\n",
    "\n",
    "2. **Normalized**:\n",
    "   - \"Normalized\" implies that the error is scaled in some manner, typically to bring it within a certain range or to account for the scale of the data.\n",
    "\n",
    "3. **Weighted**:\n",
    "   - \"Weighted\" indicates that different values or different predictions might be given different weights. This is useful when certain errors are more significant than others or when the data is imbalanced.\n",
    "   - Weights can be applied based on the importance of specific samples or categories in the data.\n",
    "\n",
    "### Formula:\n",
    "\n",
    "The formula for NWRMSLE might vary slightly depending on specific implementations, but it generally looks something like this:\n",
    "\n",
    "\\[ NWRMSLE = \\sqrt{\\frac{\\sum w_i \\cdot (\\log(p_i + 1) - \\log(a_i + 1))^2}{\\sum w_i}} \\]\n",
    "\n",
    "where:\n",
    "- \\( p_i \\) is the predicted value for the ith observation,\n",
    "- \\( a_i \\) is the actual value for the ith observation,\n",
    "- \\( w_i \\) is the weight for the ith observation,\n",
    "- \\( \\log \\) is the natural logarithm.\n",
    "\n",
    "### Use in Target Transformation:\n",
    "\n",
    "NWRMSLE can be particularly useful in cases where the target variable has undergone a transformation, such as a logarithmic transformation. This is common in situations where the target variable spans several orders of magnitude. By using logarithmic transformation on the target, models can often achieve a more balanced and accurate prediction across the range of values. The NWRMSLE then becomes an appropriate metric for evaluating these models because it inherently works with the logarithms of the predictions and actual values, aligning well with the transformed nature of the target.\n",
    "\n",
    "### Key Points:\n",
    "\n",
    "- NWRMSLE is less sensitive to large errors when both the predicted and actual values are large, which can be desirable in certain contexts.\n",
    "- It penalizes underestimates more than overestimates, which can be particularly useful in scenarios where underestimation has a greater cost.\n",
    "- The inclusion of weights allows for flexibility in emphasizing certain parts of the data according to their relevance or importance. \n",
    "\n",
    "### Conclusion:\n",
    "\n",
    "NWRMSLE is a powerful metric for evaluating regression models, especially in cases where target transformation is applied, and the data has a wide range or is imbalanced. It offers a nuanced way to assess model performance, taking into account the scale and importance of different errors."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "NWRMSLE: 0.08749628569079618\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "def nwrmsle(actual, predicted, weights):\n",
    "    \"\"\"\n",
    "    Calculate the Normalized Weighted Root Mean Squared Logarithmic Error.\n",
    "    :param actual: numpy array of actual values\n",
    "    :param predicted: numpy array of predicted values\n",
    "    :param weights: numpy array of weights for each observation\n",
    "    :return: calculated NWRMSLE\n",
    "    \"\"\"\n",
    "    # Add 1 to actual and predicted values to ensure they are positive and nonzero\n",
    "    log_actual = np.log(actual + 1)\n",
    "    log_predicted = np.log(predicted + 1)\n",
    "    \n",
    "    # Calculate the squared log error\n",
    "    squared_log_error = (log_predicted - log_actual) ** 2\n",
    "    \n",
    "    # Calculate the mean squared log error with weights\n",
    "    mean_squared_log_error = np.sum(weights * squared_log_error) / np.sum(weights)\n",
    "    \n",
    "    # Return the square root of the mean squared log error\n",
    "    return np.sqrt(mean_squared_log_error)\n",
    "\n",
    "# Example data\n",
    "actual_values = np.array([10, 20, 30, 40, 50])\n",
    "predicted_values = np.array([12, 22, 29, 43, 52])\n",
    "weights = np.array([1, 1.5, 1, 2, 1.5])\n",
    "\n",
    "# Calculate NWRMSLE\n",
    "error = nwrmsle(actual_values, predicted_values, weights)\n",
    "print(\"NWRMSLE:\", error)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Defining weights in the context of calculating a metric like Normalized Weighted Root Mean Squared Logarithmic Error (NWRMSLE) depends on the specific requirements of your problem and dataset. Weights are used to give different importance to different observations in your dataset. Here are some common strategies for defining weights:\n",
    "\n",
    "### 1. **Uniform Weights**:\n",
    "- **Equal Importance**: If you believe that each observation in your dataset is equally important, you can assign a uniform weight to all observations. This is the simplest approach and essentially turns NWRMSLE into a non-weighted metric.\n",
    "\n",
    "  ```python\n",
    "  weights = np.ones(len(actual_values))  # For a numpy array of actual_values\n",
    "  ```\n",
    "\n",
    "### 2. **Error Magnitude-Based Weights**:\n",
    "- **Larger Impact for Specific Ranges**: If errors in certain ranges of your target variable are more critical than others, you might assign higher weights to those ranges. For example, in a sales forecasting problem, underestimating high-volume sales could be more detrimental than underestimating low-volume sales.\n",
    "\n",
    "  ```python\n",
    "  weights = np.where(actual_values > threshold, higher_weight, lower_weight)\n",
    "  ```\n",
    "\n",
    "### 3. **Category-Based Weights**:\n",
    "- **Different Categories**: If your dataset contains different categories or groups and some groups are more important than others, you can assign weights based on these categories.\n",
    "\n",
    "  ```python\n",
    "  weights = np.array([weight_dict[category] for category in categories])\n",
    "  ```\n",
    "\n",
    "### 4. **Variance-Based Weights**:\n",
    "- **Inversely Proportional to Variance**: In some cases, observations with less variability (more certainty) are more critical. Here, you could inversely weight observations by their variance.\n",
    "\n",
    "  ```python\n",
    "  weights = 1 / np.var(some_feature_of_each_observation)\n",
    "  ```\n",
    "\n",
    "### 5. **Time-Based Weights**:\n",
    "- **Time Series Data**: In time series forecasting, more recent data might be more relevant than older data. Weights could decrease for older observations.\n",
    "\n",
    "  ```python\n",
    "  weights = np.linspace(start_weight, end_weight, len(actual_values))\n",
    "  ```\n",
    "\n",
    "### 6. **Custom Business Logic**:\n",
    "- **Business Objectives**: Sometimes, weights are determined by specific business goals or objectives, such as focusing on certain customers, regions, or time periods.\n",
    "\n",
    "### 7. **Model Confidence**:\n",
    "- **Confidence of Predictions**: If your model can output prediction confidence intervals or probabilities, you can use these to weight observations. More confidence in a prediction could lead to a higher weight.\n",
    "\n",
    "### Key Considerations:\n",
    "- **Balance**: Ensure that the weights are balanced and do not overly favor certain observations unless strongly justified.\n",
    "- **Validation**: It's important to validate the choice of weights through cross-validation or other model validation techniques to ensure they improve model performance.\n",
    "- **Interpretability**: Be aware that introducing weights can make the model evaluation and interpretation more complex.\n",
    "- **Data Understanding**: Deep understanding of your data and the problem context is crucial in defining meaningful and effective weights.\n",
    "\n",
    "In summary, the choice of weights should reflect the importance of different observations in achieving your overall modeling goals and should be guided by a thorough understanding of the data and the problem context."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. 均勻權重（Uniform Weights）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Uniform Weights: [1. 1. 1. 1. 1.]\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "actual_values = np.array([10, 15, 20, 25, 30])  # 示例實際值\n",
    "predicted_values = np.array([12, 14, 22, 24, 31])  # 示例預測值\n",
    "\n",
    "# 給所有觀測值分配相同的權重\n",
    "uniform_weights = np.ones(len(actual_values))\n",
    "print(\"Uniform Weights:\", uniform_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. 基於錯誤大小的權重（Error Magnitude-Based Weights）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Magnitude-Based Weights: [1 1 1 2 2]\n"
     ]
    }
   ],
   "source": [
    "threshold = 20\n",
    "higher_weight = 2\n",
    "lower_weight = 1\n",
    "\n",
    "# 為高於某閾值的實際值分配更高的權重\n",
    "magnitude_weights = np.where(actual_values > threshold, higher_weight, lower_weight)\n",
    "print(\"Magnitude-Based Weights:\", magnitude_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. 基於類別的權重（Category-Based Weights）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category-Based Weights: [1.  1.5 1.  2.  1.5]\n"
     ]
    }
   ],
   "source": [
    "categories = np.array(['A', 'B', 'A', 'C', 'B'])  # 示例類別\n",
    "weight_dict = {'A': 1, 'B': 1.5, 'C': 2}\n",
    "\n",
    "# 根據類別分配權重\n",
    "category_weights = np.array([weight_dict[category] for category in categories])\n",
    "print(\"Category-Based Weights:\", category_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. 基於變異性的權重（Variance-Based Weights）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Variance-Based Weights: 0.07142857142857142\n"
     ]
    }
   ],
   "source": [
    "some_feature = np.array([5, 10, 5, 15, 10])  # 示例特徵\n",
    "\n",
    "# 分配與特徵變異性成反比的權重\n",
    "variance_weights = 1 / np.var(some_feature)\n",
    "print(\"Variance-Based Weights:\", variance_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. 基於時間的權重（Time-Based Weights）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time-Based Weights: [1.   1.25 1.5  1.75 2.  ]\n"
     ]
    }
   ],
   "source": [
    "start_weight = 1\n",
    "end_weight = 2\n",
    "\n",
    "# 給予最近的觀測值更高的權重\n",
    "time_weights = np.linspace(start_weight, end_weight, len(actual_values))\n",
    "print(\"Time-Based Weights:\", time_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6. 自定義商業邏輯的權重（Custom Business Logic Weights）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom Business Logic Weights: [1 2 1 3 2]\n"
     ]
    }
   ],
   "source": [
    "# 假設這裡是基於特定商業邏輯定義的權重\n",
    "custom_weights = np.array([1, 2, 1, 3, 2])\n",
    "print(\"Custom Business Logic Weights:\", custom_weights)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. 模型信心的權重（Model Confidence Weights）"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model Confidence Weights: [0.8 0.5 0.9 0.6 0.7]\n"
     ]
    }
   ],
   "source": [
    "model_confidence = np.array([0.8, 0.5, 0.9, 0.6, 0.7])  # 示例模型信心值\n",
    "\n",
    "# 使用模型信心作為權重\n",
    "confidence_weights = model_confidence\n",
    "print(\"Model Confidence Weights:\", confidence_weights)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
