# %% [markdown]
# # ğŸš€ æ•¸æ“šåˆ†ææ•ˆèƒ½å„ªåŒ–æŠ€å·§

# æœ¬èª²ç¨‹å°‡ä»‹ç´¹æ•¸æ“šåˆ†æä¸­çš„æ•ˆèƒ½å„ªåŒ–æŠ€å·§ï¼ŒåŒ…æ‹¬è¨˜æ†¶é«”ç®¡ç†ã€é‹ç®—åŠ é€Ÿã€ç¨‹å¼ç¢¼å„ªåŒ–ç­‰é€²éšä¸»é¡Œã€‚

# %% [markdown]
# ## ğŸ¯ æ•™å­¸ç›®æ¨™

# - ğŸ“ˆ ç†è§£æ•ˆèƒ½ç“¶é ¸
# - ğŸ”„ å­¸ç¿’è¨˜æ†¶é«”å„ªåŒ–
# - ğŸ¨ æŒæ¡é‹ç®—åŠ é€Ÿæ–¹æ³•
# - ğŸ’¡ å¯¦è¸ç¨‹å¼ç¢¼å„ªåŒ–

# %%
# ç’°å¢ƒè¨­ç½®
import numpy as np
import pandas as pd
import time
import memory_profiler
import psutil
import warnings
from concurrent.futures import ProcessPoolExecutor, ThreadPoolExecutor
from functools import partial
import gc

# å¿½ç•¥è­¦å‘Š
warnings.filterwarnings('ignore')

# %% [markdown]
# ## 1. è¨˜æ†¶é«”ç®¡ç†å„ªåŒ–

# %%
def memory_usage_info():
    """é¡¯ç¤ºç•¶å‰è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³"""
    process = psutil.Process()
    memory_info = process.memory_info()
    
    print(f"è¨˜æ†¶é«”ä½¿ç”¨æƒ…æ³ï¼š")
    print(f"- RSS (å¸¸é§é›†å¤§å°)ï¼š{memory_info.rss / 1024 / 1024:.2f} MB")
    print(f"- VMS (è™›æ“¬è¨˜æ†¶é«”å¤§å°)ï¼š{memory_info.vms / 1024 / 1024:.2f} MB")
    print(f"- ç³»çµ±ç¸½è¨˜æ†¶é«”ï¼š{psutil.virtual_memory().total / 1024 / 1024 / 1024:.2f} GB")
    print(f"- ç³»çµ±å¯ç”¨è¨˜æ†¶é«”ï¼š{psutil.virtual_memory().available / 1024 / 1024 / 1024:.2f} GB")

# %%
def optimize_dataframe_memory():
    """DataFrame è¨˜æ†¶é«”å„ªåŒ–ç¤ºä¾‹"""
    # ç”Ÿæˆç¤ºä¾‹æ•¸æ“š
    n_rows = 1000000
    df = pd.DataFrame({
        'id': range(n_rows),
        'float_col': np.random.random(n_rows),
        'int_col': np.random.randint(0, 100, n_rows),
        'category_col': np.random.choice(['A', 'B', 'C', 'D'], n_rows),
        'string_col': ['string_' + str(i) for i in range(n_rows)]
    })
    
    # é¡¯ç¤ºå„ªåŒ–å‰çš„è¨˜æ†¶é«”ä½¿ç”¨
    print("å„ªåŒ–å‰ï¼š")
    print(df.info(memory_usage='deep'))
    initial_memory = df.memory_usage(deep=True).sum() / 1024 / 1024
    print(f"ç¸½è¨˜æ†¶é«”ä½¿ç”¨ï¼š{initial_memory:.2f} MB\n")
    
    # å„ªåŒ–æ•¸æ“šé¡å‹
    df_optimized = df.copy()
    
    # 1. å°‡æ•´æ•¸è½‰æ›ç‚ºæœ€å°å¯ç”¨é¡å‹
    df_optimized['int_col'] = pd.to_numeric(df_optimized['int_col'], downcast='integer')
    
    # 2. å°‡æµ®é»æ•¸è½‰æ›ç‚ºæœ€å°å¯ç”¨é¡å‹
    df_optimized['float_col'] = pd.to_numeric(df_optimized['float_col'], downcast='float')
    
    # 3. å°‡å­—ç¬¦é¡åˆ¥è½‰æ›ç‚ºcategoryé¡å‹
    df_optimized['category_col'] = df_optimized['category_col'].astype('category')
    
    # é¡¯ç¤ºå„ªåŒ–å¾Œçš„è¨˜æ†¶é«”ä½¿ç”¨
    print("å„ªåŒ–å¾Œï¼š")
    print(df_optimized.info(memory_usage='deep'))
    optimized_memory = df_optimized.memory_usage(deep=True).sum() / 1024 / 1024
    print(f"ç¸½è¨˜æ†¶é«”ä½¿ç”¨ï¼š{optimized_memory:.2f} MB")
    print(f"ç¯€çœè¨˜æ†¶é«”ï¼š{initial_memory - optimized_memory:.2f} MB")
    print(f"å„ªåŒ–æ¯”ä¾‹ï¼š{((initial_memory - optimized_memory) / initial_memory * 100):.2f}%")
    
    return df_optimized

# %%
def chunk_processing_example():
    """åˆ†å¡Šè™•ç†å¤§æ•¸æ“šç¤ºä¾‹"""
    # å‰µå»ºå¤§å‹æ•¸æ“šæ–‡ä»¶
    n_rows = 1000000
    chunk_size = 100000
    
    df = pd.DataFrame({
        'value': np.random.random(n_rows),
        'group': np.random.choice(['A', 'B', 'C'], n_rows)
    })
    
    # ä¿å­˜ç‚º CSV æ–‡ä»¶
    df.to_csv('large_file.csv', index=False)
    
    # ä¸€æ¬¡æ€§è®€å–è™•ç†
    start_time = time.time()
    result_full = pd.read_csv('large_file.csv')['value'].mean()
    full_time = time.time() - start_time
    print(f"ä¸€æ¬¡æ€§è™•ç†æ™‚é–“ï¼š{full_time:.2f} ç§’")
    
    # åˆ†å¡Šè™•ç†
    start_time = time.time()
    chunk_means = []
    chunk_weights = []
    
    for chunk in pd.read_csv('large_file.csv', chunksize=chunk_size):
        chunk_means.append(chunk['value'].mean())
        chunk_weights.append(len(chunk))
    
    # è¨ˆç®—åŠ æ¬Šå¹³å‡
    result_chunk = np.average(chunk_means, weights=chunk_weights)
    chunk_time = time.time() - start_time
    print(f"åˆ†å¡Šè™•ç†æ™‚é–“ï¼š{chunk_time:.2f} ç§’")
    
    print(f"\nçµæœæ¯”è¼ƒï¼š")
    print(f"ä¸€æ¬¡æ€§è™•ç†çµæœï¼š{result_full:.6f}")
    print(f"åˆ†å¡Šè™•ç†çµæœï¼š{result_chunk:.6f}")
    print(f"æ•ˆèƒ½æå‡ï¼š{((full_time - chunk_time) / full_time * 100):.2f}%")

# %% [markdown]
# ## 2. é‹ç®—åŠ é€Ÿå„ªåŒ–

# %%
def parallel_processing_example():
    """ä¸¦è¡Œè™•ç†ç¤ºä¾‹"""
    def heavy_computation(x):
        """æ¨¡æ“¬è€—æ™‚è¨ˆç®—"""
        time.sleep(0.1)  # æ¨¡æ“¬è€—æ™‚æ“ä½œ
        return x ** 2
    
    data = list(range(100))
    
    # ä¸²è¡Œè™•ç†
    start_time = time.time()
    serial_result = [heavy_computation(x) for x in data]
    serial_time = time.time() - start_time
    print(f"ä¸²è¡Œè™•ç†æ™‚é–“ï¼š{serial_time:.2f} ç§’")
    
    # å¤šé€²ç¨‹è™•ç†
    start_time = time.time()
    with ProcessPoolExecutor() as executor:
        parallel_result = list(executor.map(heavy_computation, data))
    parallel_time = time.time() - start_time
    print(f"ä¸¦è¡Œè™•ç†æ™‚é–“ï¼š{parallel_time:.2f} ç§’")
    
    print(f"åŠ é€Ÿæ¯”ï¼š{serial_time / parallel_time:.2f}x")

# %%
def vectorization_example():
    """å‘é‡åŒ–é‹ç®—ç¤ºä¾‹"""
    n = 1000000
    data = np.random.random(n)
    
    # ä½¿ç”¨å¾ªç’°
    start_time = time.time()
    result_loop = []
    for x in data:
        result_loop.append(np.sin(x) + np.cos(x))
    loop_time = time.time() - start_time
    print(f"å¾ªç’°è™•ç†æ™‚é–“ï¼š{loop_time:.4f} ç§’")
    
    # ä½¿ç”¨å‘é‡åŒ–
    start_time = time.time()
    result_vector = np.sin(data) + np.cos(data)
    vector_time = time.time() - start_time
    print(f"å‘é‡åŒ–è™•ç†æ™‚é–“ï¼š{vector_time:.4f} ç§’")
    
    print(f"åŠ é€Ÿæ¯”ï¼š{loop_time / vector_time:.2f}x")
    
    # é©—è­‰çµæœ
    print("\nçµæœé©—è­‰ï¼š")
    print(f"å¾ªç’°çµæœå‰5å€‹å…ƒç´ ï¼š{result_loop[:5]}")
    print(f"å‘é‡åŒ–çµæœå‰5å€‹å…ƒç´ ï¼š{result_vector[:5]}")
    print(f"çµæœæ˜¯å¦ç›¸åŒï¼š{np.allclose(result_loop, result_vector)}")

# %% [markdown]
# ## 3. ç¨‹å¼ç¢¼å„ªåŒ–æŠ€å·§

# %%
def code_optimization_examples():
    """ç¨‹å¼ç¢¼å„ªåŒ–ç¤ºä¾‹"""
    # 1. åˆ—è¡¨æ¨å°å¼ vs å¾ªç’°
    start_time = time.time()
    result_loop = []
    for i in range(1000000):
        if i % 2 == 0:
            result_loop.append(i ** 2)
    loop_time = time.time() - start_time
    
    start_time = time.time()
    result_comprehension = [i ** 2 for i in range(1000000) if i % 2 == 0]
    comprehension_time = time.time() - start_time
    
    print("1. åˆ—è¡¨æ¨å°å¼ vs å¾ªç’°ï¼š")
    print(f"å¾ªç’°æ™‚é–“ï¼š{loop_time:.4f} ç§’")
    print(f"æ¨å°å¼æ™‚é–“ï¼š{comprehension_time:.4f} ç§’")
    print(f"åŠ é€Ÿæ¯”ï¼š{loop_time / comprehension_time:.2f}x\n")
    
    # 2. é›†åˆæ“ä½œ vs åˆ—è¡¨æ“ä½œ
    data = list(range(1000000))
    search_items = list(range(500000, 1500000))
    
    start_time = time.time()
    result_list = [x for x in search_items if x in data]
    list_time = time.time() - start_time
    
    start_time = time.time()
    data_set = set(data)
    result_set = [x for x in search_items if x in data_set]
    set_time = time.time() - start_time
    
    print("2. é›†åˆæ“ä½œ vs åˆ—è¡¨æ“ä½œï¼š")
    print(f"åˆ—è¡¨æ“ä½œæ™‚é–“ï¼š{list_time:.4f} ç§’")
    print(f"é›†åˆæ“ä½œæ™‚é–“ï¼š{set_time:.4f} ç§’")
    print(f"åŠ é€Ÿæ¯”ï¼š{list_time / set_time:.2f}x\n")
    
    # 3. å­—å…¸æŸ¥æ‰¾ vs æ¢ä»¶åˆ¤æ–·
    data = list(range(1000000))
    
    start_time = time.time()
    result_if = []
    for x in data:
        if x % 3 == 0:
            result_if.append('fizz')
        elif x % 5 == 0:
            result_if.append('buzz')
        else:
            result_if.append(str(x))
    if_time = time.time() - start_time
    
    lookup = {0: 'fizz', 1: str(1), 2: str(2)}
    start_time = time.time()
    result_dict = [lookup.get(x % 3, str(x)) for x in data]
    dict_time = time.time() - start_time
    
    print("3. å­—å…¸æŸ¥æ‰¾ vs æ¢ä»¶åˆ¤æ–·ï¼š")
    print(f"æ¢ä»¶åˆ¤æ–·æ™‚é–“ï¼š{if_time:.4f} ç§’")
    print(f"å­—å…¸æŸ¥æ‰¾æ™‚é–“ï¼š{dict_time:.4f} ç§’")
    print(f"åŠ é€Ÿæ¯”ï¼š{if_time / dict_time:.2f}x")

# %% [markdown]
# ## 4. æ•ˆèƒ½ç›£æ§èˆ‡åˆ†æ

# %%
def performance_monitoring():
    """æ•ˆèƒ½ç›£æ§ç¤ºä¾‹"""
    @memory_profiler.profile
    def memory_intensive_function():
        """è¨˜æ†¶é«”å¯†é›†å‹å‡½æ•¸"""
        # å‰µå»ºå¤§å‹æ•¸æ“š
        data = [i ** 2 for i in range(1000000)]
        # é€²è¡Œä¸€äº›æ“ä½œ
        result = sum(data)
        return result
    
    print("è¨˜æ†¶é«”ä½¿ç”¨åˆ†æï¼š")
    result = memory_intensive_function()
    
    # CPU ä½¿ç”¨ç‡ç›£æ§
    print("\nCPU ä½¿ç”¨ç‡ç›£æ§ï¼š")
    print(f"CPU æ ¸å¿ƒæ•¸ï¼š{psutil.cpu_count()}")
    print(f"CPU ä½¿ç”¨ç‡ï¼š{psutil.cpu_percent(interval=1)}%")
    
    # è¨˜æ†¶é«”ä½¿ç”¨ç›£æ§
    print("\nè¨˜æ†¶é«”ä½¿ç”¨ç›£æ§ï¼š")
    memory_usage_info()

# %% [markdown]
# ## 5. æœ€ä½³å¯¦è¸å»ºè­°

# åœ¨é€²è¡Œæ•¸æ“šåˆ†ææ•ˆèƒ½å„ªåŒ–æ™‚ï¼Œè«‹æ³¨æ„ä»¥ä¸‹æœ€ä½³å¯¦è¸åŸå‰‡ï¼š

# 1. **è¨˜æ†¶é«”ç®¡ç†**
#    - ä½¿ç”¨é©ç•¶çš„æ•¸æ“šé¡å‹
#    - åŠæ™‚é‡‹æ”¾ä¸éœ€è¦çš„è³‡æº
#    - æ¡ç”¨åˆ†å¡Šè™•ç†å¤§æ•¸æ“š

# 2. **é‹ç®—å„ªåŒ–**
#    - å–„ç”¨å‘é‡åŒ–é‹ç®—
#    - é©ç•¶ä½¿ç”¨ä¸¦è¡Œè™•ç†
#    - é¿å…ä¸å¿…è¦çš„è¨ˆç®—

# 3. **ç¨‹å¼ç¢¼å„ªåŒ–**
#    - ä½¿ç”¨é«˜æ•ˆçš„æ•¸æ“šçµæ§‹
#    - æ¡ç”¨å„ªåŒ–çš„ç®—æ³•
#    - é¿å…é‡è¤‡è¨ˆç®—

# 4. **æ•ˆèƒ½ç›£æ§**
#    - å®šæœŸç›£æ§è³‡æºä½¿ç”¨
#    - è­˜åˆ¥æ•ˆèƒ½ç“¶é ¸
#    - åŠæ™‚é€²è¡Œå„ªåŒ–

# %% [markdown]
# ## 6. ç¸½çµ

# æœ¬èª²ç¨‹ä»‹ç´¹äº†æ•¸æ“šåˆ†ææ•ˆèƒ½å„ªåŒ–çš„æ ¸å¿ƒæ¦‚å¿µï¼š

# - **è¨˜æ†¶é«”å„ªåŒ–**ï¼šæœ‰æ•ˆç®¡ç†è¨˜æ†¶é«”è³‡æº
# - **é‹ç®—åŠ é€Ÿ**ï¼šæå‡è¨ˆç®—æ•ˆèƒ½
# - **ç¨‹å¼ç¢¼å„ªåŒ–**ï¼šæ”¹é€²ç¨‹å¼ç¢¼å“è³ª
# - **æ•ˆèƒ½ç›£æ§**ï¼šè¿½è¹¤è³‡æºä½¿ç”¨
# - **æœ€ä½³å¯¦è¸**ï¼šéµå¾ªå„ªåŒ–åŸå‰‡ 