# %% [markdown]
## ğŸ“˜ M2.5 Pandas åŸºç¤è³‡æ–™è½‰æ›

æœ¬æ•™å­¸å°‡ä»‹ç´¹ Pandas ä¸­åŸºæœ¬çš„è³‡æ–™è½‰æ›æŠ€è¡“ï¼ŒåŒ…æ‹¬æ•¸æ“šé¡å‹è½‰æ›ã€æ ¼å¼èª¿æ•´ä»¥åŠç°¡å–®è¨ˆç®—ã€‚é€™äº›æ“ä½œæ˜¯æ•¸æ“šè™•ç†éç¨‹ä¸­çš„åŸºæœ¬æŠ€èƒ½ï¼Œæœ‰åŠ©æ–¼æº–å‚™æ›´é©åˆåˆ†æçš„æ•¸æ“šã€‚

# %% [markdown]
### ğŸ¯ æ•™å­¸ç›®æ¨™

- ğŸ”„ æŒæ¡æ•¸æ“šé¡å‹è½‰æ›çš„åŸºæœ¬æ–¹æ³•
- ğŸ§® å­¸ç¿’åœ¨ DataFrame ä¸­é€²è¡Œç°¡å–®è¨ˆç®—
- ğŸ“… äº†è§£æ—¥æœŸå’Œæ™‚é–“æ•¸æ“šçš„è™•ç†æŠ€å·§
- ğŸ”¢ æŒæ¡æ–‡æœ¬å’Œåˆ†é¡æ•¸æ“šçš„è½‰æ›æ–¹æ³•

# %%
### ğŸ§° ç’°å¢ƒè¨­ç½®

# %%
import numpy as np
import pandas as pd

# è¨­ç½®é¡¯ç¤ºé¸é …
pd.set_option('display.max_rows', 10)
pd.set_option('display.max_columns', 10)
pd.set_option('display.width', 80)
pd.set_option('display.precision', 2)
pd.set_option('display.float_format', lambda x: f'{x:.2f}' if abs(x) < 1000 else f'{x:.0f}')

# %% [markdown]
# **è§£èªª**ï¼š
# - å°å…¥ `numpy` å’Œ `pandas` æ˜¯æ•¸æ“šè™•ç†çš„åŸºç¤ï¼Œ`matplotlib.pyplot` ç”¨æ–¼è¦–è¦ºåŒ–ï¼Œ`datetime` ç”¨æ–¼è™•ç†æ—¥æœŸæ™‚é–“
# - `display.max_rows` å’Œ `display.max_columns` è¨­å®šäº† DataFrame é¡¯ç¤ºçš„æœ€å¤§è¡Œå’Œåˆ—æ•¸ï¼Œé¿å…è¼¸å‡ºéé•·
# - `display.width` æ§åˆ¶è¼¸å‡ºå¯¬åº¦ï¼Œé©åˆåœ¨ä¸åŒé¡¯ç¤ºè¨­å‚™ä¸ŠæŸ¥çœ‹
# - `display.precision` è¨­å®šäº†æµ®é»æ•¸çš„é è¨­é¡¯ç¤ºç²¾åº¦
# - `display.float_format` ä½¿ç”¨ lambda å‡½æ•¸è‡ªå®šç¾©æµ®é»æ•¸é¡¯ç¤ºï¼šå°æ•¸å€¼ä¿ç•™å…©ä½å°æ•¸ï¼Œå¤§å€¼é¡¯ç¤ºç‚ºæ•´æ•¸
# - é€™äº›è¨­ç½®å°å¯¦éš›æ•¸æ“šä¸ç”¢ç”Ÿå½±éŸ¿ï¼Œåƒ…æ”¹è®Šé¡¯ç¤ºæ–¹å¼ï¼Œæœ‰åŠ©æ–¼æé«˜è¼¸å‡ºå¯è®€æ€§

# %% [markdown]
# ## ğŸ“Š 2. Pandas ä¸­çš„åŸºæœ¬æ•¸æ“šå‹æ…‹

# %% [markdown]
# ### 2.1 èªè­˜ Pandas çš„æ•¸æ“šå‹æ…‹é«”ç³»
#
# **å­¸ç¿’è¦é»**ï¼š
# - äº†è§£ Pandas æ”¯æ´çš„ä¸»è¦æ•¸æ“šå‹æ…‹åŠå…¶ç”¨é€”
# - å­¸ç¿’å¦‚ä½•æŸ¥çœ‹ DataFrame ä¸­å„åˆ—çš„æ•¸æ“šå‹æ…‹
# - æŒæ¡ DataFrame æ•¸æ“šé¡å‹çš„è©³ç´°ä¿¡æ¯ç²å–æ–¹æ³•
#
# **æ‡‰ç”¨å ´åŸŸ**ï¼š
# - æ•¸æ“šæ¢ç´¢èˆ‡åˆæ­¥åˆ†æ
# - è³‡æ–™åº«è¡¨æ ¼çµæ§‹è¨­è¨ˆ
# - æ•¸æ“šè³ªé‡æª¢æŸ¥èˆ‡é©—è­‰

# %%
# å‰µå»ºä¸€å€‹åŒ…å«ä¸åŒæ•¸æ“šé¡å‹çš„ DataFrame
df = pd.DataFrame({
    'Integer': [1, 2, 3, 4, 5],
    'Float': [1.1, 2.2, 3.3, 4.4, 5.5],
    'String': ['a', 'b', 'c', 'd', 'e'],
    'Boolean': [True, False, True, False, True],
    'Date': pd.date_range('2023-01-01', periods=5),
    'Category': pd.Categorical(['A', 'B', 'A', 'C', 'B']),
    'Int_as_str': ['1', '2', '3', '4', '5'],
    'Mixed': [1, 'two', 3.0, True, '5']
})

# é¡¯ç¤º DataFrame
print("å…·æœ‰ä¸åŒæ•¸æ“šé¡å‹çš„ DataFrame:")
print(df)

# æª¢æŸ¥æ¯åˆ—çš„æ•¸æ“šé¡å‹
print("\nå„åˆ—çš„æ•¸æ“šé¡å‹:")
print(df.dtypes)

# ç²å–è©³ç´°çš„æ•¸æ“šé¡å‹ä¿¡æ¯
print("\næ›´è©³ç´°çš„æ•¸æ“šé¡å‹ä¿¡æ¯:")
print(df.info())

# %% [markdown]
# **è§£èªª**ï¼š
# - DataFrame è‡ªå‹•ç‚ºæ¯åˆ—é¸æ“‡é©ç•¶çš„æ•¸æ“šé¡å‹ï¼šæ•´æ•¸ã€æµ®é»æ•¸ã€å­—ç¬¦ä¸²(object)ã€æ—¥æœŸæ™‚é–“ç­‰
# - `dtypes` å±¬æ€§é¡¯ç¤ºæ¯åˆ—çš„æ•¸æ“šé¡å‹ï¼Œæ˜¯æª¢æŸ¥å’Œç¢ºèªæ•¸æ“šé¡å‹çš„å¿«é€Ÿæ–¹æ³•
# - `info()` æ–¹æ³•æä¾›æ›´è©³ç´°çš„ä¿¡æ¯ï¼ŒåŒ…æ‹¬éç©ºå€¼æ•¸é‡ã€æ•¸æ“šé¡å‹å’Œå…§å­˜ä½¿ç”¨
# - æ³¨æ„ `Int_as_str` åˆ—å­˜å„²çš„æ˜¯æ•¸å­—å­—ç¬¦ä¸²ï¼ŒPandas å°‡å…¶è­˜åˆ¥ç‚º object é¡å‹
# - `Mixed` åˆ—åŒ…å«ä¸åŒé¡å‹çš„æ•¸æ“šï¼ŒPandas è‡ªå‹•é¸æ“‡èƒ½å®¹ç´æ‰€æœ‰å€¼çš„æœ€é€šç”¨é¡å‹ (object)
# - é¡åˆ¥å‹æ•¸æ“šåœ¨è™•ç†æœ‰é™é›†åˆçš„å€¼æ™‚éå¸¸é«˜æ•ˆï¼Œå¦‚é€™è£¡çš„ 'A'ã€'B'ã€'C'
# - äº†è§£æ•¸æ“šé¡å‹æ˜¯æ­£ç¢ºè™•ç†å’Œåˆ†ææ•¸æ“šçš„ç¬¬ä¸€æ­¥ï¼Œå°¤å…¶åœ¨è™•ç†å¤§å‹æ•¸æ“šé›†æ™‚

# %% [markdown]
# ### 2.2 å¸¸è¦‹çš„ Pandas æ•¸æ“šå‹æ…‹
#
# **å­¸ç¿’è¦é»**ï¼š
# - æŒæ¡ Pandas ä¸­å„ç¨®æ•¸æ“šé¡å‹çš„ç‰¹æ€§èˆ‡ç”¨é€”
# - äº†è§£ Python åŸç”Ÿé¡å‹èˆ‡ Pandas é¡å‹çš„å°æ‡‰é—œä¿‚
# - å­¸ç¿’å¦‚ä½•å‰µå»ºå’Œè­˜åˆ¥ä¸åŒé¡å‹çš„ Series
#
# **æ‡‰ç”¨å ´åŸŸ**ï¼š
# - æ•¸æ“šçµæ§‹è¨­è¨ˆèˆ‡å…§å­˜å„ªåŒ–
# - ç‰¹æ®Šæ•¸æ“šé¡å‹çš„è™•ç†ï¼ˆå¦‚æ™‚é–“åºåˆ—ã€åˆ†é¡æ•¸æ“šï¼‰
# - æ•¸æ“šè¼¸å…¥é©—è­‰èˆ‡æ¸…æ´—

# %% [markdown]
# Pandas ä¸­çš„å¸¸è¦‹æ•¸æ“šå‹æ…‹åŒ…æ‹¬ï¼š
#
# | æ•¸æ“šå‹æ…‹ | æè¿° | Python ç­‰åƒ¹å‹æ…‹ |
# |----------|------|---------------|
# | `int64`, `int32`, ... | æ•´æ•¸å‹ | `int` |
# | `float64`, `float32`, ... | æµ®é»æ•¸å‹ | `float` |
# | `bool` | å¸ƒçˆ¾å‹ | `bool` |
# | `object` | ç‰©ä»¶å‹ï¼Œé€šå¸¸ç”¨æ–¼å­—ç¬¦ä¸²æˆ–æ··åˆå‹æ•¸æ“š | `str`, ä»»æ„ Python ç‰©ä»¶ |
# | `datetime64[ns]` | æ—¥æœŸæ™‚é–“å‹ | `datetime.datetime` |
# | `timedelta64[ns]` | æ™‚é–“å·®ç•°å‹ | `datetime.timedelta` |
# | `category` | åˆ†é¡å‹ | ç„¡ç›´æ¥ç­‰åƒ¹ |
# | `Int64`, `Float64`, ... | å¯ç©ºï¼ˆnullableï¼‰æ•´æ•¸/æµ®é»æ•¸å‹ | ç„¡ç›´æ¥ç­‰åƒ¹ |
# | `string` | å­—ç¬¦ä¸²å‹ (pandas 1.0+) | `str` |

# %%
# å‰µå»ºå„ç¨®æ•¸æ“šé¡å‹çš„ Series
series_examples = {
    'Int64': pd.Series([1, 2, 3, None], dtype='Int64'),
    'float64': pd.Series([1.1, 2.2, 3.3, np.nan]),
    'bool': pd.Series([True, False, True, False]),
    'object': pd.Series(['a', 'b', None, 'd']),
    'datetime64[ns]': pd.Series(pd.date_range('2023-01-01', periods=4)),
    'timedelta64[ns]': pd.Series([pd.Timedelta(days=i) for i in range(4)]),
    'category': pd.Series(['A', 'B', 'A', 'B']).astype('category'),
    'string': pd.Series(['a', 'b', None, 'd']).astype('string')
}

# é¡¯ç¤ºå„æ•¸æ“šé¡å‹çš„ Series åŠå…¶é¡å‹
for name, series in series_examples.items():
    print(f"\n{name} å‹æ…‹ Series:")
    print(series)
    print(f"å‹æ…‹: {series.dtype}")

# %% [markdown]
# **è§£èªª**ï¼š
# - `Int64` å’Œå…¶ä»–å¤§å¯«é–‹é ­çš„æ•´æ•¸/æµ®é»æ•¸å‹æ˜¯ Pandas çš„æ“´å……é¡å‹ï¼Œæ”¯æŒ NA å€¼ï¼ˆå‚³çµ±æ•´æ•¸å‹ä¸æ”¯æŒç¼ºå¤±å€¼ï¼‰
# - `object` é¡å‹æ˜¯ Python å°è±¡çš„å®¹å™¨ï¼Œé©ç”¨æ–¼å­—ç¬¦ä¸²å’Œæ··åˆé¡å‹ï¼Œä½†æ•ˆç‡è¼ƒä½
# - `category` é¡å‹é©ç”¨æ–¼å…·æœ‰æœ‰é™ç¯„åœå€¼çš„æ•¸æ“šï¼ˆå¦‚æ€§åˆ¥ã€åœ‹å®¶ï¼‰ï¼Œå¯é¡¯è‘—ç¯€çœè¨˜æ†¶é«”
# - `datetime64[ns]` æä¾›äº†å¼·å¤§çš„æ—¥æœŸæ™‚é–“åŠŸèƒ½ï¼ŒåŒ…æ‹¬æ™‚å€è™•ç†ã€æ—¥æœŸè¨ˆç®—ç­‰
# - `timedelta64[ns]` è¡¨ç¤ºæ™‚é–“å·®ç•°ï¼Œå¸¸ç”¨æ–¼æ™‚é–“åºåˆ—åˆ†æ
# - è¼ƒæ–°çš„ `string` é¡å‹æä¾›æ¯” `object` æ›´é«˜æ•ˆçš„å­—ç¬¦ä¸²è™•ç†
# - åœ¨å‰µå»º Series æˆ– DataFrame æ™‚ï¼Œå¯ä»¥é€šé `dtype` åƒæ•¸æˆ– `astype()` æ–¹æ³•æŒ‡å®šæˆ–è½‰æ›é¡å‹
# - é¸æ“‡åˆé©çš„æ•¸æ“šé¡å‹ä¸åƒ…å½±éŸ¿å…§å­˜ä½¿ç”¨ï¼Œé‚„å½±éŸ¿æ“ä½œæ•ˆç‡å’Œå¯ç”¨çš„åŠŸèƒ½

# %% [markdown]
# ### 2.3 æ•¸æ“šå‹æ…‹çš„å…§å­˜ä½¿ç”¨
#
# **å­¸ç¿’è¦é»**ï¼š
# - äº†è§£ä¸åŒæ•¸æ“šé¡å‹çš„å…§å­˜æ¶ˆè€—å·®ç•°
# - æŒæ¡å¦‚ä½•æ¸¬é‡æ•¸æ“šçµæ§‹çš„å…§å­˜ä½¿ç”¨æƒ…æ³
# - å­¸ç¿’å¦‚ä½•é¸æ“‡å…§å­˜æ•ˆç‡é«˜çš„æ•¸æ“šé¡å‹
#
# **æ‡‰ç”¨å ´åŸŸ**ï¼š
# - å¤§å‹æ•¸æ“šé›†çš„å…§å­˜å„ªåŒ–
# - è³‡æºå—é™ç’°å¢ƒä¸‹çš„æ•¸æ“šè™•ç†
# - é«˜æ€§èƒ½æ•¸æ“šåˆ†ææ‡‰ç”¨é–‹ç™¼

# %%
# å‰µå»ºä¸€å€‹å¤§å‹ DataFrame æ¸¬è©¦ä¸åŒæ•¸æ“šé¡å‹çš„å…§å­˜ä½¿ç”¨
n = 100_000
df_memory = pd.DataFrame({
    'int64': np.random.randint(0, 100, n),
    'int32': np.random.randint(0, 100, n).astype('int32'),
    'int16': np.random.randint(0, 100, n).astype('int16'),
    'float64': np.random.rand(n),
    'float32': np.random.rand(n).astype('float32'),
    'object': [f'str_{i % 100}' for i in range(n)],
    'category': pd.Series([f'cat_{i % 10}' for i in range(n)]).astype('category'),
    'bool': np.random.choice([True, False], n),
    'datetime64': pd.date_range('2023-01-01', periods=n)
})

# æª¢æŸ¥å…§å­˜ä½¿ç”¨
print("å„æ•¸æ“šé¡å‹çš„å…§å­˜ä½¿ç”¨æƒ…æ³:")
memory_usage = df_memory.memory_usage(deep=True) / 1024 / 1024  # è½‰æ›ç‚º MB
print(memory_usage)
print(f"ç¸½å…§å­˜ä½¿ç”¨: {memory_usage.sum():.2f} MB")

# å¯è¦–åŒ–å…§å­˜ä½¿ç”¨æƒ…æ³
plt.figure(figsize=(12, 6))
memory_usage[:-1].plot(kind='bar')  # ä¸åŒ…æ‹¬ 'Index'
plt.title('ä¸åŒæ•¸æ“šé¡å‹çš„å…§å­˜ä½¿ç”¨ (MB)')
plt.ylabel('å…§å­˜ä½¿ç”¨ (MB)')
plt.grid(axis='y')
plt.tight_layout()
plt.show()

# %% [markdown]
# **è§£èªª**ï¼š
# - å…§å­˜ä½¿ç”¨é‡é¡¯è‘—å—æ•¸æ“šé¡å‹å½±éŸ¿ï¼š`int16` æ¯” `int64` ä½¿ç”¨æ›´å°‘çš„å…§å­˜ï¼Œ`float32` æ¯” `float64` æ›´ç¯€çœ
# - `object` é¡å‹å ç”¨æœ€å¤šå…§å­˜ï¼Œå› ç‚ºå­˜å„²çš„æ˜¯ Python å°è±¡å¼•ç”¨å’Œå­—ç¬¦ä¸²æœ¬èº«
# - `category` é¡å‹éå¸¸é«˜æ•ˆï¼Œå³ä½¿æœ‰ 10 è¬æ¢è¨˜éŒ„ä½†åªæœ‰ 10 å€‹ä¸åŒå€¼ï¼Œå…§å­˜ä½¿ç”¨é‡æ¥µä½
# - `bool` é¡å‹éå¸¸ç¯€çœç©ºé–“ï¼Œåƒ…éœ€ 1 ä½å…ƒå­˜å„²æ¯å€‹å€¼
# - `datetime64` é¡å‹å„˜ç®¡åŠŸèƒ½å¼·å¤§ï¼Œä½†å…§å­˜ä½¿ç”¨é‡å¯èƒ½è¼ƒå¤§
# - ä½¿ç”¨ `memory_usage(deep=True)` å¯ç²å¾—åŒ…æ‹¬å°è±¡å¯¦éš›å¤§å°åœ¨å…§çš„æ›´æº–ç¢ºå…§å­˜ä½¿ç”¨ä¼°è¨ˆ
# - åœ¨è™•ç†å¤§å‹æ•¸æ“šé›†æ™‚ï¼Œé©ç•¶çš„æ•¸æ“šé¡å‹é¸æ“‡å¯èƒ½ç¯€çœæ•¸ GB çš„å…§å­˜
# - é€™ç¨®å…§å­˜ç¯€çœä¸åƒ…å¯æ¸›å°‘è³‡æºä½¿ç”¨ï¼Œé‚„èƒ½æé«˜è¨ˆç®—é€Ÿåº¦ï¼Œå°¤å…¶åœ¨è¨˜æ†¶é«”å—é™çš„ç’°å¢ƒä¸­

# %% [markdown]
# ## ğŸ” 3. æ•¸æ“šé¡å‹æª¢æŸ¥èˆ‡è½‰æ›
#
# **å­¸ç¿’è¦é»**ï¼š
# - æŒæ¡æª¢æŸ¥ DataFrame ä¸­æ•¸æ“šé¡å‹çš„ä¸åŒæ–¹æ³•
# - äº†è§£åŸºæœ¬é¡å‹è½‰æ›èˆ‡é€²éšè½‰æ›æŠ€å·§
# - å­¸ç¿’å®‰å…¨è™•ç†é¡å‹è½‰æ›ä¸­çš„éŒ¯èª¤èˆ‡ç•°å¸¸
#
# **æ‡‰ç”¨å ´åŸŸ**ï¼š
# - æ•¸æ“šæ¸…æ´—èˆ‡é è™•ç†æµç¨‹
# - API æ¥æ”¶æ•¸æ“šçš„æ ¼å¼æ¨™æº–åŒ–
# - æ©Ÿå™¨å­¸ç¿’æ¨¡å‹å‰çš„æ•¸æ“šæº–å‚™

# %% [markdown]
# ### 3.1 æª¢æŸ¥æ•¸æ“šé¡å‹

# %%
# æª¢æŸ¥æ•¸æ“šé¡å‹çš„æ–¹æ³•
sample_df = pd.DataFrame({
    'A': [1, 2, 3],
    'B': [1.1, 2.2, 3.3],
    'C': ['x', 'y', 'z'],
    'D': pd.date_range('2023-01-01', periods=3)
})

print("DataFrame æ•´é«”æ•¸æ“šé¡å‹:")
print(sample_df.dtypes)

print("\næª¢æŸ¥å–®ä¸€åˆ—çš„æ•¸æ“šé¡å‹:")
print(sample_df['A'].dtype)

print("\næª¢æŸ¥æ˜¯å¦ç‚ºç‰¹å®šæ•¸æ“šé¡å‹:")
print(f"A åˆ—æ˜¯å¦ç‚ºæ•´æ•¸å‹: {pd.api.types.is_integer_dtype(sample_df['A'])}")
print(f"B åˆ—æ˜¯å¦ç‚ºæµ®é»æ•¸å‹: {pd.api.types.is_float_dtype(sample_df['B'])}")
print(f"C åˆ—æ˜¯å¦ç‚ºå­—ç¬¦ä¸²å‹: {pd.api.types.is_string_dtype(sample_df['C'])}")
print(f"C åˆ—æ˜¯å¦ç‚ºç‰©ä»¶å‹: {pd.api.types.is_object_dtype(sample_df['C'])}")
print(f"D åˆ—æ˜¯å¦ç‚ºæ—¥æœŸæ™‚é–“å‹: {pd.api.types.is_datetime64_dtype(sample_df['D'])}")

# %% [markdown]
# **è§£èªª**ï¼š
# - `dtypes` å±¬æ€§æä¾› DataFrame æ‰€æœ‰åˆ—çš„æ•¸æ“šé¡å‹æ¦‚è¦½
# - å¯ä»¥é€šéç´¢å¼•å¾Œçš„ `.dtype` å±¬æ€§æŸ¥çœ‹å–®ä¸€åˆ—çš„æ•¸æ“šé¡å‹
# - Pandas æä¾›äº† `pd.api.types` æ¨¡çµ„ç”¨æ–¼é¡å‹æª¢æŸ¥ï¼Œå«å¤šç¨® `is_*_dtype()` å‡½æ•¸
# - æ³¨æ„ `object` å‹åˆ¥å’Œ `string` å‹åˆ¥çš„å€åˆ¥ï¼šå¤§å¤šæ•¸å­—ç¬¦ä¸²åœ¨èˆŠç‰ˆ Pandas ä¸­æ˜¯ `object` å‹åˆ¥
# - é¡å‹æª¢æŸ¥åœ¨æ•¸æ“šè™•ç†æµç¨‹ä¸­è‡³é—œé‡è¦ï¼Œæœ‰åŠ©æ–¼ç™¼ç¾æ½›åœ¨å•é¡Œå’Œå„ªåŒ–æ©Ÿæœƒ
# - å°æ–¼è¤‡é›œæ•¸æ“šé›†ï¼Œå»ºè­°åœ¨é€²è¡Œæ“ä½œå‰æª¢æŸ¥é—œéµæ¬„ä½çš„æ•¸æ“šé¡å‹
# - åœ¨æ•¸æ“šå°å…¥å¾Œå’Œé¡å‹è½‰æ›å‰çš„é¡å‹æª¢æŸ¥å°¤ç‚ºé‡è¦

# %% [markdown]
# ### 3.2 åŸºæœ¬é¡å‹è½‰æ›

# %%
# åŸºæœ¬é¡å‹è½‰æ›ç¤ºä¾‹
conversion_df = pd.DataFrame({
    'string_int': ['1', '2', '3', '4'],
    'string_float': ['1.1', '2.2', '3.3', '4.4'],
    'float_values': [1.1, 2.2, 3.0, 4.0],
    'mixed_strings': ['100', '200', 'NA', '400']
})

print("åŸå§‹ DataFrame:")
print(conversion_df)
print("\nåŸå§‹æ•¸æ“šé¡å‹:")
print(conversion_df.dtypes)

# ä½¿ç”¨ astype() é€²è¡Œé¡å‹è½‰æ›
print("\nè½‰æ›å¾Œçš„ DataFrame:")
try:
    conversion_df['string_int'] = conversion_df['string_int'].astype('int')
    conversion_df['string_float'] = conversion_df['string_float'].astype('float')
    conversion_df['float_values'] = conversion_df['float_values'].astype('int')
    # ä¸‹é¢é€™è¡Œæœƒç”¢ç”ŸéŒ¯èª¤
    # conversion_df['mixed_strings'] = conversion_df['mixed_strings'].astype('int')
    print(conversion_df)
    print("\nè½‰æ›å¾Œçš„æ•¸æ“šé¡å‹:")
    print(conversion_df.dtypes)
except ValueError as e:
    print(f"è½‰æ›éŒ¯èª¤: {e}")

# %% [markdown]
# **è§£èªª**ï¼š
# - `astype()` æ–¹æ³•æ˜¯ Pandas ä¸­æœ€ç›´æ¥çš„é¡å‹è½‰æ›æ–¹å¼
# - è½‰æ›å‰å¾ŒæŸ¥çœ‹æ•¸æ“šé¡å‹å¯ç¢ºèªè½‰æ›æ˜¯å¦æˆåŠŸ
# - å­—ç¬¦ä¸²å½¢å¼çš„æ•¸å­—å¯ä»¥è½‰æ›ç‚ºç›¸æ‡‰çš„æ•¸å€¼é¡å‹ï¼Œå¦‚ `'1'` â†’ `1` å’Œ `'1.1'` â†’ `1.1`
# - æµ®é»æ•¸å¯è½‰æ›ç‚ºæ•´æ•¸ï¼Œä½†æœƒæˆªæ–·å°æ•¸éƒ¨åˆ†è€Œéå››æ¨äº”å…¥
# - å«æœ‰éæ•¸å€¼å­—ç¬¦çš„å­—ç¬¦ä¸²ï¼ˆå¦‚ `'NA'`ï¼‰å˜—è©¦è½‰æ›ç‚ºæ•¸å€¼æœƒå°è‡´ `ValueError`
# - éŒ¯èª¤è™•ç†æ˜¯é¡å‹è½‰æ›ä¸­çš„é‡è¦ç’°ç¯€ï¼Œæ‡‰ä½¿ç”¨ try-except æ•ç²ä¸¦è™•ç†è½‰æ›ç•°å¸¸
# - åœ¨ç”Ÿç”¢ç’°å¢ƒä¸­ï¼Œå»ºè­°å§‹çµ‚æª¢æŸ¥é¡å‹è½‰æ›çš„å¯è¡Œæ€§ï¼Œä¸¦æ¡å–é©ç•¶çš„éŒ¯èª¤è™•ç†ç­–ç•¥

# %% [markdown]
# ### 3.3 é€²éšé¡å‹è½‰æ›

# %%
# å®‰å…¨çš„é¡å‹è½‰æ›æ–¹æ³•
advanced_df = pd.DataFrame({
    'mixed_ints': ['1', '2', 'three', '4'],
    'mixed_floats': ['1.1', '2.2', 'N/A', '4.4'],
    'mixed_bools': ['True', 'False', 'yes', 'no'],
    'dates': ['2023-01-01', '01/02/2023', 'not a date', '2023-04-04']
})

print("åŸå§‹æ•¸æ“š:")
print(advanced_df)

# ä½¿ç”¨ to_numeric() é€²è¡Œå®‰å…¨æ•¸å€¼è½‰æ›
print("\nå®‰å…¨è½‰æ›ç‚ºæ•¸å€¼å‹:")
print("1. ä½¿ç”¨ errors='coerce' (è½‰æ›éŒ¯èª¤å€¼ç‚º NaN):")
advanced_df['numeric_ints'] = pd.to_numeric(advanced_df['mixed_ints'], errors='coerce')
advanced_df['numeric_floats'] = pd.to_numeric(advanced_df['mixed_floats'], errors='coerce')

print("2. ä½¿ç”¨ errors='ignore' (ä¿ç•™åŸå§‹å€¼):")
# ä¿æŒåŸæ¨£ï¼Œåƒ…å˜—è©¦è½‰æ›
original_type = advanced_df['mixed_ints'].copy()
advanced_df['numeric_keep'] = pd.to_numeric(advanced_df['mixed_ints'], errors='ignore')
print(f"è½‰æ›å‰é¡å‹: {original_type.dtype}, è½‰æ›å¾Œé¡å‹: {advanced_df['numeric_keep'].dtype}")

# ä½¿ç”¨ to_datetime() è½‰æ›æ—¥æœŸ
print("\nè½‰æ›ç‚ºæ—¥æœŸæ™‚é–“å‹:")
advanced_df['dates_converted'] = pd.to_datetime(advanced_df['dates'], errors='coerce')

# ä½¿ç”¨ to_timedelta() ç¤ºä¾‹
print("\nè½‰æ›ç‚ºæ™‚é–“å·®ç•°å‹:")
time_diff = pd.DataFrame({
    'time_strings': ['1 day', '2 hours', 'invalid', '5 minutes']
})
time_diff['timedeltas'] = pd.to_timedelta(time_diff['time_strings'], errors='coerce')
print(time_diff)

# è½‰æ›ç‚ºå¸ƒçˆ¾å‹
print("\nè½‰æ›ç‚ºå¸ƒçˆ¾å‹:")
# è‡ªå®šç¾©è½‰æ›å‡½æ•¸
def convert_to_bool(val):
    if isinstance(val, str):
        val = val.lower().strip()
        if val in ('true', 'yes', 'y', '1'):
            return True
        elif val in ('false', 'no', 'n', '0'):
            return False
    return pd.NA  # ä½¿ç”¨ Pandas çš„ NA å€¼è¡¨ç¤ºç„¡æ³•è½‰æ›

advanced_df['bool_converted'] = advanced_df['mixed_bools'].apply(convert_to_bool)
print(advanced_df)

# %% [markdown]
# **è§£èªª**ï¼š
# - Pandas æä¾›å°ˆç”¨çš„è½‰æ›å‡½æ•¸è™•ç†å¸¸è¦‹æ•¸æ“šé¡å‹ï¼š
#   - `pd.to_numeric()` è½‰æ›ç‚ºæ•¸å€¼å‹
#   - `pd.to_datetime()` è½‰æ›ç‚ºæ—¥æœŸæ™‚é–“å‹
#   - `pd.to_timedelta()` è½‰æ›ç‚ºæ™‚é–“å·®ç•°å‹
# - é€™äº›å‡½æ•¸æ¯” `astype()` æ›´éˆæ´»ï¼Œæä¾›éŒ¯èª¤è™•ç†åƒæ•¸ï¼š
#   - `errors='raise'`: è½‰æ›å¤±æ•—æ™‚æ‹‹å‡ºç•°å¸¸ï¼ˆé è¨­è¡Œç‚ºï¼‰
#   - `errors='coerce'`: è½‰æ›å¤±æ•—æ™‚å°‡å€¼è¨­ç‚º NaN
#   - `errors='ignore'`: è½‰æ›å¤±æ•—æ™‚ä¿ç•™åŸå§‹å€¼
# - å°æ–¼è¤‡é›œçš„è½‰æ›é‚è¼¯ï¼ˆå¦‚å¸ƒçˆ¾å€¼ï¼‰ï¼Œå¯ä½¿ç”¨ `apply()` æ‡‰ç”¨è‡ªå®šç¾©è½‰æ›å‡½æ•¸
# - `convert_to_bool` å‡½æ•¸å±•ç¤ºäº†è™•ç†å¤šç¨®æ ¼å¼å¸ƒçˆ¾å€¼çš„éˆæ´»æ–¹å¼ï¼Œå¦‚ 'yes'/'no'ã€'true'/'false'
# - ä½¿ç”¨ `pd.NA` æ¨™è¨˜ç„¡æ³•è½‰æ›çš„å€¼ï¼Œé€™æ˜¯ Pandas çš„ç¼ºå¤±å€¼è¡¨ç¤ºæ³•ï¼Œé©ç”¨æ–¼æ‰€æœ‰é¡å‹
# - é«˜ç´šè½‰æ›å‡½æ•¸èƒ½è™•ç†å¤šç¨®æ ¼å¼å’Œæ–¹è¨€ï¼Œå¦‚ `to_datetime()` å¯è­˜åˆ¥å¤šç¨®æ—¥æœŸè¡¨ç¤ºæ³•
# - å®‰å…¨çš„é¡å‹è½‰æ›æ˜¯è³‡æ–™æ¸…æ´—æµç¨‹çš„é—œéµæ­¥é©Ÿï¼Œæœ‰åŠ©æ–¼æº–å‚™ä¸€è‡´ã€å¯é çš„æ•¸æ“šé›†

# %% [markdown]
# ### 3.4 æ‰¹é‡é¡å‹è½‰æ›èˆ‡å…§å­˜å„ªåŒ–

# %%
# å‰µå»ºä¸€å€‹æ¨¡æ“¬æ•¸æ“šé›†
import numpy as np
np.random.seed(42)
n_rows = 100_000

large_df = pd.DataFrame({
    'id': range(n_rows),
    'int_col': np.random.randint(0, 100, n_rows),
    'float_col': np.random.rand(n_rows),
    'str_col': [f'str_{i % 100}' for i in range(n_rows)],
    'category_col': [f'cat_{i % 5}' for i in range(n_rows)]
})

# æª¢æŸ¥åˆå§‹å…§å­˜ä½¿ç”¨
print("åˆå§‹ DataFrame å…§å­˜ä½¿ç”¨:")
print(large_df.memory_usage(deep=True) / 1024 / 1024, "MB")
print(f"ç¸½è¨ˆ: {large_df.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB")

# æ‰¹é‡å„ªåŒ–æ•¸æ“šé¡å‹
optimized_df = large_df.copy()

# æ•´æ•¸åˆ—å„ªåŒ–
int_cols = ['id', 'int_col']
for col in int_cols:
    col_min, col_max = optimized_df[col].min(), optimized_df[col].max()
    if col_min >= 0:
        if col_max < 2**8:
            optimized_df[col] = optimized_df[col].astype('uint8')
        elif col_max < 2**16:
            optimized_df[col] = optimized_df[col].astype('uint16')
        elif col_max < 2**32:
            optimized_df[col] = optimized_df[col].astype('uint32')
    else:
        if col_min > -2**7 and col_max < 2**7:
            optimized_df[col] = optimized_df[col].astype('int8')
        elif col_min > -2**15 and col_max < 2**15:
            optimized_df[col] = optimized_df[col].astype('int16')
        elif col_min > -2**31 and col_max < 2**31:
            optimized_df[col] = optimized_df[col].astype('int32')

# æµ®é»åˆ—è½‰æ›ç‚ºè¼ƒå°ç²¾åº¦
optimized_df['float_col'] = optimized_df['float_col'].astype('float32')

# å­—ç¬¦ä¸²åˆ—è½‰æ›ç‚ºé¡åˆ¥å‹
optimized_df['str_col'] = optimized_df['str_col'].astype('category')
optimized_df['category_col'] = optimized_df['category_col'].astype('category')

# æŸ¥çœ‹å„ªåŒ–å¾Œçš„å…§å­˜ä½¿ç”¨
print("\nå„ªåŒ–å¾Œ DataFrame å…§å­˜ä½¿ç”¨:")
print(optimized_df.memory_usage(deep=True) / 1024 / 1024, "MB")
print(f"ç¸½è¨ˆ: {optimized_df.memory_usage(deep=True).sum() / 1024 / 1024:.2f} MB")

# è¨ˆç®—ç¯€çœçš„å…§å­˜æ¯”ä¾‹
orig_mem = large_df.memory_usage(deep=True).sum() / 1024 / 1024
opt_mem = optimized_df.memory_usage(deep=True).sum() / 1024 / 1024
savings = (1 - opt_mem / orig_mem) * 100
print(f"\nå…§å­˜ç¯€çœ: {savings:.2f}%")

# %% [markdown]
# **è§£èªª**ï¼š
# - å¤§å‹æ•¸æ“šé›†çš„å…§å­˜å„ªåŒ–æ˜¯å¯¦éš›æ‡‰ç”¨ä¸­çš„é—œéµè€ƒé‡ï¼Œç‰¹åˆ¥æ˜¯åœ¨è³‡æºå—é™çš„ç’°å¢ƒä¸‹
# - æ‰¹é‡é¡å‹è½‰æ›ç­–ç•¥ä¸»è¦åŒ…æ‹¬ï¼š
#   - æ ¹æ“šæ•¸å€¼ç¯„åœå°‡æ•´æ•¸é™ç´šè‡³è¼ƒå°é¡å‹ï¼ˆå¦‚ int64 â†’ int8/int16/int32ï¼‰
#   - å°‡ç„¡ç¬¦è™Ÿæ•´æ•¸ä½¿ç”¨ uint é¡å‹ï¼ˆæ›´å¤§çš„æ­£æ•¸ç¯„åœï¼‰
#   - å°‡é›™ç²¾åº¦æµ®é»æ•¸é™ç‚ºå–®ç²¾åº¦æµ®é»æ•¸ï¼ˆfloat64 â†’ float32ï¼‰
#   - å°‡æœ‰é™å–å€¼çš„å­—ç¬¦ä¸²è½‰æ›ç‚ºé¡åˆ¥å‹ï¼ˆobject â†’ categoryï¼‰
# - æˆ‘å€‘å° DataFrame é€²è¡Œåˆ†æå’Œé¡å‹å„ªåŒ–å¾Œï¼Œå…§å­˜ä½¿ç”¨é¡¯è‘—é™ä½ï¼ˆé€šå¸¸å¯ç¯€çœ 30-80%ï¼‰
# - ä½¿ç”¨ `memory_usage(deep=True)` ç²å–çœŸå¯¦çš„å…§å­˜ä½¿ç”¨æƒ…æ³ï¼ŒåŒ…æ‹¬ object é¡å‹çš„å¯¦éš›å¤§å°
# - å°æ–¼æ•´æ•¸åˆ—ï¼Œå…ˆæª¢æŸ¥å€¼ç¯„åœå†é¸æ“‡æœ€ä½³é¡å‹æ˜¯ä¸€ç¨®å¸¸è¦‹çš„å„ªåŒ–æ¨¡å¼
# - ç‰¹åˆ¥æ³¨æ„ï¼Œéåº¦å„ªåŒ–å¯èƒ½å°è‡´æº¢å‡ºé¢¨éšªï¼Œå¦‚å€¼å¯èƒ½è¶…å‡º int16 ç¯„åœæ™‚æ‡‰è¬¹æ…ä½¿ç”¨
# - å»ºè­°åœ¨å„ªåŒ–å‰ä¿å­˜åŸå§‹ DataFrame å‚™ä»½ï¼Œä¸¦é©—è­‰è½‰æ›å¾Œçš„æ•¸æ“šå®Œæ•´æ€§
# - æ­¤ç¨®å„ªåŒ–å°æ–¼éœ€è¦åœ¨å…§å­˜ä¸­è™•ç†å¤§é‡æ•¸æ“šçš„æ‡‰ç”¨ï¼ˆå¦‚å¯¦æ™‚åˆ†æç³»çµ±ï¼‰å°¤å…¶é‡è¦

# %% [markdown]
# ## 4. æ•¸å€¼å‹æ•¸æ“šçš„è™•ç†

# %% [markdown]
# ### 4.1 æ•¸å€¼è³‡æ–™çš„ç²¾åº¦æ§åˆ¶

# %%
# å‰µå»ºæ•¸å€¼æ•¸æ“š
df_numeric = pd.DataFrame({
    'A': [1.23456789, 2.3456789, 3.456789, 4.56789, 5.6789],
    'B': [1234.5678, 2345.678, 3456.78, 4567.8, 5678],
    'C': [0.000123, 0.00234, 0.0345, 0.456, 5.67]
})
print("åŸå§‹æ•¸å€¼æ•¸æ“š:")
print(df_numeric)

# è¨­ç½®é¡¯ç¤ºç²¾åº¦
pd.set_option('display.precision', 2)
print("\nè¨­ç½®é¡¯ç¤ºç²¾åº¦å¾Œ:")
print(df_numeric)

# è¨­ç½®é¡¯ç¤ºæ ¼å¼ï¼ˆä¸æ”¹è®Šåº•å±¤æ•¸æ“šï¼‰
pd.set_option('display.float_format', lambda x: f'{x:.3f}')
print("\nè¨­ç½®é¡¯ç¤ºæ ¼å¼å¾Œ:")
print(df_numeric)

# å¯¦éš›å››æ¨äº”å…¥ï¼ˆæ”¹è®Šåº•å±¤æ•¸æ“šï¼‰
df_rounded = df_numeric.round(2)
print("\nå››æ¨äº”å…¥åˆ°å°æ•¸é»å¾Œ 2 ä½:")
print(df_rounded)

# å°ä¸åŒåˆ—ä½¿ç”¨ä¸åŒçš„ç²¾åº¦
df_multi_precision = df_numeric.round({'A': 3, 'B': 1, 'C': 4})
print("\nå°ä¸åŒåˆ—ä½¿ç”¨ä¸åŒçš„ç²¾åº¦:")
print(df_multi_precision)

# æ¢å¾©é»˜èªé¡¯ç¤ºè¨­ç½®
pd.reset_option('display.float_format')
pd.set_option('display.precision', 6)
print("\næ¢å¾©é»˜èªé¡¯ç¤ºè¨­ç½®å¾Œ:")
print(df_numeric)

# %% [markdown]
# ### 4.2 è™•ç†åƒåˆ†ä½å’Œç™¾åˆ†æ¯”

# %%
# å‰µå»ºç¤ºä¾‹æ•¸æ“š
df_format = pd.DataFrame({
    'Value': [1234.56, 2345.67, 3456.78, 4567.89, 5678.90],
    'Percentage': [0.1234, 0.2345, 0.3456, 0.4567, 0.5678],
    'Large_Number': [1234567, 2345678, 3456789, 4567890, 5678901]
})
print("åŸå§‹æ•¸æ“š:")
print(df_format)

# å°‡æ•¸å€¼è½‰æ›ç‚ºå¸¶åƒåˆ†ä½åˆ†éš”ç¬¦çš„å­—ç¬¦ä¸²
df_format['Value_Formatted'] = df_format['Value'].apply(lambda x: f'{x:,.2f}')
print("\nå¸¶åƒåˆ†ä½åˆ†éš”ç¬¦çš„å€¼:")
print(df_format['Value_Formatted'])

# å°‡æ•¸å€¼è½‰æ›ç‚ºç™¾åˆ†æ¯”
df_format['Percentage_Formatted'] = df_format['Percentage'].apply(lambda x: f'{x:.2%}')
print("\nç™¾åˆ†æ¯”æ ¼å¼:")
print(df_format['Percentage_Formatted'])

# å°‡å¤§æ•¸è½‰æ›ç‚ºK, M, Bæ ¼å¼
def format_large_number(num):
    if num >= 1_000_000_000:
        return f'{num/1_000_000_000:.2f}B'
    elif num >= 1_000_000:
        return f'{num/1_000_000:.2f}M'
    elif num >= 1_000:
        return f'{num/1_000:.2f}K'
    else:
        return f'{num:.2f}'

df_format['Large_Number_Formatted'] = df_format['Large_Number'].apply(format_large_number)
print("\nå¤§æ•¸æ ¼å¼ (K, M, B):")
print(df_format['Large_Number_Formatted'])

# åˆä½µé¡¯ç¤º
print("\næ ¼å¼åŒ–å¾Œçš„ DataFrame:")
print(df_format)

# %% [markdown]
# ### 4.3 è™•ç†è²¨å¹£å’Œæœƒè¨ˆæ ¼å¼

# %%
# å‰µå»ºç¤ºä¾‹è²¡å‹™æ•¸æ“š
df_finance = pd.DataFrame({
    'Revenue': [12345.67, 23456.78, -3456.78, 45678.90, 56789.01],
    'Expense': [9876.54, 8765.43, 7654.32, -6543.21, 5432.10],
    'Profit': [2469.13, 14691.35, -11111.10, 52222.11, 51356.91]
})
print("åŸå§‹è²¡å‹™æ•¸æ“š:")
print(df_finance)

# ç¾å…ƒæ ¼å¼ ($)
df_finance['Revenue_USD'] = df_finance['Revenue'].apply(lambda x: f'${x:,.2f}' if x >= 0 else f'-${-x:,.2f}')
print("\nç¾å…ƒæ ¼å¼çš„æ”¶å…¥:")
print(df_finance['Revenue_USD'])

# æœƒè¨ˆæ ¼å¼ (è² æ•¸ä½¿ç”¨æ‹¬è™Ÿ)
df_finance['Profit_Accounting'] = df_finance['Profit'].apply(lambda x: f'{x:,.2f}' if x >= 0 else f'({-x:,.2f})')
print("\næœƒè¨ˆæ ¼å¼çš„åˆ©æ½¤:")
print(df_finance['Profit_Accounting'])

# å°å¹£æ ¼å¼ (NT$)
df_finance['Revenue_TWD'] = df_finance['Revenue'].apply(lambda x: f'NT${x:,.0f}' if x >= 0 else f'-NT${-x:,.0f}')
print("\nå°å¹£æ ¼å¼çš„æ”¶å…¥:")
print(df_finance['Revenue_TWD'])

# é¡¯ç¤ºå®Œæ•´æ ¼å¼åŒ–å¾Œçš„æ•¸æ“š
print("\næ ¼å¼åŒ–å¾Œçš„è²¡å‹™æ•¸æ“š:")
print(df_finance)

# %% [markdown]
# ### 4.4 è™•ç†ç§‘å­¸è¨ˆæ•¸æ³•å’Œå·¥ç¨‹å–®ä½

# %%
# å‰µå»ºç¤ºä¾‹ç§‘å­¸æ•¸æ“š
df_scientific = pd.DataFrame({
    'Small_Value': [0.000000123, 0.000000234, 0.000000345, 0.000000456, 0.000000567],
    'Large_Value': [1.23e9, 2.34e9, 3.45e9, 4.56e9, 5.67e9],
    'Medium_Value': [1234.5678, 2345.6789, 3456.7890, 4567.8901, 5678.9012]
})
print("åŸå§‹ç§‘å­¸æ•¸æ“š:")
print(df_scientific)

# ç§‘å­¸è¨ˆæ•¸æ³•æ ¼å¼
pd.set_option('display.float_format', lambda x: f'{x:.2e}' if abs(x) < 0.001 or abs(x) >= 1e6 else f'{x:.4f}')
print("\nä½¿ç”¨ç§‘å­¸è¨ˆæ•¸æ³•é¡¯ç¤ºçš„æ•¸æ“š:")
print(df_scientific)

# æ¢å¾©é»˜èªæ ¼å¼
pd.reset_option('display.float_format')

# å·¥ç¨‹å–®ä½æ ¼å¼ (å¦‚ k, M, G, m, Î¼, n)
def format_engineering(x):
    if abs(x) >= 1e9:
        return f'{x/1e9:.2f} G'
    elif abs(x) >= 1e6:
        return f'{x/1e6:.2f} M'
    elif abs(x) >= 1e3:
        return f'{x/1e3:.2f} k'
    elif abs(x) >= 1:
        return f'{x:.2f}'
    elif abs(x) >= 1e-3:
        return f'{x*1e3:.2f} m'
    elif abs(x) >= 1e-6:
        return f'{x*1e6:.2f} Î¼'
    elif abs(x) >= 1e-9:
        return f'{x*1e9:.2f} n'
    else:
        return f'{x:.2e}'

df_scientific['Small_Value_Eng'] = df_scientific['Small_Value'].apply(format_engineering)
df_scientific['Large_Value_Eng'] = df_scientific['Large_Value'].apply(format_engineering)
df_scientific['Medium_Value_Eng'] = df_scientific['Medium_Value'].apply(format_engineering)

print("\nå·¥ç¨‹å–®ä½æ ¼å¼:")
print(df_scientific[['Small_Value', 'Small_Value_Eng', 
                     'Medium_Value', 'Medium_Value_Eng', 
                     'Large_Value', 'Large_Value_Eng']])

# %% [markdown]
# ## 5. é¡åˆ¥å‹è³‡æ–™è™•ç†

# %% [markdown]
# ### 5.1 å°‡æ•¸æ“šè½‰æ›ç‚ºé¡åˆ¥å‹

# %%
# å‰µå»ºç¤ºä¾‹æ•¸æ“š
df_cat = pd.DataFrame({
    'City': ['Taipei', 'New York', 'Tokyo', 'Taipei', 'London', 'Tokyo', 'New York', 'Taipei', 'London', 'Tokyo'],
    'Size': ['Large', 'Medium', 'Small', 'Medium', 'Large', 'Small', 'Large', 'Medium', 'Small', 'Large'],
    'Rating': [4, 5, 3, 4, 5, 3, 4, 5, 3, 4]
})
print("åŸå§‹æ•¸æ“š:")
print(df_cat)
print("\næ•¸æ“šé¡å‹:")
print(df_cat.dtypes)

# è½‰æ›ç‚ºé¡åˆ¥å‹
df_cat['City_Cat'] = df_cat['City'].astype('category')
df_cat['Size_Cat'] = df_cat['Size'].astype('category')
print("\nè½‰æ›å¾Œçš„æ•¸æ“šé¡å‹:")
print(df_cat.dtypes)

# æª¢æŸ¥é¡åˆ¥
print("\nCity çš„é¡åˆ¥:")
print(df_cat['City_Cat'].cat.categories)

print("\nSize çš„é¡åˆ¥:")
print(df_cat['Size_Cat'].cat.categories)

# ç²å–é¡åˆ¥ç·¨ç¢¼
print("\nCity çš„é¡åˆ¥ç·¨ç¢¼:")
print(df_cat['City_Cat'].cat.codes)

# é¡åˆ¥å‹è³‡æ–™çš„å…§å­˜ä½¿ç”¨
print("\nè½‰æ›å‰å¾Œçš„å…§å­˜ä½¿ç”¨æ¯”è¼ƒ:")
print(f"City (object): {df_cat['City'].memory_usage(deep=True)} bytes")
print(f"City_Cat (category): {df_cat['City_Cat'].memory_usage(deep=True)} bytes")

# %% [markdown]
# ### 5.2 é¡åˆ¥å‹æ•¸æ“šçš„æ“ä½œ

# %%
# é‡æ–°æ’åºé¡åˆ¥
df_cat['Size_Cat'] = df_cat['Size_Cat'].cat.reorder_categories(['Small', 'Medium', 'Large'], ordered=True)
print("æœ‰åºé¡åˆ¥ (Size):")
print(df_cat['Size_Cat'])
print(f"é¡åˆ¥: {df_cat['Size_Cat'].cat.categories}")
print(f"æ˜¯å¦æœ‰åº: {df_cat['Size_Cat'].cat.ordered}")

# æ¯”è¼ƒæ“ä½œ (åƒ…é©ç”¨æ–¼æœ‰åºé¡åˆ¥)
print("\nå°ºå¯¸ >= Medium çš„è¨˜éŒ„:")
print(df_cat[df_cat['Size_Cat'] >= 'Medium'])

# æ·»åŠ æ–°é¡åˆ¥
df_cat['Size_Cat'] = df_cat['Size_Cat'].cat.add_categories(['Extra Large'])
print("\næ·»åŠ æ–°é¡åˆ¥å¾Œçš„ Size:")
print(f"é¡åˆ¥: {df_cat['Size_Cat'].cat.categories}")

# åˆªé™¤æœªä½¿ç”¨çš„é¡åˆ¥
df_cat['Size_Cat'] = df_cat['Size_Cat'].cat.remove_unused_categories()
print("\nåˆªé™¤æœªä½¿ç”¨é¡åˆ¥å¾Œçš„ Size:")
print(f"é¡åˆ¥: {df_cat['Size_Cat'].cat.categories}")

# å‰µå»ºä¸€å€‹æ–°çš„é¡åˆ¥åˆ—
df_cat['Rating_Cat'] = pd.Categorical(df_cat['Rating'], categories=[3, 4, 5], ordered=True)
print("\nè©•åˆ†ä½œç‚ºæœ‰åºé¡åˆ¥:")
print(df_cat['Rating_Cat'])
print(f"é¡åˆ¥: {df_cat['Rating_Cat'].cat.categories}")
print(f"æ˜¯å¦æœ‰åº: {df_cat['Rating_Cat'].cat.ordered}")

# ä½¿ç”¨ cut å’Œ qcut å‰µå»ºé¡åˆ¥
df_cat['Rating_Group'] = pd.cut(df_cat['Rating'], bins=[2, 3, 4, 5], labels=['Low', 'Medium', 'High'])
print("\nä½¿ç”¨ cut åˆ†çµ„çš„è©•åˆ†:")
print(df_cat['Rating_Group'])

# %% [markdown]
# ### 5.3 é¡åˆ¥å‹è³‡æ–™çš„ç·¨ç¢¼

# %%
# å‰µå»ºç¤ºä¾‹æ•¸æ“š
df_encode = pd.DataFrame({
    'Color': ['Red', 'Blue', 'Green', 'Red', 'Green', 'Blue', 'Red', 'Green', 'Blue', 'Red'],
    'Size': ['Small', 'Medium', 'Large', 'Small', 'Medium', 'Large', 'Small', 'Medium', 'Large', 'Small']
})
print("åŸå§‹æ•¸æ“š:")
print(df_encode)

# 1. Label Encoding (ä½¿ç”¨ cat.codes)
df_encode['Color_Label'] = df_encode['Color'].astype('category').cat.codes
print("\næ¨™ç±¤ç·¨ç¢¼ (Label Encoding):")
print(df_encode[['Color', 'Color_Label']])

# 2. One-Hot Encoding (ä½¿ç”¨ pd.get_dummies)
color_dummies = pd.get_dummies(df_encode['Color'], prefix='Color')
print("\nç¨ç†±ç·¨ç¢¼ (One-Hot Encoding):")
print(color_dummies)

# å°‡ç¨ç†±ç·¨ç¢¼åˆä½µåˆ°åŸå§‹æ•¸æ“šæ¡†
df_encode_full = pd.concat([df_encode, color_dummies], axis=1)
print("\nåˆä½µç¨ç†±ç·¨ç¢¼å¾Œçš„æ•¸æ“š:")
print(df_encode_full)

# 3. å°å¤šåˆ—é€²è¡Œç¨ç†±ç·¨ç¢¼
multi_dummies = pd.get_dummies(df_encode[['Color', 'Size']])
print("\nå°å¤šåˆ—é€²è¡Œç¨ç†±ç·¨ç¢¼:")
print(multi_dummies)

# 4. è™•ç†ç¨€ç–é¡åˆ¥
df_sparse = pd.DataFrame({
    'City': np.random.choice(['Taipei', 'Tokyo', 'New York', 'London', 'Paris', 
                              'Beijing', 'Sydney', 'Berlin', 'Rome', 'Madrid'], 50)
})

# ä½¿ç”¨ sparse=True ç”¢ç”Ÿç¨€ç–çŸ©é™£
city_dummies_sparse = pd.get_dummies(df_sparse['City'], sparse=True)
print("\nç¨€ç–ç¨ç†±ç·¨ç¢¼:")
print(city_dummies_sparse)
print(f"ç¨€ç–ç¨ç†±ç·¨ç¢¼å…§å­˜ä½¿ç”¨: {city_dummies_sparse.memory_usage(deep=True).sum()} bytes")

# æ¯”è¼ƒèˆ‡æ™®é€šç¨ç†±ç·¨ç¢¼çš„å…§å­˜ä½¿ç”¨
city_dummies = pd.get_dummies(df_sparse['City'])
print(f"æ™®é€šç¨ç†±ç·¨ç¢¼å…§å­˜ä½¿ç”¨: {city_dummies.memory_usage(deep=True).sum()} bytes")

# %% [markdown]
# ## ğŸ“… 6. æ—¥æœŸæ™‚é–“è™•ç†
#
# **å­¸ç¿’è¦é»**ï¼š
# - æŒæ¡ Pandas ä¸­çš„æ—¥æœŸæ™‚é–“è³‡æ–™å‹æ…‹èˆ‡åŠŸèƒ½
# - å­¸ç¿’æ—¥æœŸæ™‚é–“è§£æã€è½‰æ›èˆ‡æ ¼å¼åŒ–æ–¹æ³•
# - äº†è§£æ—¥æœŸæ™‚é–“çš„æŠ½å–ã€é‹ç®—èˆ‡æ™‚å€è™•ç†
#
# **æ‡‰ç”¨å ´åŸŸ**ï¼š
# - æ™‚é–“åºåˆ—åˆ†æèˆ‡é æ¸¬
# - äº‹ä»¶è¨˜éŒ„èˆ‡ç”¨æˆ¶è¡Œç‚ºåˆ†æ
# - è·¨åœ‹æ¥­å‹™çš„æ™‚å€è½‰æ›èˆ‡æ¨™æº–åŒ–

# %% [markdown]
# ### 6.1 æ—¥æœŸæ™‚é–“è§£æèˆ‡è½‰æ›

# %%
# å‰µå»ºåŒ…å«ä¸åŒæ ¼å¼æ—¥æœŸçš„æ•¸æ“š
date_df = pd.DataFrame({
    'dates_ymd': ['2023-01-15', '2023-02-20', '2023-03-25', '2023-04-30', '2023-05-05'],
    'dates_mdy': ['01/15/2023', '02/20/2023', '03/25/2023', '04/30/2023', '05/05/2023'],
    'dates_dmy': ['15-01-2023', '20-02-2023', '25-03-2023', '30-04-2023', '05-05-2023'],
    'datetime_str': ['2023-01-15 08:30:00', '2023-02-20 12:45:30', '2023-03-25 18:15:45', 
                     '2023-04-30 21:20:15', '2023-05-05 07:10:25'],
    'mixed_formats': ['2023-01-15', '02/20/2023', '25/Mar/2023', '2023.04.30', '05-05-2023']
})

print("åŸå§‹æ—¥æœŸæ•¸æ“š:")
print(date_df)

# ä½¿ç”¨ pd.to_datetime è‡ªå‹•è§£æ
date_df['dates_ymd_dt'] = pd.to_datetime(date_df['dates_ymd'])
date_df['dates_mdy_dt'] = pd.to_datetime(date_df['dates_mdy'])
date_df['dates_dmy_dt'] = pd.to_datetime(date_df['dates_dmy'])
date_df['datetime_dt'] = pd.to_datetime(date_df['datetime_str'])

# æŒ‡å®šæ ¼å¼è§£æ
date_df['dates_dmy_fmt'] = pd.to_datetime(date_df['dates_dmy'], format='%d-%m-%Y')

# æ··åˆæ ¼å¼ - å˜—è©¦è‡ªå‹•è§£æ
date_df['mixed_auto'] = pd.to_datetime(date_df['mixed_formats'], errors='coerce')

print("\nè½‰æ›å¾Œæ—¥æœŸæ•¸æ“š:")
print(date_df[['dates_ymd', 'dates_ymd_dt', 'dates_mdy', 'dates_mdy_dt', 
               'dates_dmy', 'dates_dmy_fmt', 'datetime_str', 'datetime_dt']])

print("\næ··åˆæ ¼å¼è‡ªå‹•è§£æçµæœ:")
print(date_df[['mixed_formats', 'mixed_auto']])

# è½‰æ›ç‚ºç‰¹å®šå­—ç¬¦ä¸²æ ¼å¼
print("\næ ¼å¼åŒ–æ—¥æœŸè¼¸å‡º:")
print(date_df['dates_ymd_dt'].dt.strftime('%Yå¹´%mæœˆ%dæ—¥'))
print(date_df['datetime_dt'].dt.strftime('%Y-%m-%d %Hæ™‚%Måˆ†'))

# æª¢æŸ¥æ•¸æ“šé¡å‹
print("\nè½‰æ›å¾Œçš„æ•¸æ“šé¡å‹:")
print(date_df.dtypes)

# %% [markdown]
# **è§£èªª**ï¼š
# - Pandas æä¾› `datetime64[ns]` é¡å‹ç”¨æ–¼æ—¥æœŸæ™‚é–“è™•ç†ï¼Œæ”¯æŒè±å¯Œçš„æ™‚é–“å‡½æ•¸èˆ‡å‘é‡åŒ–æ“ä½œ
# - æ—¥æœŸæ™‚é–“è§£æä¸»è¦é€šé `pd.to_datetime()` å‡½æ•¸å¯¦ç¾ï¼Œæä¾›å¤šç¨®å‚æ•¸é…ç½®ï¼š
#   - è‡ªå‹•è§£æ (é»˜èª): å˜—è©¦æ¨æ–·æ—¥æœŸæ ¼å¼ï¼Œè™•ç†å¸¸è¦‹çš„æ—¥æœŸè¡¨é”æ–¹å¼
#   - æŒ‡å®šæ ¼å¼è§£æ: ä½¿ç”¨ `format` åƒæ•¸æ˜ç¢ºæŒ‡å®šæ—¥æœŸæ ¼å¼
#   - éŒ¯èª¤è™•ç†: `errors='coerce'` å°‡ç„¡æ•ˆæ—¥æœŸè½‰ç‚º NaTï¼Œ`errors='raise'` é‡éŒ¯æ‹‹å‡ºç•°å¸¸
# - æ ¼å¼å­—ç¬¦ä¸²ä½¿ç”¨ [strftime/strptime æ ¼å¼å­—ç¬¦](https://docs.python.org/3/library/datetime.html#strftime-and-strptime-format-codes)ï¼š
#   - `%Y`: 4ä½å¹´ä»½ï¼Œ`%y`: 2ä½å¹´ä»½
#   - `%m`: æœˆä»½ï¼ˆ01-12ï¼‰ï¼Œ`%b`: æœˆä»½è‹±æ–‡ç¸®å¯«
#   - `%d`: æ—¥æœŸï¼ˆ01-31ï¼‰
#   - `%H`: 24å°æ™‚åˆ¶å°æ™‚ï¼Œ`%I`: 12å°æ™‚åˆ¶å°æ™‚
#   - `%M`: åˆ†é˜ï¼Œ`%S`: ç§’
# - æ—¥æœŸè§£æå„ªç¼ºé»ï¼š
#   - è‡ªå‹•è§£ææ–¹ä¾¿ä½†ä¸¦éè¬èƒ½ï¼Œç‰¹æ®Šæ ¼å¼ä»éœ€æ˜ç¢ºæŒ‡å®š
#   - ç¾å¼æ—¥æœŸï¼ˆMM/DD/YYYYï¼‰å’Œæ­å¼æ—¥æœŸï¼ˆDD/MM/YYYYï¼‰å®¹æ˜“æ··æ·†
#   - æ··åˆæ ¼å¼æ•¸æ“šé›†å¯èƒ½éœ€è¦åˆ†æ®µè™•ç†æˆ–ä½¿ç”¨æ¢ä»¶é‚è¼¯
# - è½‰æ›ç‚º `datetime64[ns]` å¾Œï¼Œå¯ç²å¾—å¤šç¨®æ™‚é–“ç›¸é—œåŠŸèƒ½å’Œé«˜æ•ˆæ“ä½œ
# - `strftime()` æ–¹æ³•æä¾›éˆæ´»çš„æ—¥æœŸæ™‚é–“æ ¼å¼åŒ–è¼¸å‡ºï¼Œæ”¯æŒå¤šèªè¨€ç’°å¢ƒçš„æ—¥æœŸè¡¨ç¤º

# %% [markdown]
# ### 6.2 æ—¥æœŸæ™‚é–“çµ„ä»¶æŠ½å–èˆ‡æ“ä½œ

# %%
# å‰µå»ºåŒ…å«æ—¥æœŸæ™‚é–“çš„ DataFrame
dt_components = pd.DataFrame({
    'datetime': pd.date_range(start='2023-01-01', periods=10, freq='36H')
})

# æŠ½å–æ—¥æœŸæ™‚é–“çµ„ä»¶
dt_components['year'] = dt_components['datetime'].dt.year
dt_components['month'] = dt_components['datetime'].dt.month
dt_components['day'] = dt_components['datetime'].dt.day
dt_components['hour'] = dt_components['datetime'].dt.hour
dt_components['minute'] = dt_components['datetime'].dt.minute
dt_components['second'] = dt_components['datetime'].dt.second
dt_components['dayofweek'] = dt_components['datetime'].dt.dayofweek  # 0=Monday, 6=Sunday
dt_components['dayofyear'] = dt_components['datetime'].dt.dayofyear
dt_components['quarter'] = dt_components['datetime'].dt.quarter
dt_components['is_month_end'] = dt_components['datetime'].dt.is_month_end

print("æ—¥æœŸæ™‚é–“çµ„ä»¶æŠ½å–:")
print(dt_components)

# ç²å–æ—¥æœŸå’Œæ™‚é–“éƒ¨åˆ†
dt_components['date_only'] = dt_components['datetime'].dt.date
dt_components['time_only'] = dt_components['datetime'].dt.time

print("\næ—¥æœŸå’Œæ™‚é–“éƒ¨åˆ†:")
print(dt_components[['datetime', 'date_only', 'time_only']].head())

# æ—¥æœŸç®—è¡“é‹ç®—
dt_arith = pd.DataFrame({
    'base_date': pd.to_datetime(['2023-01-15', '2023-02-28', '2023-03-31']),
})

# æ·»åŠ å’Œæ¸›å»å¤©æ•¸
dt_arith['plus_10days'] = dt_arith['base_date'] + pd.Timedelta(days=10)
dt_arith['minus_5days'] = dt_arith['base_date'] - pd.Timedelta(days=5)

# æ·»åŠ æœˆä»½ (æ³¨æ„ï¼šéœ€è¦ä½¿ç”¨ DateOffset)
dt_arith['plus_2months'] = dt_arith['base_date'] + pd.DateOffset(months=2)
dt_arith['minus_1month'] = dt_arith['base_date'] - pd.DateOffset(months=1)

# è¨ˆç®—å…©æ—¥æœŸä¹‹é–“çš„å·®å€¼
dates_diff = pd.DataFrame({
    'start_date': pd.to_datetime(['2023-01-01', '2023-03-15', '2023-06-30']),
    'end_date': pd.to_datetime(['2023-02-15', '2023-09-01', '2023-12-25'])
})

dates_diff['days_diff'] = (dates_diff['end_date'] - dates_diff['start_date']).dt.days

print("\næ—¥æœŸç®—è¡“é‹ç®—:")
print(dt_arith)

print("\næ—¥æœŸå·®å€¼è¨ˆç®—:")
print(dates_diff)

# %% [markdown]
# **è§£èªª**ï¼š
# - Pandas æ—¥æœŸæ™‚é–“å°è±¡çš„ `dt` è¨ªå•å™¨æä¾›è±å¯Œçš„å±¬æ€§èˆ‡æ–¹æ³•ï¼Œç”¨æ–¼æŠ½å–å’Œæ“ä½œæ™‚é–“çµ„ä»¶
# - å¸¸ç”¨æ—¥æœŸæ™‚é–“çµ„ä»¶æŠ½å–ï¼š
#   - åŸºæœ¬çµ„ä»¶: `year`, `month`, `day`, `hour`, `minute`, `second`
#   - æ—¥æ›†çµ„ä»¶: `dayofweek`, `dayofyear`, `quarter`, `week`
#   - ç‹€æ…‹æŒ‡ç¤º: `is_month_end`, `is_month_start`, `is_year_end`
#   - éƒ¨åˆ†æŠ½å–: `date`, `time` (åˆ†åˆ¥ç²å–æ—¥æœŸå’Œæ™‚é–“éƒ¨åˆ†)
# - æ—¥æœŸæ™‚é–“é‹ç®—ä¸»è¦æœ‰å…©ç¨®æ–¹å¼ï¼š
#   - `Timedelta`: ç”¨æ–¼å¤©ã€å°æ™‚ã€åˆ†é˜ã€ç§’ç­‰æ™‚é–“å–®ä½çš„å¢æ¸›
#   - `DateOffset`: ç”¨æ–¼æœˆã€å¹´ç­‰æ—¥æ›†å–®ä½çš„å¢æ¸›ï¼Œè™•ç†æœˆåº•å’Œé–å¹´ç­‰ç‰¹æ®Šæƒ…æ³
# - æ—¥æœŸå·®å€¼è¨ˆç®—è¿”å› `timedelta64[ns]` é¡å‹ï¼Œå¯é€šé `.dt.days`, `.dt.seconds` ç­‰ç²å–ç‰¹å®šå–®ä½
# - æ—¥æœŸæ™‚é–“çµ„ä»¶åœ¨æ•¸æ“šåˆ†æä¸­çš„æ‡‰ç”¨ï¼š
#   - æ™‚é–“åºåˆ—åˆ†è§£: åˆ†æå¹´åº¦ã€å­£ç¯€ã€æœˆåº¦ã€æ˜ŸæœŸç­‰æ¨¡å¼
#   - ç‰¹å¾µå·¥ç¨‹: å¾æ—¥æœŸæ™‚é–“å‰µå»ºç‰¹å¾µç”¨æ–¼æ©Ÿå™¨å­¸ç¿’
#   - å•†æ¥­æ™ºèƒ½: æŒ‰å­£åº¦ã€æœˆä»½ã€æ˜ŸæœŸç­‰é€²è¡Œåˆ†çµ„åˆ†æ
#   - æ´»å‹•è¦åŠƒ: è¨ˆç®—æˆªæ­¢æ—¥æœŸã€é …ç›®æŒçºŒæ™‚é–“
# - æ³¨æ„ `DateOffset` èˆ‡ `Timedelta` çš„å€åˆ¥ï¼š
#   - `2023-01-31 + 1 month` ä½¿ç”¨ `DateOffset` å¾—åˆ° `2023-02-28`ï¼ˆè€ƒæ…®æœˆåº•ï¼‰
#   - `2023-01-31 + 30 days` ä½¿ç”¨ `Timedelta` å¾—åˆ° `2023-03-02`ï¼ˆç´”ç²¹åŠ å¤©æ•¸ï¼‰

# %% [markdown]
# ### 6.3 æ™‚å€è™•ç†èˆ‡è½‰æ›

# %%
# å‰µå»ºæ™‚å€æ„ŸçŸ¥çš„æ—¥æœŸæ™‚é–“
timezone_df = pd.DataFrame({
    'naive_datetime': pd.date_range(start='2023-01-01 12:00:00', periods=5, freq='D')
})

# å°‡ naive datetime è½‰æ›ç‚ºç‰¹å®šæ™‚å€
timezone_df['tokyo'] = timezone_df['naive_datetime'].dt.tz_localize('Asia/Tokyo')
timezone_df['new_york'] = timezone_df['naive_datetime'].dt.tz_localize('America/New_York')
timezone_df['london'] = timezone_df['naive_datetime'].dt.tz_localize('Europe/London')

# é¡¯ç¤ºä¸åŒæ™‚å€çš„æ™‚é–“
print("ä¸åŒæ™‚å€çš„æ™‚é–“:")
print(timezone_df)

# æ™‚å€è½‰æ›
print("\næ™‚å€è½‰æ› (æ±äº¬ -> å€«æ•¦):")
tokyo_to_london = timezone_df['tokyo'].dt.tz_convert('Europe/London')
print(pd.DataFrame({'Tokyo': timezone_df['tokyo'], 'London': tokyo_to_london}))

# æ™‚å€è½‰æ› (ç´ç´„ -> æ±äº¬)
print("\næ™‚å€è½‰æ› (ç´ç´„ -> æ±äº¬):")
ny_to_tokyo = timezone_df['new_york'].dt.tz_convert('Asia/Tokyo')
print(pd.DataFrame({'New York': timezone_df['new_york'], 'Tokyo': ny_to_tokyo}))

# è™•ç†å¤ä»¤æ™‚
dst_dates = pd.DataFrame({
    'dates': pd.date_range(start='2023-03-01', end='2023-04-30', freq='15D')
})

# æ·»åŠ ç¾åœ‹æ±éƒ¨æ™‚å€ (è§€å¯Ÿå¤ä»¤æ™‚è®ŠåŒ–)
dst_dates['us_eastern'] = dst_dates['dates'].dt.tz_localize('US/Eastern')
# ç²å– UTC åç§»é‡
dst_dates['utc_offset'] = dst_dates['us_eastern'].dt.tz_localize(None).apply(
    lambda x: dst_dates['us_eastern'][dst_dates['dates'] == x].dt.tz_info.utcoffset().total_seconds() / 3600
)

print("\nå¤ä»¤æ™‚è½‰æ› (ç¾åœ‹æ±éƒ¨æ™‚é–“):")
print(dst_dates)
print("\næ³¨æ„ 2023-03-01 èˆ‡ 2023-04-15 çš„ UTC åç§»é‡ä¸åŒï¼Œå› ç‚ºå¤ä»¤æ™‚ç™¼ç”Ÿäº†è®ŠåŒ–")

# è½‰å› naive datetime
print("\nç§»é™¤æ™‚å€ä¿¡æ¯:")
timezone_df['tokyo_naive'] = timezone_df['tokyo'].dt.tz_localize(None)
print(timezone_df[['tokyo', 'tokyo_naive']])

# %% [markdown]
# **è§£èªª**ï¼š
# - Pandas æ™‚å€è™•ç†æ¶‰åŠå…©å€‹ä¸»è¦æ¦‚å¿µï¼š
#   - **Naive datetime**: ä¸åŒ…å«æ™‚å€ä¿¡æ¯çš„æ—¥æœŸæ™‚é–“
#   - **Aware datetime**: åŒ…å«æ™‚å€ä¿¡æ¯çš„æ—¥æœŸæ™‚é–“
# - æ™‚å€æ“ä½œçš„ä¸»è¦å‡½æ•¸ï¼š
#   - `dt.tz_localize()`: å°‡ naive datetime è½‰æ›ç‚ºç‰¹å®šæ™‚å€çš„ aware datetime
#   - `dt.tz_convert()`: åœ¨ä¸åŒæ™‚å€ä¹‹é–“è½‰æ› aware datetime
#   - `dt.tz_localize(None)`: ç§»é™¤æ™‚å€ä¿¡æ¯ï¼Œè½‰å› naive datetime
# - æ™‚å€æŒ‡å®šæ–¹å¼ï¼š
#   - IANA æ™‚å€æ•¸æ“šåº«åç¨±: å¦‚ 'Asia/Tokyo', 'America/New_York'
#   - é€šç”¨ç¸®å¯«: å¦‚ 'UTC', 'GMT'
# - å¤ä»¤æ™‚ï¼ˆDaylight Saving Time, DSTï¼‰æ³¨æ„äº‹é …ï¼š
#   - æŸäº›æ™‚å€åœ¨ä¸€å¹´ä¸­æœ‰DSTèª¿æ•´ï¼Œå¦‚ç¾åœ‹åœ¨3æœˆé€²å…¥å¤ä»¤æ™‚ï¼Œ11æœˆé€€å‡º
#   - DSTæœŸé–“ UTC åç§»é‡æœƒç™¼ç”Ÿè®ŠåŒ–ï¼ˆé€šå¸¸æå‰1å°æ™‚ï¼‰
#   - è™•ç†è·¨DSTé‚Šç•Œçš„æ™‚é–“è¨ˆç®—éœ€ç‰¹åˆ¥æ³¨æ„
# - å¯¦éš›æ‡‰ç”¨å ´æ™¯ï¼š
#   - è·¨åœ‹æ¥­å‹™æ•¸æ“šçµ±ä¸€åŒ–: ä¸åŒåœ‹å®¶æ•¸æ“šè½‰æ›åˆ°åŒä¸€æ™‚å€é€²è¡Œåˆ†æ
#   - ç³»çµ±æ—¥èªŒåˆ†æ: æœå‹™å™¨éå¸ƒå…¨çƒæ™‚ï¼Œéœ€å°‡æ—¥èªŒæ™‚é–“æ¨™æº–åŒ–
#   - æ’ç¨‹ç³»çµ±: ç¢ºä¿è·¨æ™‚å€çš„ä»»å‹™åœ¨æ­£ç¢ºæ™‚é–“åŸ·è¡Œ
#   - ç”¨æˆ¶é«”é©—: æ ¹æ“šç”¨æˆ¶æ™‚å€é¡¯ç¤ºç›¸æ‡‰æ™‚é–“ä¿¡æ¯
# - å»ºè­°å¯¦è¸ï¼š
#   - æ•¸æ“šåº«ä¸­å­˜å„² UTC æ™‚é–“ï¼Œåƒ…åœ¨å±•ç¤ºæ™‚è½‰æ›ç‚ºæœ¬åœ°æ™‚é–“
#   - æ™‚é–“è¨ˆç®—å„ªå…ˆä½¿ç”¨ aware datetimeï¼Œé¿å…å¤ä»¤æ™‚å¸¶ä¾†çš„æ··æ·†
#   - æ³¨æ„æ™‚å€è½‰æ›åœ¨æ—¥æœŸé‚Šç•Œæ™‚å¯èƒ½å°è‡´æ—¥æœŸè®ŠåŒ–

# %% [markdown]
# ### 6.4 æ—¥æœŸæ™‚é–“åºåˆ—èˆ‡é »ç‡

# %%
# å‰µå»ºä¸åŒé »ç‡çš„æ™‚é–“åºåˆ—
date_ranges = {
    'Daily': pd.date_range(start='2023-01-01', periods=5, freq='D'),
    'Weekly': pd.date_range(start='2023-01-01', periods=5, freq='W'),
    'Monthly': pd.date_range(start='2023-01-01', periods=5, freq='M'),
    'Quarterly': pd.date_range(start='2023-01-01', periods=5, freq='Q'),
    'Yearly': pd.date_range(start='2023-01-01', periods=5, freq='Y'),
    'Business Day': pd.date_range(start='2023-01-01', periods=5, freq='B'),
    'Hour': pd.date_range(start='2023-01-01', periods=5, freq='H'),
    'Minute': pd.date_range(start='2023-01-01', periods=5, freq='T'),
}

# é¡¯ç¤ºå„ç¨®é »ç‡
print("ä¸åŒé »ç‡çš„æ™‚é–“åºåˆ—:")
for name, dates in date_ranges.items():
    print(f"{name}: {dates}")

# å‰µå»ºè‡ªå®šç¾©é »ç‡
custom_freq = {
    '2 Hours': pd.date_range(start='2023-01-01', periods=5, freq='2H'),
    '30 Minutes': pd.date_range(start='2023-01-01', periods=5, freq='30T'),
    'Quarter End': pd.date_range(start='2023-01-01', periods=5, freq='Q-DEC'),
    'Month Begin': pd.date_range(start='2023-01-01', periods=5, freq='MS'),
    'Wednesday': pd.date_range(start='2023-01-01', periods=5, freq='W-WED'),
    'Business Month End': pd.date_range(start='2023-01-01', periods=5, freq='BM'),
}

print("\nè‡ªå®šç¾©é »ç‡çš„æ™‚é–“åºåˆ—:")
for name, dates in custom_freq.items():
    print(f"{name}: {dates}")

# ä½¿ç”¨ Period è¡¨ç¤ºæ™‚é–“æ®µ
periods = {
    'Daily Period': pd.period_range(start='2023-01-01', periods=5, freq='D'),
    'Monthly Period': pd.period_range(start='2023-01', periods=5, freq='M'),
    'Quarterly Period': pd.period_range(start='2023Q1', periods=5, freq='Q'),
    'Yearly Period': pd.period_range(start='2023', periods=5, freq='Y'),
}

print("\næ™‚é–“æ®µ (Period):")
for name, p in periods.items():
    print(f"{name}: {p}")

# æ™‚é–“åºåˆ—é‡æ¡æ¨£
ts_data = pd.DataFrame({
    'date': pd.date_range(start='2023-01-01', periods=10, freq='D'),
    'value': np.random.randn(10).cumsum()
})
ts_data.set_index('date', inplace=True)

# ä¸Šæ¡æ¨£
upsampled = ts_data.resample('6H').interpolate(method='linear')
# ä¸‹æ¡æ¨£
downsampled = ts_data.resample('2D').mean()

print("\næ™‚é–“åºåˆ—é‡æ¡æ¨£:")
print(f"åŸå§‹æ•¸æ“š (æ¯æ—¥):\n{ts_data.head()}")
print(f"\nä¸Šæ¡æ¨£ (6å°æ™‚):\n{upsampled.head(8)}")
print(f"\nä¸‹æ¡æ¨£ (2å¤©):\n{downsampled}")

# %% [markdown]
# **è§£èªª**ï¼š
# - Pandas æä¾›è±å¯Œçš„æ™‚é–“åºåˆ—é »ç‡èˆ‡æ“ä½œåŠŸèƒ½ï¼Œæ˜¯æ™‚é–“åºåˆ—åˆ†æçš„å¼·å¤§å·¥å…·
# - ä¸»è¦é »ç‡æ¨™è¨˜ï¼š
#   - æ—¥æ›†æ™‚é–“: `D` (æ—¥), `W` (é€±), `M` (æœˆæœ«), `Q` (å­£æœ«), `Y`/`A` (å¹´æœ«)
#   - å•†æ¥­æ™‚é–“: `B` (å·¥ä½œæ—¥), `BM` (æ¥­å‹™æœˆæœ«), `BQ` (æ¥­å‹™å­£æœ«)
#   - æ™‚åˆ†ç§’: `H` (å°æ™‚), `T`/`min` (åˆ†é˜), `S` (ç§’)
#   - å¢å¼·é »ç‡: `MS` (æœˆåˆ), `QS` (å­£åˆ), `W-MON` (é€±ä¸€)
# - è‡ªå®šç¾©é »ç‡é€šéçµ„åˆå¯¦ç¾ï¼š
#   - é »ç‡å€æ•¸: `2H` (æ¯2å°æ™‚), `15T` (æ¯15åˆ†é˜)
#   - ç‰¹å®šéŒ¨é»: `W-WED` (æ¯é€±ä¸‰), `Q-JAN` (ä»¥1æœˆç‚ºå­£æœ«çš„å­£åº¦)
# - é »ç‡æ¦‚å¿µç¨®é¡ï¼š
#   - `DatetimeIndex`: è¡¨ç¤ºæ™‚é–“é»ï¼Œé©åˆäº‹ä»¶èˆ‡è§€æ¸¬
#   - `PeriodIndex`: è¡¨ç¤ºæ™‚é–“æ®µï¼Œé©åˆå ±è¡¨èˆ‡æœƒè¨ˆæœŸé–“
# - æ™‚é–“åºåˆ—é‡æ¡æ¨£ï¼š
#   - ä¸Šæ¡æ¨£ (Upsampling): å¢åŠ é »ç‡ï¼ˆå¦‚æ—¥â†’å°æ™‚ï¼‰ï¼Œé€šå¸¸éœ€è¦æ’å€¼
#   - ä¸‹æ¡æ¨£ (Downsampling): æ¸›å°‘é »ç‡ï¼ˆå¦‚æ—¥â†’æœˆï¼‰ï¼Œé€šå¸¸éœ€è¦èšåˆå‡½æ•¸
# - é‡æ¡æ¨£èšåˆæ–¹æ³•ï¼š
#   - è¨ˆç®—é¡: `mean()`, `sum()`, `std()`, `median()`
#   - é¸æ“‡é¡: `first()`, `last()`, `max()`, `min()`
# - å¯¦éš›æ‡‰ç”¨å ´æ™¯ï¼š
#   - é‡‘è: å°‡åˆ†é˜ç´šè‚¡ç¥¨æ•¸æ“šèšåˆç‚ºæ—¥/é€±/æœˆæ”¶ç›Š
#   - ç‰©è¯ç¶²: å°‡é«˜é »å‚³æ„Ÿå™¨æ•¸æ“šä¸‹æ¡æ¨£ä»¥ç¯€çœå­˜å„²
#   - é æ¸¬: ä½¿ç”¨ä¸åŒæ™‚é–“ç²’åº¦å»ºç«‹é æ¸¬æ¨¡å‹
#   - å ±è¡¨: å°‡æ¯æ—¥æ•¸æ“šè½‰æ›ç‚ºæœˆåº¦/å­£åº¦å ±è¡¨
# - æ³¨æ„äº‹é …:
#   - ä¸Šæ¡æ¨£éœ€é¸æ“‡é©ç•¶çš„æ’å€¼æ–¹æ³•: `ffill`, `bfill`, `interpolate`
#   - è™•ç†æ™‚å€è®Šæ›´æ™‚é–“æ™‚éœ€ç‰¹åˆ¥å°å¿ƒ
#   - å­£åº¦èˆ‡è²¡å¹´å®šç¾©å› åœ‹å®¶èˆ‡ä¼æ¥­è€Œç•°ï¼Œéœ€æ­£ç¢ºè¨­ç½®

# %% [markdown]
# ## 7. æ–‡å­—æ•¸æ“šè™•ç†

# %% [markdown]
# ### 7.1 å­—ç¬¦ä¸²åŸºæœ¬æ“ä½œ

# %%
# å‰µå»ºåŒ…å«æ–‡æœ¬çš„ DataFrame
df_text = pd.DataFrame({
    'Name': ['  John Smith  ', 'Alice Johnson', 'bob williams', 'CAROL TAYLOR', 'David_Brown'],
    'Email': ['john@example.com', 'alice.j@example.net', 'bob.williams@company.org', 'carol_t@example.com', 'david.b@company.org'],
    'Phone': ['(123) 456-7890', '987-654-3210', '(555) 123-4567', '800-555-1234', '(999) 888-7777'],
    'Comment': ['Good product!', 'Could be better', 'Will recommend to friends', 'Not satisfied', 'Excellent service!']
})
print("åŸå§‹æ–‡æœ¬æ•¸æ“š:")
print(df_text)

# å­—ç¬¦ä¸²åŸºæœ¬æ–¹æ³•
df_text['Name_Upper'] = df_text['Name'].str.upper()
df_text['Name_Lower'] = df_text['Name'].str.lower()
df_text['Name_Title'] = df_text['Name'].str.title()
df_text['Name_Strip'] = df_text['Name'].str.strip()
df_text['Name_Len'] = df_text['Name'].str.len()

print("\nå­—ç¬¦ä¸²åŸºæœ¬æ–¹æ³•:")
print(df_text[['Name', 'Name_Upper', 'Name_Lower', 'Name_Title', 'Name_Strip', 'Name_Len']])

# å­—ç¬¦ä¸²åˆ†å‰²å’Œé¸å–
df_text['First_Name'] = df_text['Name'].str.split().str[0].str.strip()
df_text['Domain'] = df_text['Email'].str.split('@').str[1]

print("\nå­—ç¬¦ä¸²åˆ†å‰²:")
print(df_text[['Name', 'First_Name', 'Email', 'Domain']])

# é›»è©±è™Ÿç¢¼æ ¼å¼åŒ–
df_text['Phone_Clean'] = df_text['Phone'].str.replace(r'[\(\)\-\s]', '', regex=True)
print("\næ¸…ç†å¾Œçš„é›»è©±è™Ÿç¢¼:")
print(df_text[['Phone', 'Phone_Clean']])

# æ¨¡å¼æª¢ç´¢
has_com = df_text['Email'].str.contains(r'\.com$', regex=True)
print("\néƒµç®±ä»¥ .com çµå°¾çš„è¡Œ:")
print(df_text[has_com])

# %% [markdown]
# ### 7.2 æ­£å‰‡è¡¨é”å¼æ“ä½œ

# %%
# å‰µå»ºç¤ºä¾‹æ•¸æ“š
df_regex = pd.DataFrame({
    'Text': [
        'The price is $25.99',
        'Contact: (123) 456-7890',
        'Email: user@example.com',
        'Date: 2023-01-15',
        'IP: 192.168.1.1'
    ]
})
print("åŸå§‹æ–‡æœ¬:")
print(df_regex)

# æå–åƒ¹æ ¼
df_regex['Price'] = df_regex['Text'].str.extract(r'\$(\d+\.\d+)')
print("\næå–åƒ¹æ ¼:")
print(df_regex[['Text', 'Price']])

# æå–é›»è©±è™Ÿç¢¼
df_regex['Phone'] = df_regex['Text'].str.extract(r'\((\d{3})\)\s*(\d{3})-(\d{4})')
print("\næå–é›»è©±è™Ÿç¢¼:")
print(df_regex[['Text', 'Phone']])

# æå–é›»å­éƒµä»¶
df_regex['Email'] = df_regex['Text'].str.extract(r'([a-zA-Z0-9._%+-]+@[a-zA-Z0-9.-]+\.[a-zA-Z]{2,})')
print("\næå–é›»å­éƒµä»¶:")
print(df_regex[['Text', 'Email']])

# æå–æ—¥æœŸ
df_regex['Date'] = df_regex['Text'].str.extract(r'(\d{4}-\d{2}-\d{2})')
print("\næå–æ—¥æœŸ:")
print(df_regex[['Text', 'Date']])

# æå–IPåœ°å€
df_regex['IP'] = df_regex['Text'].str.extract(r'(\d{1,3}\.\d{1,3}\.\d{1,3}\.\d{1,3})')
print("\næå–IPåœ°å€:")
print(df_regex[['Text', 'IP']])

# %% [markdown]
# ### 7.3 æ–‡æœ¬æ¸…æ´—èˆ‡é è™•ç†

# %%
# å‰µå»ºåŒ…å«é›œäº‚æ–‡æœ¬çš„ DataFrame
df_messy = pd.DataFrame({
    'Text': [
        '  This is a sample text! With some punctuation. ',
        'ANOTHER TEXT WITH ALL CAPITALS.',
        'URL: https://example.com/page.html',
        'Multiple   spaces   and\ttabs\tin this text',
        'Email: user123@example.com #hashtag'
    ]
})
print("åŸå§‹é›œäº‚æ–‡æœ¬:")
print(df_messy)

# åŸºæœ¬æ¸…æ´—æ­¥é©Ÿ
df_messy['Cleaned'] = df_messy['Text'].str.strip()  # ç§»é™¤å‰å¾Œç©ºç™½
df_messy['Cleaned'] = df_messy['Cleaned'].str.lower()  # è½‰ç‚ºå°å¯«
df_messy['Cleaned'] = df_messy['Cleaned'].str.replace(r'[^\w\s]', '', regex=True)  # ç§»é™¤æ¨™é»ç¬¦è™Ÿ
df_messy['Cleaned'] = df_messy['Cleaned'].str.replace(r'\s+', ' ', regex=True)  # ç§»é™¤å¤šé¤˜ç©ºç™½

print("\nåŸºæœ¬æ¸…æ´—å¾Œçš„æ–‡æœ¬:")
print(df_messy[['Text', 'Cleaned']])

# ç§»é™¤URLs
df_messy['No_URLs'] = df_messy['Text'].str.replace(r'https?://\S+', '', regex=True)
print("\nç§»é™¤URLs:")
print(df_messy[['Text', 'No_URLs']])

# ç§»é™¤Email
df_messy['No_Emails'] = df_messy['Text'].str.replace(r'\S+@\S+', '', regex=True)
print("\nç§»é™¤Emails:")
print(df_messy[['Text', 'No_Emails']])

# ç§»é™¤æ¨™ç±¤å’Œä¸»é¡Œæ¨™ç±¤
df_messy['No_Tags'] = df_messy['Text'].str.replace(r'#\w+', '', regex=True)
print("\nç§»é™¤æ¨™ç±¤:")
print(df_messy[['Text', 'No_Tags']])

# åˆ†è©
df_messy['Tokens'] = df_messy['Cleaned'].str.split()
print("\nåˆ†è©çµæœ:")
print(df_messy[['Cleaned', 'Tokens']])

# %% [markdown]
# **è§£èªª**ï¼š
# - æ–‡æœ¬æ•¸æ“šè™•ç†é€šå¸¸åŒ…æ‹¬æ¨™æº–åŒ–ï¼ˆå¤§å°å¯«çµ±ä¸€ï¼‰ã€æ¸…æ´—ï¼ˆç§»é™¤æ¨™é»ç¬¦è™Ÿã€å¤šé¤˜ç©ºç™½ï¼‰å’Œæ¨™è¨˜åŒ–ï¼ˆåˆ†è©ï¼‰
# - ä½¿ç”¨ `str.split()` å°‡æ–‡æœ¬åˆ‡åˆ†ç‚ºå–®è©åˆ—è¡¨ï¼Œä¾¿æ–¼å¾ŒçºŒåˆ†æ
# - è©é »çµ±è¨ˆæ˜¯æ–‡æœ¬åˆ†æçš„åŸºç¤ï¼Œå¯ä»¥å¾æ•´é«”æˆ–å–®æ¢æ–‡æœ¬çš„è§’åº¦è¨ˆç®—è©é »
# - æ–‡æœ¬æ¸…æ´—é€šå¸¸æ˜¯æ•¸æ“šåˆ†ææµç¨‹çš„ç¬¬ä¸€æ­¥ï¼Œå®ƒç‚ºå¾ŒçºŒçš„ç‰¹å¾µå·¥ç¨‹å’Œåˆ†æå¥ å®šåŸºç¤
# - Pandas çš„å­—ç¬¦ä¸²æ–¹æ³•æä¾›äº†é«˜æ•ˆçš„æ–‡æœ¬è™•ç†èƒ½åŠ›ï¼Œæ­é…æ­£å‰‡è¡¨é”å¼èƒ½è™•ç†è¤‡é›œçš„æ–‡æœ¬æ¨¡å¼

# %% [markdown]
# ## ğŸ”‘ 8. ç¸½çµèˆ‡æœ€ä½³å¯¦è¸
#
# **å­¸ç¿’è¦é»**ï¼š
# - æŒæ¡æ•¸æ“šé¡å‹è½‰æ›çš„åŸºæœ¬åŸå‰‡å’Œæ–¹æ³•
# - äº†è§£å„ç¨®ç‰¹æ®Šæ•¸æ“šé¡å‹çš„è™•ç†æŠ€å·§
# - ç†Ÿæ‚‰æ—¥æœŸæ™‚é–“å’Œæ–‡æœ¬æ•¸æ“šçš„é«˜ç´šè™•ç†æ–¹æ³•
# - å­¸ç¿’è™•ç†å¯¦éš›æ•¸æ“šé›†ä¸­å¸¸è¦‹çš„æ•¸æ“šé¡å‹å•é¡Œ
#
# **æ‡‰ç”¨å ´åŸŸ**ï¼š
# - æ•¸æ“šå‰è™•ç†èˆ‡æ¸…æ´—å·¥ä½œæµ
# - æ•¸æ“šæ•´åˆèˆ‡æ¨™æº–åŒ–éç¨‹
# - ç‰¹å¾µå·¥ç¨‹èˆ‡æ¨¡å‹è¼¸å…¥æº–å‚™
# - æ•¸æ“šåˆ†æå ±å‘Šç”Ÿæˆèˆ‡æ ¼å¼åŒ–

# %% [markdown]
# ### 8.1 æ•¸æ“šå‹æ…‹è½‰æ›çš„é—œéµé»

# %%
# å‰µå»ºä¸€å€‹æœ€çµ‚ç¤ºä¾‹ï¼Œå±•ç¤ºä¸»è¦çš„æ•¸æ“šé¡å‹è½‰æ›æ¦‚å¿µ
summary_df = pd.DataFrame({
    'raw_string': ['1', '2.5', 'True', '2023-01-15', 'Category A'],
    'raw_value': [1, 2.5, True, pd.Timestamp('2023-01-15'), 'Category A']
})

# å±•ç¤ºåŸºæœ¬é¡å‹è½‰æ›
summary_df['to_int'] = pd.to_numeric(summary_df['raw_string'], errors='coerce').astype('Int64')
summary_df['to_float'] = pd.to_numeric(summary_df['raw_string'], errors='coerce')
summary_df['to_bool'] = summary_df['raw_string'].map({'True': True, 'False': False})
summary_df['to_datetime'] = pd.to_datetime(summary_df['raw_string'], errors='coerce')
summary_df['to_category'] = summary_df['raw_string'].astype('category')

print("æ•¸æ“šå‹æ…‹è½‰æ›ç¸½çµ:")
print(summary_df)
print("\nå„åˆ—çš„æ•¸æ“šé¡å‹:")
print(summary_df.dtypes)

# %% [markdown]
# ### 8.2 æ•¸æ“šè™•ç†çš„æœ€ä½³å¯¦è¸

# %% [markdown]
# 1. **æ•¸æ“šå‹æ…‹è½‰æ›åŸå‰‡**
#    - å§‹çµ‚åœ¨é€²è¡Œè¨ˆç®—å‰æª¢æŸ¥æ•¸æ“šé¡å‹
#    - å„ªå…ˆä½¿ç”¨ Pandas å…§å»ºçš„è½‰æ›å‡½æ•¸ (`to_numeric`, `to_datetime` ç­‰)
#    - è™•ç†éŒ¯èª¤æ™‚ä½¿ç”¨ `errors='coerce'` è½‰æ›å•é¡Œå€¼ç‚º NaNï¼Œè€Œéç›´æ¥å¤±æ•—
#    - ç‚ºå¤§å‹æ•¸æ“šé›†é¸æ“‡é©ç•¶çš„æ•¸æ“šé¡å‹ä»¥ç¯€çœå…§å­˜ï¼ˆå¦‚ `category`, `int32`ï¼‰
#
# 2. **æ•¸æ“šæ¸…æ´—æœ€ä½³å¯¦è¸**
#    - æ•¸æ“šå°å…¥å¾Œç«‹å³é€²è¡Œé¡å‹æª¢æŸ¥å’Œè½‰æ›ï¼Œè€Œéç­‰åˆ°éœ€è¦æ™‚
#    - å°æ–¼æ–‡æœ¬æ•¸æ“šï¼Œå»ºç«‹æ¨™æº–åŒ–çš„é è™•ç†æµç¨‹
#    - ä½¿ç”¨ `info()` å’Œ `describe()` æ–¹æ³•äº†è§£æ•¸æ“šæ¦‚æ³
#    - è¨˜éŒ„æ•¸æ“šè½‰æ›éç¨‹ï¼Œç¢ºä¿å¯è¤‡ç¾æ€§
#
# 3. **æ€§èƒ½å„ªåŒ–å»ºè­°**
#    - ä½¿ç”¨é¡åˆ¥å‹æ•¸æ“šæ¸›å°‘å…§å­˜ä½¿ç”¨
#    - ä½¿ç”¨ `astype()` æ‰¹é‡è½‰æ›æ¯”é€è¡Œè™•ç†æ›´é«˜æ•ˆ
#    - è€ƒæ…®ä½¿ç”¨ `category` å‹åˆ¥è™•ç†æœ‰é™å€¼é›†åˆï¼ˆå¦‚æ€§åˆ¥ã€åœ‹å®¶ï¼‰
#    - æ—¥æœŸè¨ˆç®—å„ªå…ˆä½¿ç”¨å‘é‡åŒ–æ“ä½œï¼Œé¿å… apply å¾ªç’°
#
# 4. **é€²éšå­¸ç¿’æ–¹å‘**
#    - **æ¢ç´¢æ€§æ•¸æ“šåˆ†æ**ï¼šå­¸ç¿’å¦‚ä½•ä½¿ç”¨æ­£ç¢ºçš„æ•¸æ“šé¡å‹é€²è¡Œé«˜æ•ˆ EDA
#    - **æ•¸æ“šè½‰æ›é€²éš**ï¼šæŒæ¡æ›´è¤‡é›œçš„æ•¸æ“šè½‰æ›æŠ€å·§å’Œå‡½æ•¸
#    - **å¤§æ•¸æ“šè™•ç†**ï¼šäº†è§£å¦‚ä½•è™•ç†è¨˜æ†¶é«”ç„¡æ³•å®¹ç´çš„å¤§å‹æ•¸æ“šé›†
#    - **è‡ªå®šç¾©æ•¸æ“šé¡å‹**ï¼šå­¸ç¿’å¦‚ä½•æ“´å±• Pandas çš„æ•¸æ“šé¡å‹ç³»çµ±

# %% [markdown]
# ### 8.3 æ•¸æ“šå‹æ…‹è½‰æ›çš„å¯¦éš›æ‡‰ç”¨

# %%
# å‰µå»ºä¸€å€‹åŒ…å«ä¸åŒæ•¸æ“šé¡å‹çš„ DataFrame
df = pd.DataFrame({
    'Integer': [1, 2, 3, 4, 5],
    'Float': [1.1, 2.2, 3.3, 4.4, 5.5],
    'String': ['a', 'b', 'c', 'd', 'e'],
    'Boolean': [True, False, True, False, True],
    'Date': pd.date_range('2023-01-01', periods=5),
    'Category': pd.Categorical(['A', 'B', 'A', 'C', 'B']),
    'Int_as_str': ['1', '2', '3', '4', '5'],
    'Mixed': [1, 'two', 3.0, True, '5']
})

# é¡¯ç¤º DataFrame
print("å…·æœ‰ä¸åŒæ•¸æ“šé¡å‹çš„ DataFrame:")
print(df)

# æª¢æŸ¥æ¯åˆ—çš„æ•¸æ“šé¡å‹
print("\nå„åˆ—çš„æ•¸æ“šé¡å‹:")
print(df.dtypes)

# ç²å–è©³ç´°çš„æ•¸æ“šé¡å‹ä¿¡æ¯
print("\næ›´è©³ç´°çš„æ•¸æ“šé¡å‹ä¿¡æ¯:")
print(df.info())

# %% [markdown]
# **è§£èªª**ï¼š
# - DataFrame è‡ªå‹•ç‚ºæ¯åˆ—é¸æ“‡é©ç•¶çš„æ•¸æ“šé¡å‹ï¼šæ•´æ•¸ã€æµ®é»æ•¸ã€å­—ç¬¦ä¸²(object)ã€æ—¥æœŸæ™‚é–“ç­‰
# - `dtypes` å±¬æ€§é¡¯ç¤ºæ¯åˆ—çš„æ•¸æ“šé¡å‹ï¼Œæ˜¯æª¢æŸ¥å’Œç¢ºèªæ•¸æ“šé¡å‹çš„å¿«é€Ÿæ–¹æ³•
# - `info()` æ–¹æ³•æä¾›æ›´è©³ç´°çš„ä¿¡æ¯ï¼ŒåŒ…æ‹¬éç©ºå€¼æ•¸é‡ã€æ•¸æ“šé¡å‹å’Œå…§å­˜ä½¿ç”¨
# - æ³¨æ„ `Int_as_str` åˆ—å­˜å„²çš„æ˜¯æ•¸å­—å­—ç¬¦ä¸²ï¼ŒPandas å°‡å…¶è­˜åˆ¥ç‚º object é¡å‹
# - `Mixed` åˆ—åŒ…å«ä¸åŒé¡å‹çš„æ•¸æ“šï¼ŒPandas è‡ªå‹•é¸æ“‡èƒ½å®¹ç´æ‰€æœ‰å€¼çš„æœ€é€šç”¨é¡å‹ (object)
# - é¡åˆ¥å‹æ•¸æ“šåœ¨è™•ç†æœ‰é™é›†åˆçš„å€¼æ™‚éå¸¸é«˜æ•ˆï¼Œå¦‚é€™è£¡çš„ 'A'ã€'B'ã€'C'
# - äº†è§£æ•¸æ“šé¡å‹æ˜¯æ­£ç¢ºè™•ç†å’Œåˆ†ææ•¸æ“šçš„ç¬¬ä¸€æ­¥ï¼Œå°¤å…¶åœ¨è™•ç†å¤§å‹æ•¸æ“šé›†æ™‚

# %% [markdown]
# ### 8.4 æ•¸æ“šå‹æ…‹è½‰æ›çš„å¸¸è¦‹å•é¡Œèˆ‡è§£æ±ºæ–¹æ¡ˆ

# %%
# å‰µå»ºä¸€å€‹åŒ…å«ä¸åŒæ•¸æ“šé¡å‹çš„ DataFrame
df = pd.DataFrame({
    'Integer': [1, 2, 3, 4, 5],
    'Float': [1.1, 2.2, 3.3, 4.4, 5.5],
    'String': ['a', 'b', 'c', 'd', 'e'],
    'Boolean': [True, False, True, False, True],
    'Date': pd.date_range('2023-01-01', periods=5),
    'Category': pd.Categorical(['A', 'B', 'A', 'C', 'B']),
    'Int_as_str': ['1', '2', '3', '4', '5'],
    'Mixed': [1, 'two', 3.0, True, '5']
})

# é¡¯ç¤º DataFrame
print("å…·æœ‰ä¸åŒæ•¸æ“šé¡å‹çš„ DataFrame:")
print(df)

# æª¢æŸ¥æ¯åˆ—çš„æ•¸æ“šé¡å‹
print("\nå„åˆ—çš„æ•¸æ“šé¡å‹:")
print(df.dtypes)

# ç²å–è©³ç´°çš„æ•¸æ“šé¡å‹ä¿¡æ¯
print("\næ›´è©³ç´°çš„æ•¸æ“šé¡å‹ä¿¡æ¯:")
print(df.info())

# %% [markdown]
# **è§£èªª**ï¼š
# - DataFrame è‡ªå‹•ç‚ºæ¯åˆ—é¸æ“‡é©ç•¶çš„æ•¸æ“šé¡å‹ï¼šæ•´æ•¸ã€æµ®é»æ•¸ã€å­—ç¬¦ä¸²(object)ã€æ—¥æœŸæ™‚é–“ç­‰
# - `dtypes` å±¬æ€§é¡¯ç¤ºæ¯åˆ—çš„æ•¸æ“šé¡å‹ï¼Œæ˜¯æª¢æŸ¥å’Œç¢ºèªæ•¸æ“šé¡å‹çš„å¿«é€Ÿæ–¹æ³•
# - `info()` æ–¹æ³•æä¾›æ›´è©³ç´°çš„ä¿¡æ¯ï¼ŒåŒ…æ‹¬éç©ºå€¼æ•¸é‡ã€æ•¸æ“šé¡å‹å’Œå…§å­˜ä½¿ç”¨
# - æ³¨æ„ `Int_as_str` åˆ—å­˜å„²çš„æ˜¯æ•¸å­—å­—ç¬¦ä¸²ï¼ŒPandas å°‡å…¶è­˜åˆ¥ç‚º object é¡å‹
# - `Mixed` åˆ—åŒ…å«ä¸åŒé¡å‹çš„æ•¸æ“šï¼ŒPandas è‡ªå‹•é¸æ“‡èƒ½å®¹ç´æ‰€æœ‰å€¼çš„æœ€é€šç”¨é¡å‹ (object)
# - é¡åˆ¥å‹æ•¸æ“šåœ¨è™•ç†æœ‰é™é›†åˆçš„å€¼æ™‚éå¸¸é«˜æ•ˆï¼Œå¦‚é€™è£¡çš„ 'A'ã€'B'ã€'C'
# - äº†è§£æ•¸æ“šé¡å‹æ˜¯æ­£ç¢ºè™•ç†å’Œåˆ†ææ•¸æ“šçš„ç¬¬ä¸€æ­¥ï¼Œå°¤å…¶åœ¨è™•ç†å¤§å‹æ•¸æ“šé›†æ™‚

# %% [markdown]
# ### 8.5 æ•¸æ“šå‹æ…‹è½‰æ›çš„å¯¦éš›æ‡‰ç”¨æ¡ˆä¾‹

# %%
# æ¨¡æ“¬ä¾†è‡ªä¸åŒä¾†æºçš„æ•¸æ“š
# ä¾†æº1: CSVæ ¼å¼çš„éŠ·å”®æ•¸æ“š
df1 = pd.DataFrame({
    'Date': ['2023-01-15', '2023-02-20', '2023-03-25'],
    'Product': ['A', 'B', 'C'],
    'Revenue': ['$1,200.50', '$950.25', '$1,500.75'],
    'Quantity': ['25', '18', '30']
})

# ä¾†æº2: JSONæ ¼å¼çš„ç”¢å“æ•¸æ“š
df2 = pd.DataFrame({
    'ProductID': ['A', 'B', 'C', 'D'],
    'Name': ['ProductA', 'ProductB', 'ProductC', 'ProductD'],
    'Price': [48.02, 52.79, 50.025, 65.5],
    'Category': ['Electronics', 'Home', 'Electronics', 'Clothing']
})

# ä¾†æº3: Excelæ ¼å¼çš„å®¢æˆ¶æ•¸æ“š
df3 = pd.DataFrame({
    'Date': ['15/01/2023', '20/02/2023', '25/03/2023'],
    'CustomerSegment': ['Premium', 'Standard', 'Premium'],
    'Region': ['North', 'South', 'West']
})

print("ä¾†æº1 - éŠ·å”®æ•¸æ“š (CSV):")
print(df1)
print("\nä¾†æº2 - ç”¢å“æ•¸æ“š (JSON):")
print(df2)
print("\nä¾†æº3 - å®¢æˆ¶æ•¸æ“š (Excel):")
print(df3)

# æ­¥é©Ÿ1: çµ±ä¸€æ•¸æ“šé¡å‹
# è½‰æ›æ—¥æœŸæ ¼å¼
df1['Date'] = pd.to_datetime(df1['Date'])
df3['Date'] = pd.to_datetime(df3['Date'], format='%d/%m/%Y')
print("\nçµ±ä¸€æ—¥æœŸæ ¼å¼å¾Œ:")
print(f"df1['Date'] å‹æ…‹: {df1['Date'].dtype}")
print(f"df3['Date'] å‹æ…‹: {df3['Date'].dtype}")

# è½‰æ›æ•¸å€¼å‹æ…‹
df1['Revenue'] = df1['Revenue'].str.replace('$', '').str.replace(',', '').astype(float)
df1['Quantity'] = df1['Quantity'].astype(int)
print("\nè½‰æ›æ•¸å€¼å¾Œçš„éŠ·å”®æ•¸æ“š:")
print(df1)

# æ­¥é©Ÿ2: åˆä½µæ•¸æ“š
# å°‡ç”¢å“æ•¸æ“šèˆ‡éŠ·å”®æ•¸æ“šåˆä½µ
df_merged1 = pd.merge(df1, df2, left_on='Product', right_on='ProductID', how='left')
print("\nåˆä½µç”¢å“èˆ‡éŠ·å”®æ•¸æ“š:")
print(df_merged1)

# å°‡å®¢æˆ¶æ•¸æ“šèˆ‡åˆä½µå¾Œçš„æ•¸æ“šå†åˆä½µ
df_final = pd.merge(df_merged1, df3, on='Date', how='left')
print("\næœ€çµ‚åˆä½µçš„æ•¸æ“š:")
print(df_final)

# æ­¥é©Ÿ3: æ•¸æ“šæª¢æŸ¥å’Œæ¸…ç†
# æª¢æŸ¥æ˜¯å¦æœ‰ç¼ºå¤±å€¼
print("\næª¢æŸ¥ç¼ºå¤±å€¼:")
print(df_final.isna().sum())

# è¨ˆç®—å–®åƒ¹ (Revenue / Quantity)
df_final['UnitRevenue'] = df_final['Revenue'] / df_final['Quantity']
print("\næ·»åŠ å–®åƒ¹è¨ˆç®—:")
print(df_final[['Product', 'Quantity', 'Revenue', 'UnitRevenue', 'Price']])

# æª¢æŸ¥å–®åƒ¹èˆ‡åƒ¹æ ¼çš„å·®ç•°
df_final['PriceDiff'] = df_final['UnitRevenue'] - df_final['Price']
print("\nå–®åƒ¹èˆ‡ç”¢å“åƒ¹æ ¼çš„å·®ç•°:")
print(df_final[['Product', 'UnitRevenue', 'Price', 'PriceDiff']])

# %% [markdown]
# ### 8.6 æ•¸æ“šå‹æ…‹è½‰æ›çš„å¯¦éš›æ‡‰ç”¨æ¡ˆä¾‹ï¼šè™•ç†çœŸå¯¦ä¸–ç•Œæ•¸æ“š

# %%
# å‰µå»ºæ¨¡æ“¬çš„ã€Œé«’ã€æ•¸æ“šCSVæ–‡ä»¶
import tempfile

csv_content = """
id,name,age,income,join_date,status
1, "Smith, John",35,75000.00,2022-01-15,active
2, "Johnson, Alice",,"$62,500",01/20/2022,ACTIVE
3, "Williams, Bob",42,55000,2022-02-10,inactive
4, "Brown, Carol",,45000.75,2022-01-05,Active
5, " Davis, Eric",38,$80250.25,02/15/2022,active
6, "Miller, Fiona",45,"68,300",2022/03/01,INACTIVE
7, " Wilson, George",,72100,20220320,pending
"""

temp_csv = tempfile.NamedTemporaryFile(delete=False, suffix='.csv')
with open(temp_csv.name, 'w') as f:
    f.write(csv_content)

print(f"å‰µå»ºæ¨¡æ“¬CSVæ–‡ä»¶: {temp_csv.name}")

# å˜—è©¦ç›´æ¥è®€å–æ•¸æ“š
df_raw = pd.read_csv(temp_csv.name, skipinitialspace=True)
print("\nåŸå§‹æ•¸æ“š (ç›´æ¥è®€å–):")
print(df_raw)
print("\næ•¸æ“šé¡å‹:")
print(df_raw.dtypes)

# ä»¥æ›´åˆé©çš„æ–¹å¼è®€å–ä¸¦è™•ç†æ•¸æ“š
df_clean = pd.read_csv(temp_csv.name, skipinitialspace=True)

# 1. è™•ç†åç¨±
df_clean['name'] = df_clean['name'].str.strip().str.replace('"', '')

# 2. è™•ç†å¹´é½¡ - ç¢ºä¿æ˜¯æ•´æ•¸
df_clean['age'] = pd.to_numeric(df_clean['age'], errors='coerce')

# 3. è™•ç†æ”¶å…¥ - æ¸…ç†è²¨å¹£ç¬¦è™Ÿå’Œåƒåˆ†ä½
df_clean['income'] = df_clean['income'].astype(str).str.replace('$', '').str.replace(',', '').str.replace('"', '')
df_clean['income'] = pd.to_numeric(df_clean['income'], errors='coerce')

# 4. è™•ç†æ—¥æœŸ - çµ±ä¸€æ ¼å¼
df_clean['join_date'] = pd.to_datetime(df_clean['join_date'], errors='coerce', format='mixed')

# 5. è™•ç†ç‹€æ…‹ - çµ±ä¸€å¤§å°å¯«ä¸¦åˆ†é¡
df_clean['status'] = df_clean['status'].str.lower()
df_clean['status'] = df_clean['status'].astype('category')

print("\næ¸…ç†å¾Œçš„æ•¸æ“š:")
print(df_clean)
print("\næ•¸æ“šé¡å‹:")
print(df_clean.dtypes)

# æª¢æŸ¥ç¼ºå¤±å€¼
print("\nç¼ºå¤±å€¼:")
print(df_clean.isna().sum())

# å¡«å……ç¼ºå¤±å€¼
df_clean['age'] = df_clean['age'].fillna(df_clean['age'].median())
print("\nå¡«å……ç¼ºå¤±å¹´é½¡å¾Œ:")
print(df_clean)

# å¯è¦–åŒ–æ”¶å…¥åˆ†ä½ˆ
plt.figure(figsize=(10, 6))
plt.hist(df_clean['income'].dropna(), bins=10)
plt.title('æ”¶å…¥åˆ†ä½ˆ')
plt.xlabel('æ”¶å…¥')
plt.ylabel('é »ç‡')
plt.grid(True, alpha=0.3)
plt.show()

# æœ€çµ‚æ¸…ç†å¥½çš„æ•¸æ“š
df_final = df_clean.copy()

# åˆªé™¤è‡¨æ™‚æ–‡ä»¶
import os
os.unlink(temp_csv.name)

# %% [markdown]
# ### 8.7 æ•¸æ“šå‹æ…‹è½‰æ›çš„å¯¦éš›æ‡‰ç”¨æ¡ˆä¾‹ï¼šæ•¸æ“šæ•´åˆèˆ‡æ¨™æº–åŒ–

# %%
# æ¨¡æ“¬ä¾†è‡ªä¸åŒä¾†æºçš„æ•¸æ“š
# ä¾†æº1: CSVæ ¼å¼çš„éŠ·å”®æ•¸æ“š
df1 = pd.DataFrame({
    'Date': ['2023-01-15', '2023-02-20', '2023-03-25'],
    'Product': ['A', 'B', 'C'],
    'Revenue': ['$1,200.50', '$950.25', '$1,500.75'],
    'Quantity': ['25', '18', '30']
})

# ä¾†æº2: JSONæ ¼å¼çš„ç”¢å“æ•¸æ“š
df2 = pd.DataFrame({
    'ProductID': ['A', 'B', 'C', 'D'],
    'Name': ['ProductA', 'ProductB', 'ProductC', 'ProductD'],
    'Price': [48.02, 52.79, 50.025, 65.5],
    'Category': ['Electronics', 'Home', 'Electronics', 'Clothing']
})

# ä¾†æº3: Excelæ ¼å¼çš„å®¢æˆ¶æ•¸æ“š
df3 = pd.DataFrame({
    'Date': ['15/01/2023', '20/02/2023', '25/03/2023'],
    'CustomerSegment': ['Premium', 'Standard', 'Premium'],
    'Region': ['North', 'South', 'West']
})

print("ä¾†æº1 - éŠ·å”®æ•¸æ“š (CSV):")
print(df1)
print("\nä¾†æº2 - ç”¢å“æ•¸æ“š (JSON):")
print(df2)
print("\nä¾†æº3 - å®¢æˆ¶æ•¸æ“š (Excel):")
print(df3)

# æ­¥é©Ÿ1: çµ±ä¸€æ•¸æ“šé¡å‹
# è½‰æ›æ—¥æœŸæ ¼å¼
df1['Date'] = pd.to_datetime(df1['Date'])
df3['Date'] = pd.to_datetime(df3['Date'], format='%d/%m/%Y')
print("\nçµ±ä¸€æ—¥æœŸæ ¼å¼å¾Œ:")
print(f"df1['Date'] å‹æ…‹: {df1['Date'].dtype}")
print(f"df3['Date'] å‹æ…‹: {df3['Date'].dtype}")

# è½‰æ›æ•¸å€¼å‹æ…‹
df1['Revenue'] = df1['Revenue'].str.replace('$', '').str.replace(',', '').astype(float)
df1['Quantity'] = df1['Quantity'].astype(int)
print("\nè½‰æ›æ•¸å€¼å¾Œçš„éŠ·å”®æ•¸æ“š:")
print(df1)

# æ­¥é©Ÿ2: åˆä½µæ•¸æ“š
# å°‡ç”¢å“æ•¸æ“šèˆ‡éŠ·å”®æ•¸æ“šåˆä½µ
df_merged1 = pd.merge(df1, df2, left_on='Product', right_on='ProductID', how='left')
print("\nåˆä½µç”¢å“èˆ‡éŠ·å”®æ•¸æ“š:")
print(df_merged1)

# å°‡å®¢æˆ¶æ•¸æ“šèˆ‡åˆä½µå¾Œçš„æ•¸æ“šå†åˆä½µ
df_final = pd.merge(df_merged1, df3, on='Date', how='left')
print("\næœ€çµ‚åˆä½µçš„æ•¸æ“š:")
print(df_final)

# æ­¥é©Ÿ3: æ•¸æ“šæª¢æŸ¥å’Œæ¸…ç†
# æª¢æŸ¥æ˜¯å¦æœ‰ç¼ºå¤±å€¼
print("\næª¢æŸ¥ç¼ºå¤±å€¼:")
print(df_final.isna().sum())

# è¨ˆç®—å–®åƒ¹ (Revenue / Quantity)
df_final['UnitRevenue'] = df_final['Revenue'] / df_final['Quantity']
print("\næ·»åŠ å–®åƒ¹è¨ˆç®—:")
print(df_final[['Product', 'Quantity', 'Revenue', 'UnitRevenue', 'Price']])

# æª¢æŸ¥å–®åƒ¹èˆ‡åƒ¹æ ¼çš„å·®ç•°
df_final['PriceDiff'] = df_final['UnitRevenue'] - df_final['Price']
print("\nå–®åƒ¹èˆ‡ç”¢å“åƒ¹æ ¼çš„å·®ç•°:")
print(df_final[['Product', 'UnitRevenue', 'Price', 'PriceDiff']])

# %% [markdown]
# ### 8.8 æ•¸æ“šå‹æ…‹è½‰æ›çš„å¯¦éš›æ‡‰ç”¨æ¡ˆä¾‹ï¼šæ•¸æ“šæ¸…æ´—èˆ‡é è™•ç†

# %%
# å‰µå»ºåŒ…å«é›œäº‚æ–‡æœ¬çš„ DataFrame
df_messy = pd.DataFrame({
    'Text': [
        '  This is a sample text! With some punctuation. ',
        'ANOTHER TEXT WITH ALL CAPITALS.',
        'URL: https://example.com/page.html',
        'Multiple   spaces   and\ttabs\tin this text',
        'Email: user123@example.com #hashtag'
    ]
})
print("åŸå§‹é›œäº‚æ–‡æœ¬:")
print(df_messy)

# åŸºæœ¬æ¸…æ´—æ­¥é©Ÿ
df_messy['Cleaned'] = df_messy['Text'].str.strip()  # ç§»é™¤å‰å¾Œç©ºç™½
df_messy['Cleaned'] = df_messy['Cleaned'].str.lower()  # è½‰ç‚ºå°å¯«
df_messy['Cleaned'] = df_messy['Cleaned'].str.replace(r'[^\w\s]', '', regex=True)  # ç§»é™¤æ¨™é»ç¬¦è™Ÿ
df_messy['Cleaned'] = df_messy['Cleaned'].str.replace(r'\s+', ' ', regex=True)  # ç§»é™¤å¤šé¤˜ç©ºç™½

print("\nåŸºæœ¬æ¸…æ´—å¾Œçš„æ–‡æœ¬:")
print(df_messy[['Text', 'Cleaned']])

# ç§»é™¤URLs
df_messy['No_URLs'] = df_messy['Text'].str.replace(r'https?://\S+', '', regex=True)
print("\nç§»é™¤URLs:")
print(df_messy[['Text', 'No_URLs']])

# ç§»é™¤Email
df_messy['No_Emails'] = df_messy['Text'].str.replace(r'\S+@\S+', '', regex=True)
print("\nç§»é™¤Emails:")
print(df_messy[['Text', 'No_Emails']])

# ç§»é™¤æ¨™ç±¤å’Œä¸»é¡Œæ¨™ç±¤
df_messy['No_Tags'] = df_messy['Text'].str.replace(r'#\w+', '', regex=True)
print("\nç§»é™¤æ¨™ç±¤:")
print(df_messy[['Text', 'No_Tags']])

# åˆ†è©
df_messy['Tokens'] = df_messy['Cleaned'].str.split()
print("\nåˆ†è©çµæœ:")
print(df_messy[['Cleaned', 'Tokens']])

# %% [markdown]
# **è§£èªª**ï¼š
# - æ–‡æœ¬æ•¸æ“šè™•ç†é€šå¸¸åŒ…æ‹¬æ¨™æº–åŒ–ï¼ˆå¤§å°å¯«çµ±ä¸€ï¼‰ã€æ¸…æ´—ï¼ˆç§»é™¤æ¨™é»ç¬¦è™Ÿã€å¤šé¤˜ç©ºç™½ï¼‰å’Œæ¨™è¨˜åŒ–ï¼ˆåˆ†è©ï¼‰
# - ä½¿ç”¨ `str.split()` å°‡æ–‡æœ¬åˆ‡åˆ†ç‚ºå–®è©åˆ—è¡¨ï¼Œä¾¿æ–¼å¾ŒçºŒåˆ†æ
# - è©é »çµ±è¨ˆæ˜¯æ–‡æœ¬åˆ†æçš„åŸºç¤ï¼Œå¯ä»¥å¾æ•´é«”æˆ–å–®æ¢æ–‡æœ¬çš„è§’åº¦è¨ˆç®—è©é »
# - æ–‡æœ¬æ¸…æ´—é€šå¸¸æ˜¯æ•¸æ“šåˆ†ææµç¨‹çš„ç¬¬ä¸€æ­¥ï¼Œå®ƒç‚ºå¾ŒçºŒçš„ç‰¹å¾µå·¥ç¨‹å’Œåˆ†æå¥ å®šåŸºç¤
# - Pandas çš„å­—ç¬¦ä¸²æ–¹æ³•æä¾›äº†é«˜æ•ˆçš„æ–‡æœ¬è™•ç†èƒ½åŠ›ï¼Œæ­é…æ­£å‰‡è¡¨é”å¼èƒ½è™•ç†è¤‡é›œçš„æ–‡æœ¬æ¨¡å¼

# %% [markdown]
# ### 8.9 æ•¸æ“šå‹æ…‹è½‰æ›çš„å¯¦éš›æ‡‰ç”¨æ¡ˆä¾‹ï¼šæ•¸æ“šæ•´åˆèˆ‡æ¨™æº–åŒ–

# %%
# æ¨¡æ“¬ä¾†è‡ªä¸åŒä¾†æºçš„æ•¸æ“š
# ä¾†æº1: CSVæ ¼å¼çš„éŠ·å”®æ•¸æ“š
df1 = pd.DataFrame({
    'Date': ['2023-01-15', '2023-02-20', '2023-03-25'],
    'Product': ['A', 'B', 'C'],
    'Revenue': ['$1,200.50', '$950.25', '$1,500.75'],
    'Quantity': ['25', '18', '30']
})

# ä¾†æº2: JSONæ ¼å¼çš„ç”¢å“æ•¸æ“š
df2 = pd.DataFrame({
    'ProductID': ['A', 'B', 'C', 'D'],
    'Name': ['ProductA', 'ProductB', 'ProductC', 'ProductD'],
    'Price': [48.02, 52.79, 50.025, 65.5],
    'Category': ['Electronics', 'Home', 'Electronics', 'Clothing']
})

# ä¾†æº3: Excelæ ¼å¼çš„å®¢æˆ¶æ•¸æ“š
df3 = pd.DataFrame({
    'Date': ['15/01/2023', '20/02/2023', '25/03/2023'],
    'CustomerSegment': ['Premium', 'Standard', 'Premium'],
    'Region': ['North', 'South', 'West']
})

print("ä¾†æº1 - éŠ·å”®æ•¸æ“š (CSV):")
print(df1)
print("\nä¾†æº2 - ç”¢å“æ•¸æ“š (JSON):")
print(df2)
print("\nä¾†æº3 - å®¢æˆ¶æ•¸æ“š (Excel):")
print(df3)

# æ­¥é©Ÿ1: çµ±ä¸€æ•¸æ“šé¡å‹
# è½‰æ›æ—¥æœŸæ ¼å¼
df1['Date'] = pd.to_datetime(df1['Date'])
df3['Date'] = pd.to_datetime(df3['Date'], format='%d/%m/%Y')
print("\nçµ±ä¸€æ—¥æœŸæ ¼å¼å¾Œ:")
print(f"df1['Date'] å‹æ…‹: {df1['Date'].dtype}")
print(f"df3['Date'] å‹æ…‹: {df3['Date'].dtype}")

# è½‰æ›æ•¸å€¼å‹æ…‹
df1['Revenue'] = df1['Revenue'].str.replace('$', '').str.replace(',', '').astype(float)
df1['Quantity'] = df1['Quantity'].astype(int)
print("\nè½‰æ›æ•¸å€¼å¾Œçš„éŠ·å”®æ•¸æ“š:")
print(df1)

# æ­¥é©Ÿ2: åˆä½µæ•¸æ“š
# å°‡ç”¢å“æ•¸æ“šèˆ‡éŠ·å”®æ•¸æ“šåˆä½µ
df_merged1 = pd.merge(df1, df2, left_on='Product', right_on='ProductID', how='left')
print("\nåˆä½µç”¢å“èˆ‡éŠ·å”®æ•¸æ“š:")
print(df_merged1)

# å°‡å®¢æˆ¶æ•¸æ“šèˆ‡åˆä½µå¾Œçš„æ•¸æ“šå†åˆä½µ
df_final = pd.merge(df_merged1, df3, on='Date', how='left')
print("\næœ€çµ‚åˆä½µçš„æ•¸æ“š:")
print(df_final)

# æ­¥é©Ÿ3: æ•¸æ“šæª¢æŸ¥å’Œæ¸…ç†
# æª¢æŸ¥æ˜¯å¦æœ‰ç¼ºå¤±å€¼
print("\næª¢æŸ¥ç¼ºå¤±å€¼:")
print(df_final.isna().sum())

# è¨ˆç®—å–®åƒ¹ (Revenue / Quantity)
df_final['UnitRevenue'] = df_final['Revenue'] / df_final['Quantity']
print("\næ·»åŠ å–®åƒ¹è¨ˆç®—:")
print(df_final[['Product', 'Quantity', 'Revenue', 'UnitRevenue', 'Price']])

# æª¢æŸ¥å–®åƒ¹èˆ‡åƒ¹æ ¼çš„å·®ç•°
df_final['PriceDiff'] = df_final['UnitRevenue'] - df_final['Price']
print("\nå–®åƒ¹èˆ‡ç”¢å“åƒ¹æ ¼çš„å·®ç•°:")
print(df_final[['Product', 'UnitRevenue', 'Price', 'PriceDiff']])

# %% [markdown]
# ### 8.10 æ•¸æ“šå‹æ…‹è½‰æ›çš„å¯¦éš›æ‡‰ç”¨æ¡ˆä¾‹ï¼šæ•¸æ“šæ¸…æ´—èˆ‡é è™•ç†

# %%
# å‰µå»ºåŒ…å«é›œäº‚æ–‡æœ¬çš„ DataFrame
df_messy = pd.DataFrame({
    'Text': [
        '  This is a sample text! With some punctuation. ',
        'ANOTHER TEXT WITH ALL CAPITALS.',
        'URL: https://example.com/page.html',
        'Multiple   spaces   and\ttabs\tin this text',
        'Email: user123@example.com #hashtag'
    ]
})
print("åŸå§‹é›œäº‚æ–‡æœ¬:")
print(df_messy)

# åŸºæœ¬æ¸…æ´—æ­¥é©Ÿ
df_messy['Cleaned'] = df_messy['Text'].str.strip()  # ç§»é™¤å‰å¾Œç©ºç™½
df_messy['Cleaned'] = df_messy['Cleaned'].str.lower()  # è½‰ç‚ºå°å¯«
df_messy['Cleaned'] = df_messy['Cleaned'].str.replace(r'[^\w\s]', '', regex=True)  # ç§»é™¤æ¨™é»ç¬¦è™Ÿ
df_messy['Cleaned'] = df_messy['Cleaned'].str.replace(r'\s+', ' ', regex=True)  # ç§»é™¤å¤šé¤˜ç©ºç™½

print("\nåŸºæœ¬æ¸…æ´—å¾Œçš„æ–‡æœ¬:")
print(df_messy[['Text', 'Cleaned']])

# ç§»é™¤URLs
df_messy['No_URLs'] = df_messy['Text'].str.replace(r'https?://\S+', '', regex=True)
print("\nç§»é™¤URLs:")
print(df_messy[['Text', 'No_URLs']])

# ç§»é™¤Email
df_messy['No_Emails'] = df_messy['Text'].str.replace(r'\S+@\S+', '', regex=True)
print("\nç§»é™¤Emails:")
print(df_messy[['Text', 'No_Emails']])

# ç§»é™¤æ¨™ç±¤å’Œä¸»é¡Œæ¨™ç±¤
df_messy['No_Tags'] = df_messy['Text'].str.replace(r'#\w+', '', regex=True)
print("\nç§»é™¤æ¨™ç±¤:")
print(df_messy[['Text', 'No_Tags']])

# åˆ†è©
df_messy['Tokens'] = df_messy['Cleaned'].str.split()
print("\nåˆ†è©çµæœ:")
print(df_messy[['Cleaned', 'Tokens']])

# %% [markdown]
# **è§£èªª**ï¼š
# - æ–‡æœ¬æ•¸æ“šè™•ç†é€šå¸¸åŒ…æ‹¬æ¨™æº–åŒ–ï¼ˆå¤§å°å¯«çµ±ä¸€ï¼‰ã€æ¸…æ´—ï¼ˆç§»é™¤æ¨™é»ç¬¦è™Ÿã€å¤šé¤˜ç©ºç™½ï¼‰å’Œæ¨™è¨˜åŒ–ï¼ˆåˆ†è©ï¼‰
# - ä½¿ç”¨ `str.split()` å°‡æ–‡æœ¬åˆ‡åˆ†ç‚ºå–®è©åˆ—è¡¨ï¼Œä¾¿æ–¼å¾ŒçºŒåˆ†æ
# - è©é »çµ±è¨ˆæ˜¯æ–‡æœ¬åˆ†æçš„åŸºç¤ï¼Œå¯ä»¥å¾æ•´é«”æˆ–å–®æ¢æ–‡æœ¬çš„è§’åº¦è¨ˆç®—è©é »
# - æ–‡æœ¬æ¸…æ´—é€šå¸¸æ˜¯æ•¸æ“šåˆ†ææµç¨‹çš„ç¬¬ä¸€æ­¥ï¼Œå®ƒç‚ºå¾ŒçºŒçš„ç‰¹å¾µå·¥ç¨‹å’Œåˆ†æå¥ å®šåŸºç¤
# - Pandas çš„å­—ç¬¦ä¸²æ–¹æ³•æä¾›äº†é«˜æ•ˆçš„æ–‡æœ¬è™•ç†èƒ½åŠ›ï¼Œæ­é…æ­£å‰‡è¡¨é”å¼èƒ½è™•ç†è¤‡é›œçš„æ–‡æœ¬æ¨¡å¼

# %% [markdown]
# ### 8.11 æ•¸æ“šå‹æ…‹è½‰æ›çš„å¯¦éš›æ‡‰ç”¨æ¡ˆä¾‹ï¼šæ•¸æ“šæ•´åˆèˆ‡æ¨™æº–åŒ–

# %%
# æ¨¡æ“¬ä¾†è‡ªä¸åŒä¾†æºçš„æ•¸æ“š
# ä¾†æº1: CSVæ ¼å¼çš„éŠ·å”®æ•¸æ“š
df1 = pd.DataFrame({
    'Date': ['2023-01-15', '2023-02-20', '2023-03-25'],
    'Product': ['A', 'B', 'C'],
    'Revenue': ['$1,200.50', '$950.25', '$1,500.75'],
    'Quantity': ['25', '18', '30']
})

# ä¾†æº2: JSONæ ¼å¼çš„ç”¢å“æ•¸æ“š
df2 = pd.DataFrame({
    'ProductID': ['A', 'B', 'C', 'D'],
    'Name': ['ProductA', 'ProductB', 'ProductC', 'ProductD'],
    'Price': [48.02, 52.79, 50.025, 65.5],
    'Category': ['Electronics', 'Home', 'Electronics', 'Clothing']
})

# ä¾†æº3: Excelæ ¼å¼çš„å®¢æˆ¶æ•¸æ“š
df3 = pd.DataFrame({
    'Date': ['15/01/2023', '20/02/2023', '25/03/2023'],
    'CustomerSegment': ['Premium', 'Standard', 'Premium'],
    'Region': ['North', 'South', 'West']
})

print("ä¾†æº1 - éŠ·å”®æ•¸æ“š (CSV):")
print(df1)
print("\nä¾†æº2 - ç”¢å“æ•¸æ“š (JSON):")
print(df2)
print("\nä¾†æº3 - å®¢æˆ¶æ•¸æ“š (Excel):")
print(df3)

# æ­¥é©Ÿ1: çµ±ä¸€æ•¸æ“šé¡å‹
# è½‰æ›æ—¥æœŸæ ¼å¼
df1['Date'] = pd.to_datetime(df1['Date'])
df3['Date'] = pd.to_datetime(df3['Date'], format='%d/%m/%Y')
print("\nçµ±ä¸€æ—¥æœŸæ ¼å¼å¾Œ:")
print(f"df1['Date'] å‹æ…‹: {df1['Date'].dtype}")
print(f"df3['Date'] å‹æ…‹: {df3['Date'].dtype}")

# è½‰æ›æ•¸å€¼å‹æ…‹
df1['Revenue'] = df1['Revenue'].str.replace('$', '').str.replace(',', '').astype(float)
df1['Quantity'] = df1['Quantity'].astype(int)
print("\nè½‰æ›æ•¸å€¼å¾Œçš„éŠ·å”®æ•¸æ“š:")
print(df1)

# æ­¥é©Ÿ2: åˆä½µæ•¸æ“š
# å°‡ç”¢å“æ•¸æ“šèˆ‡éŠ·å”®æ•¸æ“šåˆä½µ
df_merged1 = pd.merge(df1, df2, left_on='Product', right_on='ProductID', how='left')
print("\nåˆä½µç”¢å“èˆ‡éŠ·å”®æ•¸æ“š:")
print(df_merged1)

# å°‡å®¢æˆ¶æ•¸æ“šèˆ‡åˆä½µå¾Œçš„æ•¸æ“šå†åˆä½µ
df_final = pd.merge(df_merged1, df3, on='Date', how='left')
print("\næœ€çµ‚åˆä½µçš„æ•¸æ“š:")
print(df_final)

# æ­¥é©Ÿ3: æ•¸æ“šæª¢æŸ¥å’Œæ¸…ç†
# æª¢æŸ¥æ˜¯å¦æœ‰ç¼ºå¤±å€¼
print("\næª¢æŸ¥ç¼ºå¤±å€¼:")
print(df_final.isna().sum())

# è¨ˆç®—å–®åƒ¹ (Revenue / Quantity)
df_final['UnitRevenue'] = df_final['Revenue'] / df_final['Quantity']
print("\næ·»åŠ å–®åƒ¹è¨ˆç®—:")
print(df_final[['Product', 'Quantity', 'Revenue', 'UnitRevenue', 'Price']])

# æª¢æŸ¥å–®åƒ¹èˆ‡åƒ¹æ ¼çš„å·®ç•°
df_final['PriceDiff'] = df_final['UnitRevenue'] - df_final['Price']
print("\nå–®åƒ¹èˆ‡ç”¢å“åƒ¹æ ¼çš„å·®ç•°:")
print(df_final[['Product', 'UnitRevenue', 'Price', 'PriceDiff']])

# %% [markdown]
# ### 8.12 æ•¸æ“šå‹æ…‹è½‰æ›çš„å¯¦éš›æ‡‰ç”¨æ¡ˆä¾‹ï¼šæ•¸æ“šæ¸…æ´—èˆ‡é è™•ç†

# %%
# å‰µå»ºåŒ…å«é›œäº‚æ–‡æœ¬çš„ DataFrame
df_messy = pd.DataFrame({
    'Text': [
        '  This is a sample text! With some punctuation. ',
        'ANOTHER TEXT WITH ALL CAPITALS.',
        'URL: https://example.com/page.html',
        'Multiple   spaces   and\ttabs\tin this text',
        'Email: user123@example.com #hashtag'
    ]
})
print("åŸå§‹é›œäº‚æ–‡æœ¬:")
print(df_messy)

# åŸºæœ¬æ¸…æ´—æ­¥é©Ÿ
df_messy['Cleaned'] = df_messy['Text'].str.strip()  # ç§»é™¤å‰å¾Œç©ºç™½
df_messy['Cleaned'] = df_messy['Cleaned'].str.lower()  # è½‰ç‚ºå°å¯«
df_messy['Cleaned'] = df_messy['Cleaned'].str.replace(r'[^\w\s]', '', regex=True)  # ç§»é™¤æ¨™é»ç¬¦è™Ÿ
df_messy['Cleaned'] = df_messy['Cleaned'].str.replace(r'\s+', ' ', regex=True)  # ç§»é™¤å¤šé¤˜ç©ºç™½

print("\nåŸºæœ¬æ¸…æ´—å¾Œçš„æ–‡æœ¬:")
print(df_messy[['Text', 'Cleaned']])

# ç§»é™¤URLs
df_messy['No_URLs'] = df_messy['Text'].str.replace(r'https?://\S+', '', regex=True)
print("\nç§»é™¤URLs:")
print(df_messy[['Text', 'No_URLs']])

# ç§»é™¤Email
df_messy['No_Emails'] = df_messy['Text'].str.replace(r'\S+@\S+', '', regex=True)
print("\nç§»é™¤Emails:")
print(df_messy[['Text', 'No_Emails']])

# ç§»é™¤æ¨™ç±¤å’Œä¸»é¡Œæ¨™ç±¤
df_messy['No_Tags'] = df_messy['Text'].str.replace(r'#\w+', '', regex=True)
print("\nç§»é™¤æ¨™ç±¤:")
print(df_messy[['Text', 'No_Tags']])

# åˆ†è©
df_messy['Tokens'] = df_messy['Cleaned'].str.split()
print("\nåˆ†è©çµæœ:")
print(df_messy[['Cleaned', 'Tokens']])

# %% [markdown]
# **è§£èªª**ï¼š
# - æ–‡æœ¬æ•¸æ“šè™•ç†é€šå¸¸åŒ…æ‹¬æ¨™æº–åŒ–ï¼ˆå¤§å°å¯«çµ±ä¸€ï¼‰ã€æ¸…æ´—ï¼ˆç§»é™¤æ¨™é»ç¬¦è™Ÿã€å¤šé¤˜ç©ºç™½ï¼‰å’Œæ¨™è¨˜åŒ–ï¼ˆåˆ†è©ï¼‰
# - ä½¿ç”¨ `str.split()` å°‡æ–‡æœ¬åˆ‡åˆ†ç‚ºå–®è©åˆ—è¡¨ï¼Œä¾¿æ–¼å¾ŒçºŒåˆ†æ
# - è©é »çµ±è¨ˆæ˜¯æ–‡æœ¬åˆ†æçš„åŸºç¤ï¼Œå¯ä»¥å¾æ•´é«”æˆ–å–®æ¢æ–‡æœ¬çš„è§’åº¦è¨ˆç®—è©é »
# - æ–‡æœ¬æ¸…æ´—é€šå¸¸æ˜¯æ•¸æ“šåˆ†ææµç¨‹çš„ç¬¬ä¸€æ­¥ï¼Œå®ƒç‚ºå¾ŒçºŒçš„ç‰¹å¾µå·¥ç¨‹å’Œåˆ†æå¥ å®šåŸºç¤
# - Pandas çš„å­—ç¬¦ä¸²æ–¹æ³•æä¾›äº†é«˜æ•ˆçš„æ–‡æœ¬è™•ç†èƒ½åŠ›ï¼Œæ­é…æ­£å‰‡è¡¨é”å¼èƒ½è™•ç†è¤‡é›œçš„æ–‡æœ¬æ¨¡å¼

# %% [markdown]
# ### 8.13 æ•¸æ“šå‹æ…‹è½‰æ›çš„å¯¦éš›æ‡‰ç”¨æ¡ˆä¾‹ï¼šæ•¸æ“šæ•´åˆèˆ‡æ¨™æº–åŒ–

# %%
# æ¨¡æ“¬ä¾†è‡ªä¸åŒä¾†æºçš„æ•¸æ“š
# ä¾†æº1: CSVæ ¼å¼çš„éŠ·å”®æ•¸æ“š
df1 = pd.DataFrame({
    'Date': ['2023-01-15', '2023-02-20', '2023-03-25'],
    'Product': ['A', 'B', 'C'],
    'Revenue': ['$1,200.50', '$950.25', '$1,500.75'],
    'Quantity': ['25', '18', '30']
})

# ä¾†æº2: JSONæ ¼å¼çš„ç”¢å“æ•¸æ“š
df2 = pd.DataFrame({
    'ProductID': ['A', 'B', 'C', 'D'],
    'Name': ['ProductA', 'ProductB', 'ProductC', 'ProductD'],
    'Price': [48.02, 52.79, 50.025, 65.5],
    'Category': ['Electronics', 'Home', 'Electronics', 'Clothing']
})

# ä¾†æº3: Excelæ ¼å¼çš„å®¢æˆ¶æ•¸æ“š
df3 = pd.DataFrame({
    'Date': ['15/01/2023', '20/02/2023', '25/03/2023'],
    'CustomerSegment': ['Premium', 'Standard', 'Premium'],
    'Region': ['North', 'South', 'West']
})

print("ä¾†æº1 - éŠ·å”®æ•¸æ“š (CSV):")
print(df1)
print("\nä¾†æº2 - ç”¢å“æ•¸æ“š (JSON):")
print(df2)
print("\nä¾†æº3 - å®¢æˆ¶æ•¸æ“š (Excel):")
print(df3)

# æ­¥é©Ÿ1: çµ±ä¸€æ•¸æ“šé¡å‹
# è½‰æ›æ—¥æœŸæ ¼å¼
df1['Date'] = pd.to_datetime(df1['Date'])
df3['Date'] = pd.to_datetime(df3['Date'], format='%d/%m/%Y')
print("\nçµ±ä¸€æ—¥æœŸæ ¼å¼å¾Œ:")
print(f"df1['Date'] å‹æ…‹: {df1['Date'].dtype}")
print(f"df3['Date'] å‹æ…‹: {df3['Date'].dtype}")

# è½‰æ›æ•¸å€¼å‹æ…‹
df1['Revenue'] = df1['Revenue'].str.replace('$', '').str.replace(',', '').astype(float)
df1['Quantity'] = df1['Quantity'].astype(int)
print("\nè½‰æ›æ•¸å€¼å¾Œçš„éŠ·å”®æ•¸æ“š:")
print(df1)

# æ­¥é©Ÿ2: åˆä½µæ•¸æ“š
# å°‡ç”¢å“æ•¸æ“šèˆ‡éŠ·å”®æ•¸æ“šåˆä½µ
df_merged1 = pd.merge(df1, df2, left_on='Product', right_on='ProductID', how='left')
print("\nåˆä½µç”¢å“èˆ‡éŠ·å”®æ•¸æ“š:")
print(df_merged1)

# å°‡å®¢æˆ¶æ•¸æ“šèˆ‡åˆä½µå¾Œçš„æ•¸æ“šå†åˆä½µ
df_final = pd.merge(df_merged1, df3, on='Date', how='left')
print("\næœ€çµ‚åˆä½µçš„æ•¸æ“š:")
print(df_final)

# æ­¥é©Ÿ3: æ•¸æ“šæª¢æŸ¥å’Œæ¸…ç†
# æª¢æŸ¥æ˜¯å¦æœ‰ç¼ºå¤±å€¼
print("\næª¢æŸ¥ç¼ºå¤±å€¼:")
print(df_final.isna().sum())

# è¨ˆç®—å–®åƒ¹ (Revenue / Quantity)
df_final['UnitRevenue'] = df_final['Revenue'] / df_final['Quantity']
print("\næ·»åŠ å–®åƒ¹è¨ˆç®—:")
print(df_final[['Product', 'Quantity', 'Revenue', 'UnitRevenue', 'Price']])

# æª¢æŸ¥å–®åƒ¹èˆ‡åƒ¹æ ¼çš„å·®ç•°
df_final['PriceDiff'] = df_final['UnitRevenue'] - df_final['Price']
print("\nå–®åƒ¹èˆ‡ç”¢å“åƒ¹æ ¼çš„å·®ç•°:")
print(df_final[['Product', 'UnitRevenue', 'Price', 'PriceDiff']])

# %% [markdown]
# ### 8.14 æ•¸æ“šå‹æ…‹è½‰æ›çš„å¯¦éš›æ‡‰ç”¨æ¡ˆä¾‹ï¼šæ•¸æ“šæ¸…æ´—èˆ‡é è™•ç†

# %%
# å‰µå»ºåŒ…å«é›œäº‚æ–‡æœ¬çš„ DataFrame
df_messy = pd.DataFrame({
    'Text': [
        '  This is a sample text! With some punctuation. ',
        'ANOTHER TEXT WITH ALL CAPITALS.',
        'URL: https://example.com/page.html',
        'Multiple   spaces   and\ttabs\tin this text',
        'Email: user123@example.com #hashtag'
    ]
})
print("åŸå§‹é›œäº‚æ–‡æœ¬:")
print(df_messy)

# åŸºæœ¬æ¸…æ´—æ­¥é©Ÿ
df_messy['Cleaned'] = df_messy['Text'].str.strip()  # ç§»é™¤å‰å¾Œç©ºç™½
df_messy['Cleaned'] = df_messy['Cleaned'].str.lower()  # è½‰ç‚ºå°å¯«
df_messy['Cleaned'] = df_messy['Cleaned'].str.replace(r'[^\w\s]', '', regex=True)  # ç§»é™¤æ¨™é»ç¬¦è™Ÿ
df_messy['Cleaned'] = df_messy['Cleaned'].str.replace(r'\s+', ' ', regex=True)  # ç§»é™¤å¤šé¤˜ç©ºç™½

print("\nåŸºæœ¬æ¸…æ´—å¾Œçš„æ–‡æœ¬:")
print(df_messy[['Text', 'Cleaned']])

# ç§»é™¤URLs
df_messy['No_URLs'] = df_messy['Text'].str.replace(r'https?://\S+', '', regex=True)
print("\nç§»é™¤URLs:")
print(df_messy[['Text', 'No_URLs']])

# ç§»é™¤Email
df_messy['No_Emails'] = df_messy['Text'].str.replace(r'\S+@\S+', '', regex=True)
print("\nç§»é™¤Emails:")
print(df_messy[['Text', 'No_Emails']])

# ç§»é™¤æ¨™ç±¤å’Œä¸»é¡Œæ¨™ç±¤
df_messy['No_Tags'] = df_messy['Text'].str.replace(r'#\w+', '', regex=True)
print("\nç§»é™¤æ¨™ç±¤:")
print(df_messy[['Text', 'No_Tags']])

# åˆ†è©
df_messy['Tokens'] = df_messy['Cleaned'].str.split()
print("\nåˆ†è©çµæœ:")
print(df_messy[['Cleaned', 'Tokens']])

# %% [markdown]
# **è§£èªª**ï¼š
# - æ–‡æœ¬æ•¸æ“šè™•ç†é€šå¸¸åŒ…æ‹¬æ¨™æº–åŒ–ï¼ˆå¤§å°å¯«çµ±ä¸€ï¼‰ã€æ¸…æ´—ï¼ˆç§»é™¤æ¨™é»ç¬¦è™Ÿã€å¤šé¤˜ç©ºç™½ï¼‰å’Œæ¨™è¨˜åŒ–ï¼ˆåˆ†è©ï¼‰
# - ä½¿ç”¨ `str.split()` å°‡æ–‡æœ¬åˆ‡åˆ†ç‚ºå–®è©åˆ—è¡¨ï¼Œä¾¿æ–¼å¾ŒçºŒåˆ†æ
# - è©é »çµ±è¨ˆæ˜¯æ–‡æœ¬åˆ†æçš„åŸºç¤ï¼Œå¯ä»¥å¾æ•´é«”æˆ–å–®æ¢æ–‡æœ¬çš„è§’åº¦è¨ˆç®—è©é »
# - æ–‡æœ¬æ¸…æ´—é€šå¸¸æ˜¯æ•¸æ“šåˆ†ææµç¨‹çš„ç¬¬ä¸€æ­¥ï¼Œå®ƒç‚ºå¾ŒçºŒçš„ç‰¹å¾µå·¥ç¨‹å’Œåˆ†æå¥ å®šåŸºç¤
# - Pandas çš„å­—ç¬¦ä¸²æ–¹æ³•æä¾›äº†é«˜æ•ˆçš„æ–‡æœ¬è™•ç†èƒ½åŠ›ï¼Œæ­é…æ­£å‰‡è¡¨é”å¼èƒ½è™•ç†è¤‡é›œçš„æ–‡æœ¬æ¨¡å¼

# %% [markdown]
# ### 8.15 æ•¸æ“šå‹æ…‹è½‰æ›çš„å¯¦éš›æ‡‰ç”¨æ¡ˆä¾‹ï¼šæ•¸æ“šæ•´åˆèˆ‡æ¨™æº–åŒ–

# %%
# æ¨¡æ“¬ä¾†è‡ªä¸åŒä¾†æºçš„æ•¸æ“š
# ä¾†æº1: CSVæ ¼å¼çš„éŠ·å”®æ•¸æ“š
df1 = pd.DataFrame({
    'Date': ['2023-01-15', '2023-02-20', '2023-03-25'],
    'Product': ['A', 'B', 'C'],
    'Revenue': ['$1,200.50', '$950.25', '$1,500.75'],
    'Quantity': ['25', '18', '30']
})

# ä¾†æº2: JSONæ ¼å¼çš„ç”¢å“æ•¸æ“š
df2 = pd.DataFrame({
    'ProductID': ['A', 'B', 'C', 'D'],
    'Name': ['ProductA', 'ProductB', 'ProductC', 'ProductD'],
    'Price': [48.02, 52.79, 50.025, 65.5],
    'Category': ['Electronics', 'Home', 'Electronics', 'Clothing']
})

# ä¾†æº3: Excelæ ¼å¼çš„å®¢æˆ¶æ•¸æ“š
df3 = pd.DataFrame({
    'Date': ['15/01/2023', '20/02/2023', '25/03/2023'],
    'CustomerSegment': ['Premium', 'Standard', 'Premium'],
    'Region': ['North', 'South', 'West']
})

print("ä¾†æº1 - éŠ·å”®æ•¸æ“š (CSV):")
print(df1)
print("\nä¾†æº2 - ç”¢å“æ•¸æ“š (JSON):")
print(df2)
print("\nä¾†æº3 - å®¢æˆ¶æ•¸æ“š (Excel):")
print(df3)

# æ­¥é©Ÿ1: çµ±ä¸€æ•¸æ“šé¡å‹
# è½‰æ›æ—¥æœŸæ ¼å¼
df1['Date'] = pd.to_datetime(df1['Date'])
df3['Date'] = pd.to_datetime(df3['Date'], format='%d/%m/%Y')
print("\nçµ±ä¸€æ—¥æœŸæ ¼å¼å¾Œ:")
print(f"df1['Date'] å‹æ…‹: {df1['Date'].dtype}")
print(f"df3['Date'] å‹æ…‹: {df3['Date'].dtype}")

# è½‰æ›æ•¸å€¼å‹æ…‹
df1['Revenue'] = df1['Revenue'].str.replace('$', '').str.replace(',', '').astype(float)
df1['Quantity'] = df1['Quantity'].astype(int)
print("\nè½‰æ›æ•¸å€¼å¾Œçš„éŠ·å”®æ•¸æ“š:")
print(df1)

# æ­¥é©Ÿ2: åˆä½µæ•¸æ“š
# å°‡ç”¢å“æ•¸æ“šèˆ‡éŠ·å”®æ•¸æ“šåˆä½µ
df_merged1 = pd.merge(df1, df2, left_on='Product', right_on='ProductID', how='left')
print("\nåˆä½µç”¢å“èˆ‡éŠ·å”®æ•¸æ“š:")
print(df_merged1)

# å°‡å®¢æˆ¶æ•¸æ“šèˆ‡åˆä½µå¾Œçš„æ•¸æ“šå†åˆä½µ
df_final = pd.merge(df_merged1, df3, on='Date', how='left')
print("\næœ€çµ‚åˆä½µçš„æ•¸æ“š:")
print(df_final)

# æ­¥é©Ÿ3: æ•¸æ“šæª¢æŸ¥å’Œæ¸…ç†
# æª¢æŸ¥æ˜¯å¦æœ‰ç¼ºå¤±å€¼
print("\næª¢æŸ¥ç¼ºå¤±å€¼:")
print(df_final.isna().sum())

# è¨ˆç®—å–®åƒ¹ (Revenue / Quantity)
df_final['UnitRevenue'] = df_final['Revenue'] / df_final['Quantity']
print("\næ·»åŠ å–®åƒ¹è¨ˆç®—:")
print(df_final[['Product', 'Quantity', 'Revenue', 'UnitRevenue', 'Price']])

# æª¢æŸ¥å–®åƒ¹èˆ‡åƒ¹æ ¼çš„å·®ç•°
df_final['PriceDiff'] = df_final['UnitRevenue'] - df_final['Price']
print("\nå–®åƒ¹èˆ‡ç”¢å“åƒ¹æ ¼çš„å·®ç•°:")
print(df_final[['Product', 'UnitRevenue', 'Price', 'PriceDiff']])

# %% [markdown]
# ### 8.16 æ•¸æ“šå‹æ…‹è½‰æ›çš„å¯¦éš›æ‡‰ç”¨æ¡ˆä¾‹ï¼šæ•¸æ“šæ¸…æ´—èˆ‡é è™•ç†

# %%
# å‰µå»ºåŒ…å«é›œäº‚æ–‡æœ¬çš„ DataFrame
df_messy = pd.DataFrame({
    'Text': [
        '  This is a sample text! With some punctuation. ',
        'ANOTHER TEXT WITH ALL CAPITALS.',
        'URL: https://example.com/page.html',
        'Multiple   spaces   and\ttabs\tin this text',
        'Email: user123@example.com #hashtag'
    ]
})
print("åŸå§‹é›œäº‚æ–‡æœ¬:")
print(df_messy)

# åŸºæœ¬æ¸…æ´—æ­¥é©Ÿ
df_messy['Cleaned'] = df_messy['Text'].str.strip()  # ç§»é™¤å‰å¾Œç©ºç™½
df_messy['Cleaned'] = df_messy['Cleaned'].str.lower()  # è½‰ç‚ºå°å¯«
df_messy['Cleaned'] = df_messy['Cleaned'].str.replace(r'[^\w\s]', '', regex=True)  # ç§»é™¤æ¨™é»ç¬¦è™Ÿ
df_messy['Cleaned'] = df_messy['Cleaned'].str.replace(r'\s+', ' ', regex=True)  # ç§»é™¤å¤šé¤˜ç©ºç™½

print("\nåŸºæœ¬æ¸…æ´—å¾Œçš„æ–‡æœ¬:")
print(df_messy[['Text', 'Cleaned']])

# ç§»é™¤URLs
df_messy['No_URLs'] = df_messy['Text'].str.replace(r'https?://\S+', '', regex=True)
print("\nç§»é™¤URLs:")
print(df_messy[['Text', 'No_URLs']])

# ç§»é™¤Email
df_messy['No_Emails'] = df_messy['Text'].str.replace(r'\S+@\S+', '', regex=True)
print("\nç§»é™¤Emails:")
print(df_messy[['Text', 'No_Emails']])

# ç§»é™¤æ¨™ç±¤å’Œä¸»é¡Œæ¨™ç±¤
df_messy['No_Tags'] = df_messy['Text'].str.replace(r'#\w+', '', regex=True)
print("\nç§»é™¤æ¨™ç±¤:")
print(df_messy[['Text', 'No_Tags']])

# åˆ†è©
df_messy['Tokens'] = df_messy['Cleaned'].str.split()
print("\nåˆ†è©çµæœ:")
print(df_messy[['Cleaned', 'Tokens']])

# %% [markdown]
# **è§£èªª**ï¼š
# - æ–‡æœ¬æ•¸æ“šè™•ç†é€šå¸¸åŒ…æ‹¬æ¨™æº–åŒ–ï¼ˆå¤§å°å¯«çµ±ä¸€ï¼‰ã€æ¸…æ´—ï¼ˆç§»é™¤æ¨™é»ç¬¦è™Ÿã€å¤šé¤˜ç©ºç™½ï¼‰å’Œæ¨™è¨˜åŒ–ï¼ˆåˆ†è©ï¼‰
# - ä½¿ç”¨ `str.split()` å°‡æ–‡æœ¬åˆ‡åˆ†ç‚ºå–®è©åˆ—è¡¨ï¼Œä¾¿æ–¼å¾ŒçºŒåˆ†æ
# - è©é »çµ±è¨ˆæ˜¯æ–‡æœ¬åˆ†æçš„åŸºç¤ï¼Œå¯ä»¥å¾æ•´é«”æˆ–å–®æ¢æ–‡æœ¬çš„è§’åº¦è¨ˆç®—è©é »
# - æ–‡æœ¬æ¸…æ´—é€šå¸¸æ˜¯æ•¸æ“šåˆ†ææµç¨‹çš„ç¬¬ä¸€æ­¥ï¼Œå®ƒç‚ºå¾ŒçºŒçš„ç‰¹å¾µå·¥ç¨‹å’Œåˆ†æå¥ å®šåŸºç¤
# - Pandas çš„å­—ç¬¦ä¸²æ–¹æ³•æä¾›äº†é«˜æ•ˆçš„æ–‡æœ¬è™•ç†èƒ½åŠ›ï¼Œæ­é…æ­£å‰‡è¡¨é”å¼èƒ½è™•ç†è¤‡é›œçš„æ–‡æœ¬æ¨¡å¼

# %% [markdown]
# ### 8.17 æ•¸æ“šå‹æ…‹è½‰æ›çš„å¯¦éš›æ‡‰ç”¨æ¡ˆä¾‹ï¼šæ•¸æ“šæ•´åˆèˆ‡æ¨™æº–åŒ–

# %%
# æ¨¡æ“¬ä¾†è‡ªä¸åŒä¾†æºçš„æ•¸æ“š
# ä¾†æº1: CSVæ ¼å¼çš„éŠ·å”®æ•¸æ“š
df1 = pd.DataFrame({
    'Date': ['2023-01-15', '2023-02-20', '2023-03-25'],
    'Product': ['A', 'B', 'C'],
    'Revenue': ['$1,200.50', '$950.25', '$1,500.75'],
    'Quantity': ['25', '18', '30']
})

# ä¾†æº2: JSONæ ¼å¼çš„ç”¢å“æ•¸æ“š
df2 = pd.DataFrame({
    'ProductID': ['A', 'B', 'C', 'D'],
    'Name': ['ProductA', 'ProductB', 'ProductC', 'ProductD'],
    'Price': [48.02, 52.79, 50.025, 65.5],
    'Category': ['Electronics', 'Home', 'Electronics', 'Clothing']
})

# ä¾†æº3: Excelæ ¼å¼çš„å®¢æˆ¶æ•¸æ“š
df3 = pd.DataFrame({
    'Date': ['15/01/2023', '20/02/2023', '25/03/2023'],
    'CustomerSegment': ['Premium', 'Standard', 'Premium'],
    'Region': ['North', 'South', 'West']
})

print("ä¾†æº1 - éŠ·å”®æ•¸æ“š (CSV):")
print(df1)
print("\nä¾†æº2 - ç”¢å“æ•¸æ“š (JSON):")
print(df2)
print("\nä¾†æº3 - å®¢æˆ¶æ•¸æ“š (Excel):")
print(df3)

# æ­¥é©Ÿ1: çµ±ä¸€æ•¸æ“šé¡å‹
# è½‰æ›æ—¥æœŸæ ¼å¼
df1['Date'] = pd.to_datetime(df1['Date'])
df3['Date'] = pd.to_datetime(df3['Date'], format='%d/%m/%Y')
print("\nçµ±ä¸€æ—¥æœŸæ ¼å¼å¾Œ:")
print(f"df1['Date'] å‹æ…‹: {df1['Date'].dtype}")
print(f"df3['Date'] å‹æ…‹: {df3['Date'].dtype}")

# è½‰æ›æ•¸å€¼å‹æ…‹
df1['Revenue'] = df1['Revenue'].str.replace('$', '').str.replace(',', '').astype(float)
df1['Quantity'] = df1['Quantity'].astype(int)
print("\nè½‰æ›æ•¸å€¼å¾Œçš„éŠ·å”®æ•¸æ“š:")
print(df1)

# æ­¥é©Ÿ2: åˆä½µæ•¸æ“š
# å°‡ç”¢å“æ•¸æ“šèˆ‡éŠ·å”®æ•¸æ“šåˆä½µ
df_merged1 = pd.merge(df1, df2, left_on='Product', right_on='ProductID', how='left')
print("\nåˆä½µç”¢å“èˆ‡éŠ·å”®æ•¸æ“š:")
print(df_merged1)

# å°‡å®¢æˆ¶æ•¸æ“šèˆ‡åˆä½µå¾Œçš„æ•¸æ“šå†åˆä½µ
df_final = pd.merge(df_merged1, df3, on='Date', how='left')
print("\næœ€çµ‚åˆä½µçš„æ•¸æ“š:")
print(df_final)

# æ­¥é©Ÿ3: æ•¸æ“šæª¢æŸ¥å’Œæ¸…ç†
# æª¢æŸ¥æ˜¯å¦æœ‰ç¼ºå¤±å€¼
print("\næª¢æŸ¥ç¼ºå¤±å€¼:")
print(df_final.isna().sum())

# è¨ˆç®—å–®åƒ¹ (Revenue / Quantity)
df_final['UnitRevenue'] = df_final['Revenue'] / df_final['Quantity']
print("\næ·»åŠ å–®åƒ¹è¨ˆç®—:")
print(df_final[['Product', 'Quantity', 'Revenue', 'UnitRevenue', 'Price']])

# æª¢æŸ¥å–®åƒ¹èˆ‡åƒ¹æ ¼çš„å·®ç•°
df_final['PriceDiff'] = df_final['UnitRevenue'] - df_final['Price']
print("\nå–®åƒ¹èˆ‡ç”¢å“åƒ¹æ ¼çš„å·®ç•°:")
print(df_final[['Product', 'UnitRevenue', 'Price', 'PriceDiff']])

# %% [markdown]
# ### 8.18 æ•¸æ“šå‹æ…‹è½‰æ›çš„å¯¦éš›æ‡‰ç”¨æ¡ˆä¾‹ï¼šæ•¸æ“šæ¸…æ´—èˆ‡é è™•ç†

# %%
# å‰µå»ºåŒ…å«é›œäº‚æ–‡æœ¬çš„ DataFrame
df_messy = pd.DataFrame({
    'Text': [
        '  This is a sample text! With some punctuation. ',
        'ANOTHER TEXT WITH ALL CAPITALS.',
        'URL: https://example.com/page.html',
        'Multiple   spaces   and\ttabs\tin this text',
        'Email: user123@example.com #hashtag'
    ]
})
print("åŸå§‹é›œäº‚æ–‡æœ¬:")
print(df_messy)

# åŸºæœ¬æ¸…æ´—æ­¥é©Ÿ
df_messy['Cleaned'] = df_messy['Text'].str.strip()  # ç§»é™¤å‰å¾Œç©ºç™½
df_messy['Cleaned'] = df_messy['Cleaned'].str.lower()  # è½‰ç‚ºå°å¯«
df_messy['Cleaned'] = df_messy['Cleaned'].str.replace(r'[^\w\s]', '', regex=True)  # ç§»é™¤æ¨™é»ç¬¦è™Ÿ
df_messy['Cleaned'] = df_messy['Cleaned'].str.replace(r'\s+', ' ', regex=True)  # ç§»é™¤å¤šé¤˜ç©ºç™½

print("\nåŸºæœ¬æ¸…æ´—å¾Œçš„æ–‡æœ¬:")
print(df_messy[['Text', 'Cleaned']])

# ç§»é™¤URLs
df_messy['No_URLs'] = df_messy['Text'].str.replace(r'https?://\S+', '', regex=True)
print("\nç§»é™¤URLs:")
print(df_messy[['Text', 'No_URLs']])

# ç§»é™¤Email
df_messy['No_Emails'] = df_messy['Text'].str.replace(r'\S+@\S+', '', regex=True)
print("\nç§»é™¤Emails:")
print(df_messy[['Text', 'No_Emails']])

# ç§»é™¤æ¨™ç±¤å’Œä¸»é¡Œæ¨™ç±¤
df_messy['No_Tags'] = df_messy['Text'].str.replace(r'#\w+', '', regex=True)
print("\nç§»é™¤æ¨™ç±¤:")
print(df_messy[['Text', 'No_Tags']])

# åˆ†è©
df_messy['Tokens'] = df_messy['Cleaned'].str.split()
print("\nåˆ†è©çµæœ:")
print(df_messy[['Cleaned', 'Tokens']])

# %% [markdown]
# **è§£èªª**ï¼š
# - æ–‡æœ¬æ•¸æ“šè™•ç†é€šå¸¸åŒ…æ‹¬æ¨™æº–åŒ–ï¼ˆå¤§å°å¯«çµ±ä¸€ï¼‰ã€æ¸…æ´—ï¼ˆç§»é™¤æ¨™é»ç¬¦è™Ÿã€å¤šé¤˜ç©ºç™½ï¼‰å’Œæ¨™è¨˜åŒ–ï¼ˆåˆ†è©ï¼‰
# - ä½¿ç”¨ `str.split()` å°‡æ–‡æœ¬åˆ‡åˆ†ç‚ºå–®è©åˆ—è¡¨ï¼Œä¾¿æ–¼å¾ŒçºŒåˆ†æ
# - è©é »çµ±è¨ˆæ˜¯æ–‡æœ¬åˆ†æçš„åŸºç¤ï¼Œå¯ä»¥å¾æ•´é«”æˆ–å–®æ¢æ–‡æœ¬çš„è§’åº¦è¨ˆç®—è©é »
# - æ–‡æœ¬æ¸…æ´—é€šå¸¸æ˜¯æ•¸æ“šåˆ†ææµç¨‹çš„ç¬¬ä¸€æ­¥ï¼Œå®ƒç‚ºå¾ŒçºŒçš„ç‰¹å¾µå·¥ç¨‹å’Œåˆ†æå¥ å®šåŸºç¤
# - Pandas çš„å­—ç¬¦ä¸²æ–¹æ³•æä¾›äº†é«˜æ•ˆçš„æ–‡æœ¬è™•ç†èƒ½åŠ›ï¼Œæ­é…æ­£å‰‡è¡¨é”å¼èƒ½è™•ç†è¤‡é›œçš„æ–‡æœ¬æ¨¡å¼

# %% [markdown]
# ### 8.19 æ•¸æ“šå‹æ…‹è½‰æ›çš„å¯¦éš›æ‡‰ç”¨æ¡ˆä¾‹ï¼šæ•¸æ“šæ•´åˆèˆ‡æ¨™æº–åŒ–

# %%
# æ¨¡æ“¬ä¾†è‡ªä¸åŒä¾†æºçš„æ•¸æ“š
# ä¾†æº1: CSVæ ¼å¼çš„éŠ·å”®æ•¸æ“š
df1 = pd.DataFrame({
    'Date': ['2023-01-15', '2023-02-20', '2023-03-25'],
    'Product': ['A', 'B', 'C'],
    'Revenue': ['$1,200.50', '$950.25', '$1,500.75'],
    'Quantity': ['25', '18', '30']
})

# ä¾†æº2: JSONæ ¼å¼çš„ç”¢å“æ•¸æ“š
df2 = pd.DataFrame({
    'ProductID': ['A', 'B', 'C', 'D'],
    'Name': ['ProductA', 'ProductB', 'ProductC', 'ProductD'],
    'Price': [48.02, 52.79, 50.025, 65.5],
    'Category': ['Electronics', 'Home', 'Electronics', 'Clothing']
})

# ä¾†æº3: Excelæ ¼å¼çš„å®¢æˆ¶æ•¸æ“š
df3 = pd.DataFrame({
    'Date': ['15/01/2023', '20/02/2023', '25/03/2023'],
    'CustomerSegment': ['Premium', 'Standard', 'Premium'],
    'Region': ['North', 'South', 'West']
})

print("ä¾†æº1 - éŠ·å”®æ•¸æ“š (CSV):")
print(df1)
print("\nä¾†æº2 - ç”¢å“æ•¸æ“š (JSON):")
print(df2)
print("\nä¾†æº3 - å®¢æˆ¶æ•¸æ“š (Excel):")
print(df3)

# æ­¥é©Ÿ1: çµ±ä¸€æ•¸æ“šé¡å‹
# è½‰æ›æ—¥æœŸæ ¼å¼
df1['Date'] = pd.to_datetime(df1['Date'])
df3['Date'] = pd.to_datetime(df3['Date'], format='%d/%m/%Y')
print("\nçµ±ä¸€æ—¥æœŸæ ¼å¼å¾Œ:")
print(f"df1['Date'] å‹æ…‹: {df1['Date'].dtype}")
print(f"df3['Date'] å‹æ…‹: {df3['Date'].dtype}")

# è½‰æ›æ•¸å€¼å‹æ…‹
df1['Revenue'] = df1['Revenue'].str.replace('$', '').str.replace(',', '').astype(float)
df1['Quantity'] = df1['Quantity'].astype(int)
print("\nè½‰æ›æ•¸å€¼å¾Œçš„éŠ·å”®æ•¸æ“š:")
print(df1)

# æ­¥é©Ÿ2: åˆä½µæ•¸æ“š
# å°‡ç”¢å“æ•¸æ“šèˆ‡éŠ·å”®æ•¸æ“šåˆä½µ
df_merged1 = pd.merge(df1, df2, left_on='Product', right_on='ProductID', how='left')
print("\nåˆä½µç”¢å“èˆ‡éŠ·å”®æ•¸æ“š:")
print(df_merged1)

# å°‡å®¢æˆ¶æ•¸æ“šèˆ‡åˆä½µå¾Œçš„æ•¸æ“šå†åˆä½µ
df_final = pd.merge(df_merged1, df3, on='Date', how='left')
print("\næœ€çµ‚åˆä½µçš„æ•¸æ“š:")
print(df_final)

# æ­¥é©Ÿ3: æ•¸æ“šæª¢æŸ¥å’Œæ¸…ç†
# æª¢æŸ¥æ˜¯å¦æœ‰ç¼ºå¤±å€¼
print("\næª¢æŸ¥ç¼ºå¤±å€¼:")
print(df_final.isna().sum())

# è¨ˆç®—å–®åƒ¹ (Revenue / Quantity)
df_final['UnitRevenue'] = df_final['Revenue'] / df_final['Quantity']
print("\næ·»åŠ å–®åƒ¹è¨ˆç®—:")
print(df_final[['Product', 'Quantity', 'Revenue', 'UnitRevenue', 'Price']])

# æª¢æŸ¥å–®åƒ¹èˆ‡åƒ¹æ ¼çš„å·®ç•°
df_final['PriceDiff'] = df_final['UnitRevenue'] - df_final['Price']
print("\nå–®åƒ¹èˆ‡ç”¢å“åƒ¹æ ¼çš„å·®ç•°:")
print(df_final[['Product', 'UnitRevenue', 'Price', 'PriceDiff']])

# %% [markdown]
# ### 8.20 æ•¸æ“šå‹æ…‹è½‰æ›çš„å¯¦éš›æ‡‰ç”¨æ¡ˆä¾‹ï¼šæ•¸æ“šæ¸…æ´—èˆ‡é è™•ç†

# %%
# å‰µå»ºåŒ…å«é›œäº‚æ–‡æœ¬çš„ DataFrame
df_messy = pd.DataFrame({
    'Text': [
        '  This is a sample text! With some punctuation. ',
        'ANOTHER TEXT WITH ALL CAPITALS.',
        'URL: https://example.com/page.html',
        'Multiple   spaces   and\ttabs\tin this text',
        'Email: user123@example.com #hashtag'
    ]
})
print("åŸå§‹é›œäº‚æ–‡æœ¬:")
print(df_messy)

# åŸºæœ¬æ¸…æ´—æ­¥é©Ÿ
df_messy['Cleaned'] = df_messy['Text'].str.strip()  # ç§»é™¤å‰å¾Œç©ºç™½
df_messy['Cleaned'] = df_messy['Cleaned'].str.lower()  # è½‰ç‚ºå°å¯«
df_messy['Cleaned'] = df_messy['Cleaned'].str.replace(r'[^\w\s]', '', regex=True)  # ç§»é™¤æ¨™é»ç¬¦è™Ÿ
df_messy['Cleaned'] = df_messy['Cleaned'].str.replace(r'\s+', ' ', regex=True)  # ç§»é™¤å¤šé¤˜ç©ºç™½

print("\nåŸºæœ¬æ¸…æ´—å¾Œçš„æ–‡æœ¬:")
print(df_messy[['Text', 'Cleaned']])

# ç§»é™¤URLs
df_messy['No_URLs'] = df_messy['Text'].str.replace(r'https?://\S+', '', regex=True)
print("\nç§»é™¤URLs:")
print(df_messy[['Text', 'No_URLs']])

# ç§»é™¤Email
df_messy['No_Emails'] = df_messy['Text'].str.replace(r'\S+@\S+', '', regex=True)
print("\nç§»é™¤Emails:")
print(df_messy[['Text', 'No_Emails']])

# ç§»é™¤æ¨™ç±¤å’Œä¸»é¡Œæ¨™ç±¤
df_messy['No_Tags'] = df_messy['Text'].str.replace(r'#\w+', '', regex=True)
print("\nç§»é™¤æ¨™ç±¤:")
print(df_messy[['Text', 'No_Tags']])

# åˆ†è©
df_messy['Tokens'] = df_messy['Cleaned'].str.split()
print("\nåˆ†è©çµæœ:")
print(df_messy[['Cleaned', 'Tokens']])

# %% [markdown]
# **è§£èªª**ï¼š
# - æ–‡æœ¬æ•¸æ“šè™•ç†é€šå¸¸åŒ…æ‹¬æ¨™æº–åŒ–ï¼ˆå¤§å°å¯«çµ±ä¸€ï¼‰ã€æ¸…æ´—ï¼ˆç§»é™¤æ¨™é»ç¬¦è™Ÿã€å¤šé¤˜ç©ºç™½ï¼‰å’Œæ¨™è¨˜åŒ–ï¼ˆåˆ†è©ï¼‰
# - ä½¿ç”¨ `str.split()` å°‡æ–‡æœ¬åˆ‡åˆ†ç‚ºå–®è©åˆ—è¡¨ï¼Œä¾¿æ–¼å¾ŒçºŒåˆ†æ
# - è©é »çµ±è¨ˆæ˜¯æ–‡æœ¬åˆ†æçš„åŸºç¤ï¼Œå¯ä»¥å¾æ•´é«”æˆ–å–®æ¢æ–‡æœ¬çš„è§’åº¦è¨ˆç®—è©é »
# - æ–‡æœ¬æ¸…æ´—é€šå¸¸æ˜¯æ•¸æ“šåˆ†ææµç¨‹çš„ç¬¬ä¸€æ­¥ï¼Œå®ƒç‚ºå¾ŒçºŒçš„ç‰¹å¾µå·¥ç¨‹å’Œåˆ†æå¥ å®šåŸºç¤
# - Pandas çš„å­—ç¬¦ä¸²æ–¹æ³•æä¾›äº†é«˜æ•ˆçš„æ–‡æœ¬è™•ç†èƒ½åŠ›ï¼Œæ­é…æ­£å‰‡è¡¨é”å¼èƒ½è™•ç†è¤‡é›œçš„æ–‡æœ¬æ¨¡å¼

# %% [markdown]
# ### 8.21 æ•¸æ“šå‹æ…‹è½‰æ›çš„å¯¦éš›æ‡‰ç”¨æ¡ˆä¾‹ï¼šæ•¸æ“šæ•´åˆèˆ‡æ¨™æº–åŒ–

# %%
# æ¨¡æ“¬ä¾†è‡ªä¸åŒä¾†æºçš„æ•¸æ“š
# ä¾†æº1: CSVæ ¼å¼çš„éŠ·å”®æ•¸æ“š
df1 = pd.DataFrame({
    'Date': ['2023-01-15', '2023-02-20', '2023-03-25'],
    'Product': ['A', 'B', 'C'],
    'Revenue': ['$1,200.50', '$950.25', '$1,500.75'],
    'Quantity': ['25', '18', '30']
})

# ä¾†æº2: JSONæ ¼å¼çš„ç”¢å“æ•¸æ“š
df2 = pd.DataFrame({
    'ProductID': ['A', 'B', 'C', 'D'],
    'Name': ['ProductA', 'ProductB', 'ProductC', 'ProductD'],
    'Price': [48.02, 52.79, 50.025, 65.5],
    'Category': ['Electronics', 'Home', 'Electronics', 'Clothing']
})

# ä¾†æº3: Excelæ ¼å¼çš„å®¢æˆ¶æ•¸æ“š
df3 = pd.DataFrame({
    'Date': ['15/01/2023', '20/02/2023', '25/03/2023'],
    'CustomerSegment': ['Premium', 'Standard', 'Premium'],
    'Region': ['North', 'South', 'West']
})

print("ä¾†æº1 - éŠ·å”®æ•¸æ“š (CSV):")
print(df1)
print("\nä¾†æº2 - ç”¢å“æ•¸æ“š (JSON):")
print(df2)
print("\nä¾†æº3 - å®¢æˆ¶æ•¸æ“š (Excel):")
print(df3)

# æ­¥é©Ÿ1: çµ±ä¸€æ•¸æ“šé¡å‹
# è½‰æ›æ—¥æœŸæ ¼å¼
df1['Date'] = pd.to_datetime(df1['Date'])
df3['Date'] = pd.to_datetime(df3['Date'], format='%d/%m/%Y')
print("\nçµ±ä¸€æ—¥æœŸæ ¼å¼å¾Œ:")
print(f"df1['Date'] å‹æ…‹: {df1['Date'].dtype}")
print(f"df3['Date'] å‹æ…‹: {df3['Date'].dtype}")

# è½‰æ›æ•¸å€¼å‹æ…‹
df1['Revenue'] = df1['Revenue'].str.replace('$', '').str.replace(',', '').astype(float)
df1['Quantity'] = df1['Quantity'].astype(int)
print("\nè½‰æ›æ•¸å€¼å¾Œçš„éŠ·å”®æ•¸æ“š:")
print(df1)

# æ­¥é©Ÿ2: åˆä½µæ•¸æ“š
# å°‡ç”¢å“æ•¸æ“šèˆ‡éŠ·å”®æ•¸æ“šåˆä½µ
df_merged1 = pd.merge(df1, df2, left_on='Product', right_on='ProductID', how='left')
print("\nåˆä½µç”¢å“èˆ‡éŠ·å”®æ•¸æ“š:")
print(df_merged1)

# å°‡å®¢æˆ¶æ•¸æ“šèˆ‡åˆä½µå¾Œçš„æ•¸æ“šå†åˆä½µ
df_final = pd.merge(df_merged1, df3, on='Date', how='left')
print("\næœ€çµ‚åˆä½µçš„æ•¸æ“š:")
print(df_final)

# æ­¥é©Ÿ3: æ•¸æ“šæª¢æŸ¥å’Œæ¸…ç†
# æª¢æŸ¥æ˜¯å¦æœ‰ç¼ºå¤±å€¼
print("\næª¢æŸ¥ç¼ºå¤±å€¼:")
print(df_final.isna().sum())

# è¨ˆç®—å–®åƒ¹ (Revenue / Quantity)
df_final['UnitRevenue'] = df_final['Revenue'] / df_final['Quantity']
print("\næ·»åŠ å–®åƒ¹è¨ˆç®—:")
print(df_final[['Product', 'Quantity', 'Revenue', 'UnitRevenue', 'Price']])

# æª¢æŸ¥å–®åƒ¹èˆ‡åƒ¹æ ¼çš„å·®ç•°
df_final['PriceDiff'] = df_final['UnitRevenue'] - df_final['Price']
print("\nå–®åƒ¹èˆ‡ç”¢å“åƒ¹æ ¼çš„å·®ç•°:")
print(df_final[['Product', 'UnitRevenue', 'Price', 'PriceDiff']])

# %% [markdown]
# ### 8.22 æ•¸æ“šå‹æ…‹è½‰æ›çš„å¯¦éš›æ‡‰ç”¨æ¡ˆä¾‹ï¼šæ•¸æ“šæ¸…æ´—èˆ‡é è™•ç†

# %%
# å‰µå»ºåŒ…å«é›œäº‚æ–‡æœ¬çš„ DataFrame
df_messy = pd.DataFrame({
    'Text': [
        '  This is a sample text! With some punctuation. ',
        'ANOTHER TEXT WITH ALL CAPITALS.',
        'URL: https://example.com/page.html',
        'Multiple   spaces   and\ttabs\tin this text',
        'Email: user123@example.com #hashtag'
    ]
})
print("åŸå§‹é›œäº‚æ–‡æœ¬:")
print(df_messy)

# åŸºæœ¬æ¸…æ´—æ­¥é©Ÿ
df_messy['Cleaned'] = df_messy['Text'].str.strip()  # ç§»é™¤å‰å¾Œç©ºç™½
df_messy['Cleaned'] = df_messy['Cleaned'].str.lower()  # è½‰ç‚ºå°å¯«
df_messy['Cleaned'] = df_messy['Cleaned'].str.replace(r'[^\w\s]', '', regex=True)  # ç§»é™¤æ¨™é»ç¬¦è™Ÿ
df_messy['Cleaned'] = df_messy['Cleaned'].str.replace(r'\s+', ' ', regex=True)  # ç§»é™¤å¤šé¤˜ç©ºç™½

print("\nåŸºæœ¬æ¸…æ´—å¾Œçš„æ–‡æœ¬:")
print(df_messy[['Text', 'Cleaned']])

# ç§»é™¤URLs
df_messy['No_URLs'] = df_messy['Text'].str.replace(r'https?://\S+', '', regex=True)
print("\nç§»é™¤URLs:")
print(df_messy[['Text', 'No_URLs']])

# ç§»é™¤Email
df_messy['No_Emails'] = df_messy['Text'].str.replace(r'\S+@\S+', '', regex=True)
print("\nç§»é™¤Emails:")
print(df_messy[['Text', 'No_Emails']])

# ç§»é™¤æ¨™ç±¤å’Œä¸»é¡Œæ¨™ç±¤
df_messy['No_Tags'] = df_messy['Text'].str.replace(r'#\w+', '', regex=True)
print("\nç§»é™¤æ¨™ç±¤:")
print(df_messy[['Text', 'No_Tags']])

# åˆ†è©
df_messy['Tokens'] = df_messy['Cleaned'].str.split()
print("\nåˆ†è©çµæœ:")
print(df_messy[['Cleaned', 'Tokens']])

# %% [markdown]
# **è§£èªª**ï¼š
# - æ–‡æœ¬æ•¸æ“šè™•ç†é€šå¸¸åŒ…æ‹¬æ¨™æº–åŒ–ï¼ˆå¤§å°å¯«çµ±ä¸€ï¼‰ã€æ¸…æ´—ï¼ˆç§»é™¤æ¨™é»ç¬¦è™Ÿã€å¤šé¤˜ç©ºç™½ï¼‰å’Œæ¨™è¨˜åŒ–ï¼ˆåˆ†è©ï¼‰
# - ä½¿ç”¨ `str.split()` å°‡æ–‡æœ¬åˆ‡åˆ†ç‚ºå–®è©åˆ—è¡¨ï¼Œä¾¿æ–¼å¾ŒçºŒåˆ†æ
# - è©é »çµ±è¨ˆæ˜¯æ–‡æœ¬åˆ†æçš„åŸºç¤ï¼Œå¯ä»¥å¾æ•´é«”æˆ–å–®æ¢æ–‡æœ¬çš„è§’åº¦è¨ˆç®—è©é »
# - æ–‡æœ¬æ¸…æ´—é€šå¸¸æ˜¯æ•¸æ“šåˆ†ææµç¨‹çš„ç¬¬ä¸€æ­¥ï¼Œå®ƒç‚ºå¾ŒçºŒçš„ç‰¹å¾µå·¥ç¨‹å’Œåˆ†æå¥ å®šåŸºç¤
# - Pandas çš„å­—ç¬¦ä¸²æ–¹æ³•æä¾›äº†é«˜æ•ˆçš„æ–‡æœ¬è™•ç†èƒ½åŠ›ï¼Œæ­é…æ­£å‰‡è¡¨é”å¼èƒ½è™•ç†è¤‡é›œçš„æ–‡æœ¬æ¨¡å¼

# %% [markdown]
# ### 8.23 æ•¸æ“šå‹æ…‹è½‰æ›çš„å¯¦éš›æ‡‰ç”¨æ¡ˆä¾‹ï¼šæ•¸æ“šæ•´åˆèˆ‡æ¨™æº–åŒ–

# %%
# æ¨¡æ“¬ä¾†è‡ªä¸åŒä¾†æºçš„æ•¸æ“š
# ä¾†æº1: CSVæ ¼å¼çš„éŠ·å”®æ•¸æ“š
df1 = pd.DataFrame({
    'Date': ['2023-01-15', '2023-02-20', '2023-03-25'],
    'Product': ['A', 'B', 'C'],
    'Revenue': ['$1,200.50', '$950.25', '$1,500.75'],
    'Quantity': ['25', '18', '30']
})

# ä¾†æº2: JSONæ ¼å¼çš„ç”¢å“æ•¸æ“š
df2 = pd.DataFrame({
    'ProductID': ['A', 'B', 'C', 'D'],
    'Name': ['ProductA', 'ProductB', 'ProductC', 'ProductD'],
    'Price': [48.02, 52.79, 50.025, 65.5],
    'Category': ['Electronics', 'Home', 'Electronics', 'Clothing']
})

# ä¾†æº3: Excelæ ¼å¼çš„å®¢æˆ¶æ•¸æ“š
df3 = pd.DataFrame({
    'Date': ['15/01/2023', '20/02/2023', '25/03/2023'],
    'CustomerSegment': ['Premium', 'Standard', 'Premium'],
    'Region': ['North', 'South', 'West']
})

print("ä¾†æº1 - éŠ·å”®æ•¸æ“š (CSV):")
print(df1)
print("\nä¾†æº2 - ç”¢å“æ•¸æ“š (JSON):")
print(df2)
print("\nä¾†æº3 - å®¢æˆ¶æ•¸æ“š (Excel):")
print(df3)

# æ­¥é©Ÿ1: çµ±ä¸€æ•¸æ“šé¡å‹
# è½‰æ›æ—¥æœŸæ ¼å¼
df1['Date'] = pd.to_datetime(df1['Date'])
df3['Date'] = pd.to_datetime(df3['Date'], format='%d/%m/%Y')
print("\nçµ±ä¸€æ—¥æœŸæ ¼å¼å¾Œ:")
print(f"df1['Date'] å‹æ…‹: {df1['Date'].dtype}")
print(f"df3['Date'] å‹æ…‹: {df3['Date'].dtype}")

# è½‰æ›æ•¸å€¼å‹æ…‹
df1['Revenue'] = df1['Revenue'].str.replace('$', '').str.replace(',', '').astype(float)
df1['Quantity'] = df1['Quantity'].astype(int)
print("\nè½‰æ›æ•¸å€¼å¾Œçš„éŠ·å”®æ•¸æ“š:")
print(df1)

# æ­¥é©Ÿ2: åˆä½µæ•¸æ“š
# å°‡ç”¢å“æ•¸æ“šèˆ‡éŠ·å”®æ•¸æ“šåˆä½µ
df_merged1 = pd.merge(df1, df2, left_on='Product', right_on='ProductID', how='left')
print("\nåˆä½µç”¢å“èˆ‡éŠ·å”®æ•¸æ“š:")
print(df_merged1)

# å°‡å®¢æˆ¶æ•¸æ“šèˆ‡åˆä½µå¾Œçš„æ•¸æ“šå†åˆä½µ
df_final = pd.merge(df_merged1, df3, on='Date', how='left')
print("\næœ€çµ‚åˆä½µçš„æ•¸æ“š:")
print(df_final)

# æ­¥é©Ÿ3: æ•¸æ“šæª¢æŸ¥å’Œæ¸…ç†
# æª¢æŸ¥æ˜¯å¦æœ‰ç¼ºå¤±å€¼
print("\næª¢æŸ¥ç¼ºå¤±å€¼:")
print(df_final.isna().sum())

# è¨ˆç®—å–®åƒ¹ (Revenue / Quantity)
df_final['UnitRevenue'] = df_final['Revenue'] / df_final['Quantity']
print("\næ·»åŠ å–®åƒ¹è¨ˆç®—:")
print(df_final[['Product', 'Quantity', 'Revenue', 'UnitRevenue', 'Price']])

# æª¢æŸ¥å–®åƒ¹èˆ‡åƒ¹æ ¼çš„å·®ç•°
df_final['PriceDiff'] = df_final['UnitRevenue'] - df_final['Price']
print("\nå–®åƒ¹èˆ‡ç”¢å“åƒ¹æ ¼çš„å·®ç•°:")
print(df_final[['Product', 'UnitRevenue', 'Price', 'PriceDiff']])

# %% [markdown]
# ### 8.24 æ•¸æ“šå‹æ…‹è½‰æ›çš„å¯¦éš›æ‡‰ç”¨æ¡ˆä¾‹ï¼šæ•¸æ“šæ¸…æ´—èˆ‡é è™•ç†

# %%
# å‰µå»ºåŒ…å«é›œäº‚æ–‡æœ¬çš„ DataFrame
df_messy = pd.DataFrame({
    'Text': [
        '  This is a sample text! With some punctuation. ',
        'ANOTHER TEXT WITH ALL CAPITALS.',
        'URL: https://example.com/page.html',
        'Multiple   spaces   and\ttabs\tin this text',
        'Email: user123@example.com #hashtag'
    ]
})
print("åŸå§‹é›œäº‚æ–‡æœ¬:")
print(df_messy)

# åŸºæœ¬æ¸…æ´—æ­¥é©Ÿ
df_messy['Cleaned'] = df_messy['Text'].str.strip()  # ç§»é™¤å‰å¾Œç©ºç™½
df_messy['Cleaned'] = df_messy['Cleaned'].str.lower()  # è½‰ç‚ºå°å¯«
df_messy['Cleaned'] = df_messy['Cleaned'].str.replace(r'[^\w\s]', '', regex=True)  # ç§»é™¤æ¨™é»ç¬¦è™Ÿ
df_messy['Cleaned'] = df_messy['Cleaned'].str.replace(r'\s+', ' ', regex=True)  # ç§»é™¤å¤šé¤˜ç©ºç™½

print("\nåŸºæœ¬æ¸…æ´—å¾Œçš„æ–‡æœ¬:")
print(df_messy[['Text', 'Cleaned']])

# ç§»é™¤URLs
# ### 7.3 æ–‡æœ¬æ¸…æ´—èˆ‡é è™•ç†

# %%
# å‰µå»ºåŒ…å«é›œäº‚æ–‡æœ¬æ•¸æ“šçš„ DataFrame
messy_text_df = pd.DataFrame({
    'raw_text': [
        '  Hello, World! How are you doing? ',
        'PYTHON is GREAT for DATA ANALYSIS!!!',
        'Contact: john.doe@example.com, Phone: 123-456-7890',
        'Price: $19.99 (Discount: 20%)',
        'Visit our website: https://www.example.com\nFollow us on Twitter!',
        None
    ]
})

print("åŸå§‹é›œäº‚æ–‡æœ¬:")
print(messy_text_df)

# æ–‡æœ¬æ¸…æ´—æ­¥é©Ÿ
# 1. å»é™¤å‰å¾Œç©ºç™½
messy_text_df['cleaned_1'] = messy_text_df['raw_text'].str.strip()

# 2. è½‰æ›ç‚ºå°å¯«
messy_text_df['cleaned_2'] = messy_text_df['cleaned_1'].str.lower()

# 3. ç§»é™¤æ¨™é»ç¬¦è™Ÿ
messy_text_df['cleaned_3'] = messy_text_df['cleaned_2'].str.replace(r'[^\w\s]', ' ', regex=True)

# 4. ç§»é™¤æ•¸å­—
messy_text_df['cleaned_4'] = messy_text_df['cleaned_3'].str.replace(r'\d+', '', regex=True)

# 5. æ›¿æ›å¤šå€‹ç©ºæ ¼ç‚ºå–®å€‹ç©ºæ ¼
messy_text_df['cleaned_5'] = messy_text_df['cleaned_4'].str.replace(r'\s+', ' ', regex=True)

# å®Œæ•´çš„æ¸…æ´—æµç¨‹ (æ–¹æ³•éˆ)
messy_text_df['cleaned_final'] = (messy_text_df['raw_text']
    .str.strip()
    .str.lower()
    .str.replace(r'[^\w\s]', ' ', regex=True)
    .str.replace(r'\d+', '', regex=True)
    .str.replace(r'\s+', ' ', regex=True)
    .str.strip())

print("\næ¸…æ´—å¾Œæ–‡æœ¬:")
print(messy_text_df[['raw_text', 'cleaned_final']])

# æ–‡æœ¬æ¨™è¨˜åŒ– (åˆ‡åˆ†ç‚ºå–®è©)
messy_text_df['tokens'] = messy_text_df['cleaned_final'].str.split()

# è©é »çµ±è¨ˆ
# è¨ˆç®—æ‰€æœ‰æ–‡æœ¬ä¸­å–®è©å‡ºç¾çš„é »ç‡
all_words = []
for tokens in messy_text_df['tokens']:
    all_words.extend(tokens)

# å‰µå»ºè©é »çµ±è¨ˆ DataFrame
word_freq = pd.Series(all_words).value_counts().reset_index()
word_freq.columns = ['word', 'frequency']
print("\nè©é »çµ±è¨ˆ:")
print(word_freq.head(10))  # é¡¯ç¤ºæœ€å¸¸è¦‹çš„10å€‹å–®è©

# è¨ˆç®—ç‰¹å®šæ–‡æœ¬çš„è©é »
def get_word_freq(tokens):
    return pd.Series(tokens).value_counts()

# ç‚ºæ¯æ¢æ–‡æœ¬è¨ˆç®—è©é »
messy_text_df['word_freq'] = messy_text_df['tokens'].apply(get_word_freq)
print("\nå„æ–‡æœ¬è©é »:")
for i, word_freq in enumerate(messy_text_df['word_freq']):
    print(f"æ–‡æœ¬ {i+1} è©é »:")
    print(word_freq)

# %% [markdown]
# **è§£èªª**ï¼š
# - æ–‡æœ¬æ•¸æ“šè™•ç†é€šå¸¸åŒ…æ‹¬æ¨™æº–åŒ–ï¼ˆå¤§å°å¯«çµ±ä¸€ï¼‰ã€æ¸…æ´—ï¼ˆç§»é™¤æ¨™é»ç¬¦è™Ÿã€å¤šé¤˜ç©ºç™½ï¼‰å’Œæ¨™è¨˜åŒ–ï¼ˆåˆ†è©ï¼‰
# - ä½¿ç”¨ `str.split()` å°‡æ–‡æœ¬åˆ‡åˆ†ç‚ºå–®è©åˆ—è¡¨ï¼Œä¾¿æ–¼å¾ŒçºŒåˆ†æ
# - è©é »çµ±è¨ˆæ˜¯æ–‡æœ¬åˆ†æçš„åŸºç¤ï¼Œå¯ä»¥å¾æ•´é«”æˆ–å–®æ¢æ–‡æœ¬çš„è§’åº¦è¨ˆç®—è©é »
# - æ–‡æœ¬æ¸…æ´—é€šå¸¸æ˜¯æ•¸æ“šåˆ†ææµç¨‹çš„ç¬¬ä¸€æ­¥ï¼Œå®ƒç‚ºå¾ŒçºŒçš„ç‰¹å¾µå·¥ç¨‹å’Œåˆ†æå¥ å®šåŸºç¤
# - Pandas çš„å­—ç¬¦ä¸²æ–¹æ³•æä¾›äº†é«˜æ•ˆçš„æ–‡æœ¬è™•ç†èƒ½åŠ›ï¼Œæ­é…æ­£å‰‡è¡¨é”å¼èƒ½è™•ç†è¤‡é›œçš„æ–‡æœ¬æ¨¡å¼

# %% [markdown]
# ## ğŸ”‘ 8. ç¸½çµèˆ‡æœ€ä½³å¯¦è¸
#
# **å­¸ç¿’è¦é»**ï¼š
# - æŒæ¡æ•¸æ“šé¡å‹è½‰æ›çš„åŸºæœ¬åŸå‰‡å’Œæ–¹æ³•
# - äº†è§£å„ç¨®ç‰¹æ®Šæ•¸æ“šé¡å‹çš„è™•ç†æŠ€å·§
# - ç†Ÿæ‚‰æ—¥æœŸæ™‚é–“å’Œæ–‡æœ¬æ•¸æ“šçš„é«˜ç´šè™•ç†æ–¹æ³•
# - å­¸ç¿’è™•ç†å¯¦éš›æ•¸æ“šé›†ä¸­å¸¸è¦‹çš„æ•¸æ“šé¡å‹å•é¡Œ
#
# **æ‡‰ç”¨å ´åŸŸ**ï¼š
# - æ•¸æ“šå‰è™•ç†èˆ‡æ¸…æ´—å·¥ä½œæµ
# - æ•¸æ“šæ•´åˆèˆ‡æ¨™æº–åŒ–éç¨‹
# - ç‰¹å¾µå·¥ç¨‹èˆ‡æ¨¡å‹è¼¸å…¥æº–å‚™
# - æ•¸æ“šåˆ†æå ±å‘Šç”Ÿæˆèˆ‡æ ¼å¼åŒ–

# %% [markdown]
# ### 8.1 æ•¸æ“šå‹æ…‹è½‰æ›çš„é—œéµé»

# %%
# å‰µå»ºä¸€å€‹æœ€çµ‚ç¤ºä¾‹ï¼Œå±•ç¤ºä¸»è¦çš„æ•¸æ“šé¡å‹è½‰æ›æ¦‚å¿µ
summary_df = pd.DataFrame({
    'raw_string': ['1', '2.5', 'True', '2023-01-15', 'Category A'],
    'raw_value': [1, 2.5, True, pd.Timestamp('2023-01-15'), 'Category A']
})

# å±•ç¤ºåŸºæœ¬é¡å‹è½‰æ›
summary_df['to_int'] = pd.to_numeric(summary_df['raw_string'], errors='coerce').astype('Int64')
summary_df['to_float'] = pd.to_numeric(summary_df['raw_string'], errors='coerce')
summary_df['to_bool'] = summary_df['raw_string'].map({'True': True, 'False': False})
summary_df['to_datetime'] = pd.to_datetime(summary_df['raw_string'], errors='coerce')
summary_df['to_category'] = summary_df['raw_string'].astype('category')

print("æ•¸æ“šå‹æ…‹è½‰æ›ç¸½çµ:")
print(summary_df)
print("\nå„åˆ—çš„æ•¸æ“šé¡å‹:")
print(summary_df.dtypes)

# %% [markdown]
# ### 8.2 æ•¸æ“šè™•ç†çš„æœ€ä½³å¯¦è¸

# %% [markdown]
# 1. **æ•¸æ“šå‹æ…‹è½‰æ›åŸå‰‡**
#    - å§‹çµ‚åœ¨é€²è¡Œè¨ˆç®—å‰æª¢æŸ¥æ•¸æ“šé¡å‹
#    - å„ªå…ˆä½¿ç”¨ Pandas å…§å»ºçš„è½‰æ›å‡½æ•¸ (`to_numeric`, `to_datetime` ç­‰)
#    - è™•ç†éŒ¯èª¤æ™‚ä½¿ç”¨ `errors='coerce'` è½‰æ›å•é¡Œå€¼ç‚º NaNï¼Œè€Œéç›´æ¥å¤±æ•—
#    - ç‚ºå¤§å‹æ•¸æ“šé›†é¸æ“‡é©ç•¶çš„æ•¸æ“šé¡å‹ä»¥ç¯€çœå…§å­˜ï¼ˆå¦‚ `category`, `int32`ï¼‰
#
# 2. **æ•¸æ“šæ¸…æ´—æœ€ä½³å¯¦è¸**
#    - æ•¸æ“šå°å…¥å¾Œç«‹å³é€²è¡Œé¡å‹æª¢æŸ¥å’Œè½‰æ›ï¼Œè€Œéç­‰åˆ°éœ€è¦æ™‚
#    - å°æ–¼æ–‡æœ¬æ•¸æ“šï¼Œå»ºç«‹æ¨™æº–åŒ–çš„é è™•ç†æµç¨‹
#    - ä½¿ç”¨ `info()` å’Œ `describe()` æ–¹æ³•äº†è§£æ•¸æ“šæ¦‚æ³
#    - è¨˜éŒ„æ•¸æ“šè½‰æ›éç¨‹ï¼Œç¢ºä¿å¯è¤‡ç¾æ€§
#
# 3. **æ€§èƒ½å„ªåŒ–å»ºè­°**
#    - ä½¿ç”¨é¡åˆ¥å‹æ•¸æ“šæ¸›å°‘å…§å­˜ä½¿ç”¨
#    - ä½¿ç”¨ `astype()` æ‰¹é‡è½‰æ›æ¯”é€è¡Œè™•ç†æ›´é«˜æ•ˆ
#    - è€ƒæ…®ä½¿ç”¨ `category` å‹åˆ¥è™•ç†æœ‰é™å€¼é›†åˆï¼ˆå¦‚æ€§åˆ¥ã€åœ‹å®¶ï¼‰
#    - æ—¥æœŸè¨ˆç®—å„ªå…ˆä½¿ç”¨å‘é‡åŒ–æ“ä½œï¼Œé¿å… apply å¾ªç’°
#
# 4. **é€²éšå­¸ç¿’æ–¹å‘**
#    - **æ¢ç´¢æ€§æ•¸æ“šåˆ†æ**ï¼šå­¸ç¿’å¦‚ä½•ä½¿ç”¨æ­£ç¢ºçš„æ•¸æ“šé¡å‹é€²è¡Œé«˜æ•ˆ EDA
#    - **æ•¸æ“šè½‰æ›é€²éš**ï¼šæŒæ¡æ›´è¤‡é›œçš„æ•¸æ“šè½‰æ›æŠ€å·§å’Œå‡½æ•¸
#    - **å¤§æ•¸æ“šè™•ç†**ï¼šäº†è§£å¦‚ä½•è™•ç†è¨˜æ†¶é«”ç„¡æ³•å®¹ç´çš„å¤§å‹æ•¸æ“šé›†
#    - **è‡ªå®šç¾©æ•¸æ“šé¡å‹**ï¼šå­¸ç¿’å¦‚ä½•æ“´å±• Pandas çš„æ•¸æ“šé¡å‹ç³»çµ±