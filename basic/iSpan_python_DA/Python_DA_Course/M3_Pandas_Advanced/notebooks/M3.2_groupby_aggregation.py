# %% [markdown]
# # ğŸ“˜ M3.2 Pandas åˆ†çµ„èˆ‡èšåˆé€²éšæ‡‰ç”¨
# 
# æœ¬æ•™å­¸å°‡æ·±å…¥æ¢è¨ Pandas ä¸­ `groupby()` æ“ä½œçš„é€²éšæ‡‰ç”¨èˆ‡èšåˆå‡½æ•¸çš„å¤šç¨®ç”¨æ³•ã€‚
# åˆ†çµ„èˆ‡èšåˆæ˜¯æ•¸æ“šåˆ†æä¸­çš„æ ¸å¿ƒæ“ä½œï¼ŒæŒæ¡é€™äº›é€²éšæŠ€å·§å¯ä»¥è®“æ‚¨æ›´é«˜æ•ˆåœ°å¾è¤‡é›œæ•¸æ“šä¸­æå–æ´å¯Ÿã€‚

# %% [markdown]
# ## ğŸ¯ æ•™å­¸ç›®æ¨™
# 
# - ğŸ” æ·±å…¥ç†è§£ groupby() æ“ä½œçš„å…§éƒ¨æ©Ÿåˆ¶èˆ‡å„ªåŒ–
# - ğŸ”„ æŒæ¡å¤šç¨®èšåˆæ–¹æ³•èˆ‡å‡½æ•¸çš„ç¶œåˆæ‡‰ç”¨
# - ğŸ“Š å­¸ç¿’å‰µå»ºèˆ‡ä½¿ç”¨è¤‡é›œçš„è‡ªå®šç¾©èšåˆå‡½æ•¸
# - ğŸ§® ç†è§£åˆ†çµ„è½‰æ›èˆ‡éæ¿¾çš„é«˜ç´šæŠ€å·§
# - ğŸ› ï¸ é‹ç”¨åˆ†çµ„æ“ä½œè§£æ±ºå¯¦éš›æ¥­å‹™å•é¡Œ

# %% [markdown]
# ## ğŸ§° 1. ç’°å¢ƒè¨­ç½®

# %%
import numpy as np
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from functools import partial

# è¨­ç½®é¡¯ç¤ºé¸é …
pd.set_option('display.max_rows', 15)
pd.set_option('display.max_columns', 12)
pd.set_option('display.width', 100)
pd.set_option('display.precision', 2)

# %% [markdown]
# ## ğŸ“Š 2. GroupBy é€²éšæ“ä½œ

# %%
# å‰µå»ºè¼ƒè¤‡é›œçš„ç¤ºä¾‹æ•¸æ“šé›†
np.random.seed(42)
n_rows = 1000

# ç”¢å“è³‡æ–™
products = pd.DataFrame({
    'ProductID': range(1, 101),
    'Category': np.random.choice(['Electronics', 'Clothing', 'Food', 'Books', 'Home'], 100),
    'Supplier': np.random.choice(['SupplierA', 'SupplierB', 'SupplierC', 'SupplierD'], 100),
    'Price': np.random.uniform(10, 1000, 100).round(2),
    'Stock': np.random.randint(0, 100, 100)
})

# éŠ·å”®è³‡æ–™
sales = pd.DataFrame({
    'SaleID': range(1, n_rows + 1),
    'Date': pd.date_range(start='2023-01-01', periods=n_rows),
    'ProductID': np.random.choice(products['ProductID'], n_rows),
    'Quantity': np.random.randint(1, 10, n_rows),
    'CustomerID': np.random.randint(1, 21, n_rows),
    'StoreID': np.random.choice(['Store1', 'Store2', 'Store3', 'Store4'], n_rows),
    'Discount': np.random.choice([0, 0.05, 0.1, 0.15, 0.2], n_rows),
})

# åˆä½µç”¢å“èˆ‡éŠ·å”®è³‡æ–™
sales_data = pd.merge(sales, products, on='ProductID')

# è¨ˆç®—æ¯ç­†éŠ·å”®çš„ç¸½é‡‘é¡
sales_data['TotalAmount'] = sales_data['Quantity'] * sales_data['Price'] * (1 - sales_data['Discount'])

print("éŠ·å”®è³‡æ–™é è¦½:")
print(sales_data.head())
print(f"\nè³‡æ–™é›†ç¶­åº¦: {sales_data.shape}")

# %% [markdown]
# ### 2.1 GroupBy å°è±¡çš„æ·±å…¥ç†è§£

# %%
# å‰µå»º GroupBy å°è±¡ä¸¦æŸ¥çœ‹å…¶çµæ§‹
store_group = sales_data.groupby('StoreID')
print("GroupBy å°è±¡é¡å‹:", type(store_group))
print("GroupBy å°è±¡åŒ…å«çš„ç¾¤çµ„:", list(store_group.groups.keys()))
print("ç¬¬ä¸€å€‹ç¾¤çµ„çš„ç´¢å¼•:", list(store_group.groups['Store1'])[:5], "...")

# ä½¿ç”¨ get_group() æ–¹æ³•ç²å–ç‰¹å®šç¾¤çµ„
store1_data = store_group.get_group('Store1')
print("\nStore1çš„è³‡æ–™ (å‰5è¡Œ):")
print(store1_data.head())

# %%
# æŸ¥çœ‹ GroupBy å°è±¡çš„çµ„æˆ
# ä½¿ç”¨ for å¾ªç’°éæ­·ç¾¤çµ„
print("éæ­·ç¾¤çµ„ (åƒ…é¡¯ç¤ºæ¯å€‹ç¾¤çµ„çš„å‰2è¡Œ):")
for name, group in store_group:
    print(f"\n{name} ç¾¤çµ„:")
    print(group.head(2))
    if name == 'Store2':  # åªé¡¯ç¤ºéƒ¨åˆ†ç¾¤çµ„ä½œç‚ºç¤ºä¾‹
        break

# %% [markdown]
# ### 2.2 å¤šç¨®èšåˆå‡½æ•¸çš„çµ„åˆæ‡‰ç”¨

# %%
# åŸºæœ¬èšåˆæ“ä½œçš„é€²éšç”¨æ³•
store_category_summary = sales_data.groupby(['StoreID', 'Category']).agg({
    'TotalAmount': ['sum', 'mean', 'count', 'median', 'std'],
    'Quantity': ['sum', 'mean', 'max'],
    'Discount': ['mean', 'max']
})

print("å¤šç´šåˆ†çµ„èˆ‡å¤šç¨®èšåˆå‡½æ•¸çµ„åˆ:")
print(store_category_summary)

# %%
# æ”¹é€²çµæœæ ¼å¼ï¼Œå±•å¹³å¤šç´šåˆ—å
store_category_flat = store_category_summary.reset_index()
store_category_flat.columns = ['_'.join(col).strip('_') for col in store_category_flat.columns.values]
print("å±•å¹³å¾Œçš„å¤šç´šåˆ†çµ„çµæœ:")
print(store_category_flat.head())

# %%
# ä½¿ç”¨ named aggregation (Pandas 0.25+)
named_agg = sales_data.groupby(['StoreID', 'Category']).agg(
    total_sales=('TotalAmount', 'sum'),
    avg_sales=('TotalAmount', 'mean'),
    sales_count=('TotalAmount', 'count'),
    total_quantity=('Quantity', 'sum'),
    avg_quantity=('Quantity', 'mean'),
    avg_discount=('Discount', 'mean')
)

print("ä½¿ç”¨å‘½åèšåˆçš„çµæœ:")
print(named_agg.head())

# %% [markdown]
# ### 2.3 é«˜ç´šè‡ªå®šç¾©èšåˆå‡½æ•¸

# %%
# å®šç¾©è¤‡é›œè‡ªå®šç¾©èšåˆå‡½æ•¸
def weighted_avg(group, value_col, weight_col):
    """è¨ˆç®—åŠ æ¬Šå¹³å‡æ•¸"""
    return (group[value_col] * group[weight_col]).sum() / group[weight_col].sum()

# å‰µå»ºéƒ¨åˆ†å‡½æ•¸ä»¥ä¾¿åœ¨ agg() ä¸­ä½¿ç”¨
weighted_price = partial(weighted_avg, value_col='Price', weight_col='Quantity')
weighted_discount = partial(weighted_avg, value_col='Discount', weight_col='TotalAmount')

# ä½¿ç”¨è‡ªå®šç¾©èšåˆå‡½æ•¸
custom_agg = sales_data.groupby('Category').agg({
    'TotalAmount': ['sum', 'count'],
    'Price': [weighted_price],
    'Discount': [weighted_discount]
})

print("ä½¿ç”¨è‡ªå®šç¾©èšåˆå‡½æ•¸çš„çµæœ:")
print(custom_agg)

# %%
# ä½¿ç”¨è£é£¾å™¨å®šç¾©è‡ªå®šç¾©èšåˆå‡½æ•¸ (æ›´å…·å¯è®€æ€§çš„æ–¹å¼)
from pandas.api.extensions import register_series_accessor

@register_series_accessor("custom_stats")
class CustomStats:
    def __init__(self, series):
        self._series = series
        
    def top_n_mean(self, n=3):
        """è¨ˆç®—å‰nå€‹æœ€å¤§å€¼çš„å¹³å‡å€¼"""
        return self._series.nlargest(n).mean()
    
    def excludes_extremes_mean(self):
        """è¨ˆç®—æ’é™¤æœ€å¤§å€¼å’Œæœ€å°å€¼å¾Œçš„å¹³å‡å€¼"""
        s = self._series.sort_values()
        return s.iloc[1:-1].mean()

# æ¸¬è©¦è‡ªå®šç¾©çµ±è¨ˆæ–¹æ³•
print("å®¢è£½åŒ–Seriesçµ±è¨ˆæ–¹æ³•:")
price_series = sales_data['Price']
print(f"å‰3å€‹æœ€å¤§åƒ¹æ ¼çš„å¹³å‡å€¼: {price_series.custom_stats.top_n_mean(3):.2f}")
print(f"æ’é™¤æ¥µå€¼å¾Œçš„å¹³å‡åƒ¹æ ¼: {price_series.custom_stats.excludes_extremes_mean():.2f}")

# %%
# ä½¿ç”¨ lambda å‡½æ•¸é€²è¡Œè¤‡é›œèšåˆæ“ä½œ
advanced_stats = sales_data.groupby('Category').agg({
    'TotalAmount': [
        'sum', 
        'mean',
        ('above_avg_count', lambda x: (x > x.mean()).sum()),
        ('pct_above_500', lambda x: (x > 500).mean() * 100)
    ],
    'Price': [
        'mean',
        ('price_range', lambda x: x.max() - x.min()),
        ('price_95pct', lambda x: x.quantile(0.95))
    ],
    'Quantity': [
        'sum',
        ('median_qty', 'median'),
        ('mode_qty', lambda x: x.mode().iloc[0] if not x.mode().empty else np.nan)
    ]
})

print("ä½¿ç”¨ lambda å‡½æ•¸çš„é€²éšçµ±è¨ˆçµæœ:")
print(advanced_stats)

# %% [markdown]
# ### 2.4 åˆ†çµ„è½‰æ›èˆ‡æ‡‰ç”¨ (Transform & Apply)

# %%
# ä½¿ç”¨ transform é€²è¡Œçµ„å…§æ¨™æº–åŒ–
# è¨ˆç®—æ¯å€‹é¡åˆ¥ä¸­ç”¢å“åƒ¹æ ¼çš„ z-score
sales_data['Price_ZScore'] = sales_data.groupby('Category')['Price'].transform(
    lambda x: (x - x.mean()) / x.std()
)

# è¨ˆç®—æ¯å€‹é–€åº—éŠ·å”®é¡ç›¸å°æ–¼è©²é–€åº—å¹³å‡å€¼çš„ç™¾åˆ†æ¯”
sales_data['SalesVsStoreAvg'] = sales_data.groupby('StoreID')['TotalAmount'].transform(
    lambda x: x / x.mean() * 100
)

print("ä½¿ç”¨ transform é€²è¡Œæ•¸æ“šè½‰æ›çš„çµæœ:")
print(sales_data[['ProductID', 'Category', 'Price', 'Price_ZScore', 
                 'StoreID', 'TotalAmount', 'SalesVsStoreAvg']].head(10))

# %%
# ä½¿ç”¨ transform è¨ˆç®—ç´¯è¨ˆå’Œç§»å‹•çµ±è¨ˆé‡
# æŒ‰é–€åº—å’Œæ—¥æœŸåˆ†çµ„ï¼Œè¨ˆç®—æ¯å€‹é–€åº—çš„ç´¯è¨ˆéŠ·å”®é¡
sales_data['Date'] = pd.to_datetime(sales_data['Date'])
sales_data['Month'] = sales_data['Date'].dt.to_period('M')

# è¨ˆç®—æ¯å€‹é–€åº—æ¯æœˆç´¯è¨ˆéŠ·å”®é¡
sales_data['CumulativeStoreSales'] = sales_data.sort_values('Date').groupby(['StoreID', 'Month'])['TotalAmount'].transform(
    lambda x: x.cumsum()
)

# è¨ˆç®—æ¯å€‹ç”¢å“é¡åˆ¥çš„3å¤©ç§»å‹•å¹³å‡éŠ·å”®é¡
sales_data['MovingAvgCategorySales'] = sales_data.sort_values('Date').groupby(['Category', 'Date'])['TotalAmount'].transform(
    lambda x: x.rolling(3, min_periods=1).mean()
)

print("ç´¯è¨ˆå’Œç§»å‹•çµ±è¨ˆçµæœ:")
print(sales_data[['Date', 'Month', 'StoreID', 'Category', 'TotalAmount', 
                 'CumulativeStoreSales', 'MovingAvgCategorySales']].sort_values(['StoreID', 'Date']).head(10))

# %%
# ä½¿ç”¨ apply é€²è¡Œæ›´è¤‡é›œçš„çµ„å…§æ“ä½œ
# æ‰¾å‡ºæ¯å€‹é¡åˆ¥ä¸­éŠ·å”®é¡æœ€é«˜çš„å‰3å€‹ç”¢å“
top_products = sales_data.groupby('Category').apply(
    lambda x: x.nlargest(3, 'TotalAmount')
).reset_index(drop=True)

print("æ¯å€‹é¡åˆ¥éŠ·å”®é¡æœ€é«˜çš„å‰3å€‹ç”¢å“:")
print(top_products[['Category', 'ProductID', 'TotalAmount']])

# %%
# ä½¿ç”¨ apply è¨ˆç®—æ¯å€‹é¡åˆ¥çš„éŠ·å”®è¶¨å‹¢
category_trend = sales_data.groupby('Category').apply(
    lambda group: pd.Series({
        'SalesGrowth': (group['TotalAmount'].iloc[-30:].mean() / 
                        group['TotalAmount'].iloc[:30].mean() - 1) * 100,
        'QuantityGrowth': (group['Quantity'].iloc[-30:].sum() / 
                          group['Quantity'].iloc[:30].sum() - 1) * 100,
        'IsGrowing': group['TotalAmount'].iloc[-30:].mean() > group['TotalAmount'].iloc[:30].mean()
    })
)

print("å„é¡åˆ¥éŠ·å”®è¶¨å‹¢åˆ†æ:")
print(category_trend)

# %% [markdown]
# ### 2.5 åˆ†çµ„éæ¿¾ (Filtering)

# %%
# ä½¿ç”¨ filter æ–¹æ³•é€²è¡Œçµ„ç´šéæ¿¾
# åªä¿ç•™å¹³å‡éŠ·å”®é¡è¶…é300çš„é¡åˆ¥
high_value_categories = sales_data.groupby('Category').filter(
    lambda x: x['TotalAmount'].mean() > 300
)

print("é«˜åƒ¹å€¼é¡åˆ¥ (å¹³å‡éŠ·å”®é¡ > 300):")
cat_names = high_value_categories['Category'].unique()
print(f"ç¯©é¸å¾Œçš„é¡åˆ¥: {', '.join(cat_names)}")
print(f"ç¯©é¸å‰è¡Œæ•¸: {len(sales_data)}, ç¯©é¸å¾Œè¡Œæ•¸: {len(high_value_categories)}")

# %%
# è¤‡é›œéæ¿¾ï¼šä¿ç•™è‡³å°‘æœ‰100ç­†éŠ·å”®ä¸”å¹³å‡æŠ˜æ‰£ç‡ä½æ–¼10%çš„åº—é‹ª
qualified_stores = sales_data.groupby('StoreID').filter(
    lambda x: (len(x) >= 100) & (x['Discount'].mean() < 0.1)
)

print("ç¬¦åˆæ¢ä»¶çš„åº—é‹ª:")
store_names = qualified_stores['StoreID'].unique()
print(f"ç¯©é¸å¾Œçš„åº—é‹ª: {', '.join(store_names)}")
print(f"ç¯©é¸å‰è¡Œæ•¸: {len(sales_data)}, ç¯©é¸å¾Œè¡Œæ•¸: {len(qualified_stores)}")

# %%
# çµ„åˆéæ¿¾èˆ‡èšåˆï¼šæ‰¾å‡ºç”¢å“é¡åˆ¥ä¸­è‡³å°‘æœ‰3ç¨®ç”¢å“ä¸”å¹³å‡åƒ¹æ ¼é«˜æ–¼300çš„é¡åˆ¥
price_threshold = 300
min_products = 3

# æ­¥é©Ÿ1ï¼šè¨ˆç®—æ¯å€‹é¡åˆ¥çš„ç¨ç‰¹ç”¢å“æ•¸é‡
product_counts = sales_data.groupby('Category')['ProductID'].nunique()
qualified_categories = product_counts[product_counts >= min_products].index

# æ­¥é©Ÿ2ï¼šè¨ˆç®—æ¯å€‹é¡åˆ¥çš„å¹³å‡åƒ¹æ ¼
avg_prices = sales_data.groupby('Category')['Price'].mean()
high_price_categories = avg_prices[avg_prices > price_threshold].index

# æ­¥é©Ÿ3ï¼šæ‰¾å‡ºåŒæ™‚æ»¿è¶³å…©å€‹æ¢ä»¶çš„é¡åˆ¥
target_categories = set(qualified_categories) & set(high_price_categories)
print(f"ç¬¦åˆæ¢ä»¶çš„é¡åˆ¥ (è‡³å°‘{min_products}å€‹ç”¢å“ä¸”å¹³å‡åƒ¹æ ¼ > {price_threshold}):")
print(target_categories)

# æ­¥é©Ÿ4ï¼šç¯©é¸å‡ºé€™äº›é¡åˆ¥çš„è³‡æ–™
target_data = sales_data[sales_data['Category'].isin(target_categories)]
print(f"\nç¯©é¸å¾Œçš„è³‡æ–™é è¦½:")
print(target_data[['Category', 'ProductID', 'Price']].head())

# %% [markdown]
# ## ğŸ“Š 3. å¯¦éš›æ¡ˆä¾‹ï¼šéŠ·å”®æ•¸æ“šå¤šç¶­åº¦åˆ†æ

# %%
# å‰µå»ºæ™‚é–“ç¶­åº¦
sales_data['Year'] = sales_data['Date'].dt.year
sales_data['Month'] = sales_data['Date'].dt.month
sales_data['Quarter'] = sales_data['Date'].dt.quarter
sales_data['Day'] = sales_data['Date'].dt.day_name()

# 1. å¤šç¶­åº¦éŠ·å”®åˆ†æï¼šæŒ‰å­£åº¦ã€é–€åº—å’Œç”¢å“é¡åˆ¥é€²è¡Œåˆ†çµ„
multi_dim_analysis = sales_data.groupby(['Year', 'Quarter', 'StoreID', 'Category']).agg({
    'TotalAmount': ['sum', 'mean', 'count'],
    'Quantity': 'sum',
    'Discount': 'mean'
}).round(2)

print("å¤šç¶­åº¦éŠ·å”®åˆ†æ (å­£åº¦ x é–€åº— x é¡åˆ¥):")
print(multi_dim_analysis.head(8))

# %%
# 2. æ™‚æ®µåˆ†æï¼šä¸åŒæ™‚é–“ç¶­åº¦çš„éŠ·å”®è¶¨å‹¢
time_analysis = sales_data.groupby(['Month', 'Day']).agg(
    total_sales=('TotalAmount', 'sum'),
    avg_sales=('TotalAmount', 'mean'),
    transactions=('SaleID', 'nunique'),
    avg_quantity=('Quantity', 'mean')
).reset_index()

print("æœˆä»½èˆ‡æ˜ŸæœŸåˆ†æ:")
print(time_analysis.head(10))

# å¯è¦–åŒ–æœˆä»½éŠ·å”®è¶¨å‹¢
plt.figure(figsize=(14, 6))
sns.barplot(x='Month', y='total_sales', data=time_analysis, estimator=sum, ci=None)
plt.title('æ¯æœˆç¸½éŠ·å”®é¡', fontsize=14)
plt.xlabel('æœˆä»½')
plt.ylabel('ç¸½éŠ·å”®é¡')
plt.tight_layout()
plt.show()

# %%
# 3. å®¢æˆ¶è³¼è²·åˆ†æï¼šç ”ç©¶æ¯å€‹å®¢æˆ¶çš„è³¼è²·è¡Œç‚º
customer_analysis = sales_data.groupby('CustomerID').agg(
    total_spent=('TotalAmount', 'sum'),
    total_transactions=('SaleID', 'nunique'),
    avg_transaction_value=('TotalAmount', lambda x: x.sum() / len(x.unique())),
    first_purchase=('Date', 'min'),
    last_purchase=('Date', 'max'),
    favorite_category=('Category', lambda x: x.mode().iloc[0]),
    favorite_store=('StoreID', lambda x: x.mode().iloc[0]),
    product_variety=('ProductID', 'nunique')
)

# è¨ˆç®—å®¢æˆ¶æ´»èºæœŸ (å¤©æ•¸)
customer_analysis['active_days'] = (customer_analysis['last_purchase'] - 
                                   customer_analysis['first_purchase']).dt.days

print("å®¢æˆ¶è³¼è²·è¡Œç‚ºåˆ†æ:")
print(customer_analysis.head())

# %%
# å®¢æˆ¶åƒ¹å€¼åˆ†å±¤ (RFMåˆ†æç°¡åŒ–ç‰ˆ)
# R(Recency) - æœ€è¿‘ä¸€æ¬¡è³¼è²·æ™‚é–“
# F(Frequency) - è³¼è²·é »ç‡
# M(Monetary) - è³¼è²·é‡‘é¡
today = pd.Timestamp('2023-12-31')
rfm = sales_data.groupby('CustomerID').agg(
    recency=('Date', lambda x: (today - x.max()).days),
    frequency=('SaleID', 'nunique'),
    monetary=('TotalAmount', 'sum')
)

# å°‡RFMä¸‰å€‹ç¶­åº¦åˆ†ç‚º5å€‹ç­‰ç´š
for metric in ['recency', 'frequency', 'monetary']:
    if metric == 'recency':
        # å°æ–¼recency, å¤©æ•¸è¶Šå°è¶Šå¥½
        rfm[f'{metric}_score'] = pd.qcut(rfm[metric], 5, labels=False, duplicates='drop')
        rfm[f'{metric}_score'] = 4 - rfm[f'{metric}_score']  # åè½‰åˆ†æ•¸
    else:
        # å°æ–¼frequencyå’Œmonetary, æ•¸å€¼è¶Šå¤§è¶Šå¥½
        rfm[f'{metric}_score'] = pd.qcut(rfm[metric], 5, labels=False, duplicates='drop')

# è¨ˆç®—RFMç¸½åˆ†
rfm['rfm_score'] = rfm['recency_score'] + rfm['frequency_score'] + rfm['monetary_score']

# å®šç¾©å®¢æˆ¶åˆ†å±¤
rfm['customer_segment'] = pd.qcut(rfm['rfm_score'], 4, 
                                 labels=['Bronze', 'Silver', 'Gold', 'Platinum'])

print("å®¢æˆ¶RFMåˆ†æèˆ‡åˆ†å±¤:")
print(rfm.head(10))

# å±•ç¤ºå„å®¢æˆ¶åˆ†å±¤çš„å¹³å‡æŒ‡æ¨™
segment_analysis = rfm.groupby('customer_segment').agg({
    'recency': 'mean',
    'frequency': 'mean',
    'monetary': 'mean'
}).round(2)

print("\nä¸åŒå®¢æˆ¶å±¤ç´šçš„å¹³å‡æŒ‡æ¨™:")
print(segment_analysis)

# %% [markdown]
# ## ğŸ“Š 4. é«˜ç´šåˆ†çµ„æŠ€å·§èˆ‡æœ€ä½³å¯¦è¸

# %%
# 1. ä½¿ç”¨ pd.Grouper é€²è¡Œæ™‚é–“åºåˆ—åˆ†çµ„
time_grouped = sales_data.groupby([
    pd.Grouper(key='Date', freq='W'),  # æŒ‰é€±åˆ†çµ„
    'Category'
]).agg({
    'TotalAmount': 'sum',
    'Quantity': 'sum'
}).reset_index()

print("ä½¿ç”¨ pd.Grouper æŒ‰é€±åˆ†çµ„:")
print(time_grouped.head())

# %%
# 2. ä½¿ç”¨åˆ†çµ„ç´¢å¼•å¯¦ç¾é«˜ç´šé¸æ“‡
print("ä½¿ç”¨ .xs() é€²è¡Œè·¨å±¤ç´šé¸æ“‡:")
# é¸æ“‡ç‰¹å®šé¡åˆ¥åœ¨æ¯å€‹åº—é‹ªçš„éŠ·å”®æ•¸æ“š
electronics_by_store = multi_dim_analysis.xs('Electronics', level='Category', drop_level=False)
print(electronics_by_store.head())

# %%
# 3. çµ„å…§æ’å
sales_data['StoreRank'] = sales_data.groupby('StoreID')['TotalAmount'].rank(method='dense', ascending=False)
sales_data['CategoryRank'] = sales_data.groupby(['StoreID', 'Category'])['TotalAmount'].rank(method='dense', ascending=False)

print("çµ„å…§æ’åç¤ºä¾‹:")
print(sales_data[['StoreID', 'Category', 'TotalAmount', 'StoreRank', 'CategoryRank']].head(15))

# %%
# 4. æ€§èƒ½å„ªåŒ–æŠ€å·§
import time

def performance_test():
    results = {}
    
    # æ¸¬è©¦1: æ¨™æº–groupby
    start = time.time()
    std_groupby = sales_data.groupby('Category')['TotalAmount'].mean()
    results['Standard groupby'] = time.time() - start
    
    # æ¸¬è©¦2: é å…ˆæ’åºå¾Œgroupby
    start = time.time()
    # å…ˆæ’åºæ•¸æ“šï¼Œä½¿ç”¨æ’åºçš„æ•¸æ“šé€²è¡Œåˆ†çµ„èƒ½æé«˜é€Ÿåº¦
    sorted_data = sales_data.sort_values('Category')
    sorted_groupby = sorted_data.groupby('Category')['TotalAmount'].mean()
    results['Sorted groupby'] = time.time() - start
    
    # æ¸¬è©¦3: ä½¿ç”¨categoricals
    start = time.time()
    # å°‡åˆ†çµ„åˆ—è½‰æ›ç‚ºcategoricalå¯ä»¥æé«˜åˆ†çµ„é€Ÿåº¦
    cat_data = sales_data.copy()
    cat_data['Category'] = cat_data['Category'].astype('category')
    cat_groupby = cat_data.groupby('Category')['TotalAmount'].mean()
    results['Categorical groupby'] = time.time() - start
    
    return results

# åŸ·è¡Œæ€§èƒ½æ¸¬è©¦
perf_results = performance_test()
print("åˆ†çµ„æ“ä½œæ€§èƒ½æ¯”è¼ƒ (ç§’):")
for method, duration in perf_results.items():
    print(f"{method}: {duration:.5f}")

# %% [markdown]
# ## ğŸ“‹ 5. ç¸½çµ

# %% [markdown]
# ### 5.1 åˆ†çµ„èˆ‡èšåˆçš„æ ¸å¿ƒæ¦‚å¿µ
# 
# - **GroupBy å°è±¡**ï¼šç†è§£å…¶å…§éƒ¨çµæ§‹ã€åˆ†çµ„éµå’Œæ•¸æ“šåˆ†å‰²æ–¹å¼
# - **å¤šå±¤æ¬¡åˆ†çµ„**ï¼šä½¿ç”¨å¤šå€‹éµå¯¦ç¾è¤‡é›œçš„æ•¸æ“šåˆ†å±¤èšåˆ
# - **èšåˆå‡½æ•¸**ï¼šéˆæ´»çµ„åˆå…§ç½®èˆ‡è‡ªå®šç¾©çš„èšåˆå‡½æ•¸
# - **èšåˆæ–¹æ³•**ï¼šæŒæ¡ agg()ã€transform()ã€apply() å’Œ filter() çš„å€åˆ¥èˆ‡æ‡‰ç”¨å ´æ™¯

# %% [markdown]
# ### 5.2 é€²éšæ‡‰ç”¨æŠ€å·§
# 
# - **è‡ªå®šç¾©èšåˆå‡½æ•¸**ï¼šä½¿ç”¨ lambdaã€partial å‡½æ•¸å’Œè£é£¾å™¨å‰µå»ºè¤‡é›œèšåˆåŠŸèƒ½
# - **åˆ†çµ„è½‰æ›**ï¼šä½¿ç”¨ transform() é€²è¡Œçµ„å…§æ¨™æº–åŒ–ã€ç´¯è¨ˆçµ±è¨ˆå’Œç§»å‹•çª—å£è¨ˆç®—
# - **åˆ†å±¤èšåˆ**ï¼šåœ¨å¤šå€‹ç¶­åº¦ä¸Šé€²è¡Œæ•¸æ“šæ‘˜è¦ï¼Œæå–æ¥­å‹™æ´å¯Ÿ
# - **é«˜æ•ˆåˆ†çµ„**ï¼šåˆ©ç”¨ç´¢å¼•ã€æ’åºå’Œé¡åˆ¥å„ªåŒ–åˆ†çµ„æ€§èƒ½
# - **çµæœè™•ç†**ï¼šæ¸…ç†å’Œé‡å¡‘èšåˆçµæœï¼Œä½¿å…¶æ›´æ˜“æ–¼åˆ†æå’Œå¯è¦–åŒ–

# %% [markdown]
# ### 5.3 å¯¦å‹™æ‡‰ç”¨æ€è€ƒ
# 
# - **æ¥­å‹™æŒ‡æ¨™è¨­è¨ˆ**ï¼šåŸºæ–¼åˆ†çµ„èšåˆæ§‹å»ºKPIå’Œæ¥­å‹™æŒ‡æ¨™
# - **å®¢æˆ¶åˆ†å±¤**ï¼šä½¿ç”¨RFMç­‰æ¨¡å‹é€²è¡Œå®¢æˆ¶åƒ¹å€¼åˆ†æ
# - **æ™‚é–“åºåˆ—åˆ†æ**ï¼šåœ¨ä¸åŒæ™‚é–“ç²’åº¦ä¸Šåˆ†ææ¥­å‹™è¶¨å‹¢å’Œå­£ç¯€æ€§
# - **å¤šç¶­åº¦åˆ†æ**ï¼šçµåˆä¸åŒç¶­åº¦çš„æ•¸æ“šï¼Œç™¼ç¾éš±è—çš„æ¥­å‹™é—œè¯
# - **é æ¸¬å»ºæ¨¡æº–å‚™**ï¼šä½¿ç”¨åˆ†çµ„èšåˆå‰µå»ºæœ‰æ•ˆçš„æ¨¡å‹ç‰¹å¾µ 